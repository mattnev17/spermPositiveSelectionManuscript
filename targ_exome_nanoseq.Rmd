---
title: "nanoseqDataPrep"
author: "Matt Neville"
date: "17/01/2022"
output: html_document
---

# 1. Libraries
```{r parameters}
library(egg)
library(dndscv)
library(scales)
library(readxl)
library(ggh4x)
library(ggrepel)
library(patchwork)
library(RColorBrewer)
library(stringi)
library(ggforce)
library(ggpubr)
library(gt)
library(ggpattern)
library(tidyverse)

```


# 2. Targ Data Processing
Processing outputs of Nextflow implementation of https://github.com/cancerit/NanoSeq
Targeted and exome samples are often processed separately due to differences in file sizes and target panel
## Contam/Efficiency/Ancestry PCs
```{bash ContamSummaries}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm contam.txt
for sample in `grep "targeted" ../targetedSampleList.txt | cut -f3 `;
  do echo $sample
	#Shows contaminant level.
	contamination=$(tail -n 1 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt)
	intendedPCs=$(head -n 2 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt | tail -n 1)
	contamPCs=$(head -n 3 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt | tail -n 1)
	seqReads=$(head -n 2 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv | tail -n 1 |  awk '{print $2}')
	dupRate=$(head -n 6 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv  | tail -n 1 |  awk '{print $2}')
	f_eff=$(head -n 12 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv  | tail -n 1 |  awk '{print $2}')
	echo "${sample} ${contamination} ${intendedPCs} ${contamPCs} ${seqReads} ${dupRate} ${f_eff}" >> contam.txt
done
for sample in `grep "exome" ../targetedSampleList.txt | cut -f3 `;
  do echo $sample
	#Shows contaminant level.
	contamination=$(tail -n 1 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt)
	intendedPCs=$(head -n 2 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt | tail -n 1)
	contamPCs=$(head -n 3 ${NF}outNextflow/QC/$sample/verifyBAMid/$sample.verifyBAMid.txt | tail -n 1)
	seqReads=$(head -n 2 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv | tail -n 1 |  awk '{print $2}')
	dupRate=$(head -n 6 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv  | tail -n 1 |  awk '{print $2}')
	f_eff=$(head -n 12 ${NF}outNextflow/QC/$sample/effi/$sample.effi.tsv  | tail -n 1 |  awk '{print $2}')
	echo "${sample} ${contamination} ${intendedPCs} ${contamPCs} ${seqReads} ${dupRate} ${f_eff}" >> contam.txt
done
```

## Burdens
```{bash burdens}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm burdens.tsv
for sample in `grep "targeted" ../targetedSampleList.txt | cut -f1`;
  do echo $sample
  sed '/muts/d' ${NF}outNextflow/NanoSeq/$sample/post/$sample.mut_burden.tsv | sed "s/$/\t$sample/" >> burdens.tsv
done
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow

for sample in `grep "exome" ../targetedSampleList.txt | cut -f1`;
  do echo $sample
  sed '/muts/d' ${NF}outNextflow/NanoSeq/$sample/post/$sample.mut_burden.tsv | sed "s/$/\t$sample/" >> burdens.tsv
done
```

## Variant Calls
```{bash varCalls}
#Merge together all calls
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm mergedCalls.vcf
for sample in `grep "targeted" ../targetedSampleList.txt | cut -f1`;
 do echo $sample
  gunzip -c ${NF}outNextflow/NanoSeq/$sample/$sample.vcf.gz | sed '/#/d' | sed "s/$/\t$sample/" >> mergedCalls.vcf
done
for sample in `grep "exome" ../targetedSampleList.txt | cut -f1`;
 do echo $sample
  gunzip -c ${NF}outNextflow/NanoSeq/$sample/$sample.vcf.gz | sed '/#/d' | sed "s/$/\t$sample/" >> mergedCalls.vcf
done
```

## TriNuc Background
```{bash triNucBackground}
#Merge together trinucs
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm trinuc.txt
for sample in `grep "targeted" ../targetedSampleList.txt | cut -f1`;
 do echo $sample
  cut -f1,2 ${NF}outNextflow/NanoSeq/$sample/post/$sample.trint_counts_and_ratio2genome.tsv | sed '/ratio/d' | sed "s/$/\t$sample/" >> trinuc.txt
done
for sample in `grep "exome" ../targetedSampleList.txt | cut -f1`;
 do echo $sample
  cut -f1,2 ${NF}outNextflow/NanoSeq/$sample/post/$sample.trint_counts_and_ratio2genome.tsv | sed '/ratio/d' | sed "s/$/\t$sample/" >> trinuc.txt
done
```

## Coverage
```{bash cov}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
mkdir -p cov/source
mkdir -p cov/masked
mkdir -p cov/targCut
mkdir -p cov/exCut
mkdir -p cov/inPanel
mkdir -p cov/jobLogs
mkdir -p cov/collapseCut

# Copy Targeted directly
for sample in `grep "targeted" ../targetedSampleList.txt  | cut -f1`;
  do echo $sample
  gunzip -c ${NF}outNextflow/NanoSeq/$sample/post/$sample.cov.bed.gz | awk -F'\t|;' '$6 > 10' > cov/source/${sample}.cov.bed
done

# Script to copy Exomes as files are large
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
nano cov/covSource.sh
#!/bin/bash
sample="$1"
gunzip -c ${NF}outNextflow/NanoSeq/$sample/post/$sample.cov.bed.gz | awk -F'\t|;' '$6 > 10' > cov/source/${sample}.cov.bed
chmod +x cov/covSource.sh

# Copy exomes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
for sample in `grep "exome" ../targetedSampleList.txt  | cut -f1`;
  do echo $sample
  bsub -o cov/jobLogs/cov.$sample.out -e cov/jobLogs/cov.$sample.err -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 ./cov/covSource.sh $sample
done
```

## Cram storage
```{bash cramStorage}
# Pulling the neat (de-duplicated) crams to store for future uses including snp filtering below
cd /lustre/scratch127/casm/team294rr/mn7/sperm
mkdir -p neatCrams/T1
mkdir -p neatCrams/T2
mkdir -p neatCrams/EX

cd /lustre/scratch127/casm/team294rr/mn7/sperm
bsub -q normal -e neatCrams/cramStorageT1.err -o neatCrams/cramStorageT1.out -R 'select[mem>=100] rusage[mem=100]' -M100 "cp $NF/T1_work/work/*/*/dedup/*.cram* neatCrams/T1/"

cd /lustre/scratch127/casm/team294rr/mn7/sperm
bsub -q normal -e neatCrams/cramStorageT2.err -o neatCrams/cramStorageT2.out -R 'select[mem>=100] rusage[mem=100]' -M100 "cp $NF/dT2_work/work/*/*/dedup/*neat.cram* neatCrams/T2/"

cd /lustre/scratch127/casm/team294rr/mn7/sperm
bsub -q long -e neatCrams/cramStorageEX.err -o neatCrams/cramStorageEX.out -R 'select[mem>=100] rusage[mem=100]' -M100 "cp $E/work/*/*/dedup/*.cram* neatCrams/EX/"

cd /lustre/scratch127/casm/team294rr/mn7/sperm
bsub -q long -e neatCrams/cramStorageEX.err -o neatCrams/cramStorageEX.out -R 'select[mem>=100] rusage[mem=100]' -M100 "cp $E/work/*/*/dedup/*.cram* neatCrams/EX/"

ls -lh work/*/*/dedup/*.cram 
```

# 3. QC
## a) Check burdens/Masked SNP counts
```{r maskedCounts}
#First snvs/mnvs then bind indels as they have different column orders
allCallsTarg0 <- read_tsv(paste0(path, "postNextflow/mergedCalls.vcf"), col_names = c("chr", "start", "ref", "alt", "FILTER","info", "Sample_PD_ID"), col_types = 'cd-cc-ccc') |>
  filter(str_detect(info, "nv")) |>
  separate(info, sep = ";", into = c("TRI","TIMES_CALLED","TYPE","DUPLEX_VAF","BAM_VAF","BAM_VAF_BQ10",NA,NA,NA,NA,"DUPLEX_COV","BAM_MUT","BAM_COV","BAM_MUT_BQ10","BAM_COV_BQ10",NA,"QPOS",NA,NA,NA,NA,NA), convert = T) |> 
  mutate_at(vars(TRI:QPOS), ~str_remove(., ".*=")) |> 
  mutate_at(vars(TIMES_CALLED, DUPLEX_VAF:QPOS), as.numeric) |>
  # Add indels
  bind_rows(read_tsv(paste0(path, "postNextflow/mergedCalls.vcf"), col_names = c("chr", "start", "ref", "alt", "FILTER","info", "Sample_PD_ID"), col_types = 'cd-cc-ccc') |> 
    filter(!str_detect(info, "nv")) |>
    separate(info, sep = ";", into = c("TYPE","TIMES_CALLED","DUPLEX_VAF","BAM_VAF","BAM_VAF_BQ10",NA,"DUPLEX_COV","BAM_MUT","BAM_COV","BAM_MUT_BQ10","BAM_COV_BQ10", NA), convert = T) |> 
    mutate_at(vars(TYPE:BAM_COV_BQ10), ~str_remove(., ".*=")) |> 
    mutate_at(vars(TIMES_CALLED:BAM_COV_BQ10), as.numeric)) |> 
  left_join(targetedSamples, by = "Sample_PD_ID") |> 
  # Suppress warnings about creating NAs when converting to numeric values
  suppressWarnings() 

# Filter to preset cutoff
allCallsTarg <- allCallsTarg0 |>  filter(BAM_VAF < 0.01 & (DUPLEX_VAF < 0.1 | is.na(DUPLEX_VAF)))

#Read in QC metrics
seqMetrics <- read_delim(paste0(path, "postNextflow/contam.txt"), delim = " ", col_names = c("ss_ID", "contamination", "seqReads", "dupRate", "f_eff"), col_types = 'cc------ddd') |> 
  mutate(contamination = as.numeric(str_remove(contamination, "FREEMIX\\(Alpha\\):"))) |> 
  left_join(targetedSamples) |> 
  distinct() 

seqMetricsSummary <- seqMetrics |> drop_na(seqReads) |> group_by(target) |> summarize(contamination = mean(contamination), seqReads = mean(seqReads),dupRate = mean(dupRate), f_eff = mean(f_eff))

#Calculate burdens from variant counts 
adjBurdens <- allCallsTarg |> filter(FILTER == "PASS") |> filter(TYPE %in% c("snv", "dnv", "mnv")) |> 
  group_by(Sample_PD_ID) |> dplyr::summarize(mutsMan = sum(TIMES_CALLED), mutsSingle = n()) |> 
  # Add indel burdens
  left_join(allCallsTarg |> filter(FILTER == "PASS") |> filter(TYPE %in% c("del", "ins")) |> 
    group_by(Sample_PD_ID) |> dplyr::summarize(indels = sum(TIMES_CALLED), indelsSingle = n()), by = "Sample_PD_ID") |> 
  mutate(indels = replace_na(indels, 0)) |>  mutate(indelsSingle = replace_na(indelsSingle, 0))

#Compare and merge with burdens in pipeline
burdens <- read_tsv(paste0(path, "postNextflow/burdens.tsv"), col_names = c("group", "muts",	"total",	"burden",	"burden_lci",	"burden_uci", "Sample_PD_ID"), col_types = 'cdddddc') |> 
  filter(group == "observed") |> 
  left_join(adjBurdens, by = "Sample_PD_ID") |> 
  mutate(burdenMan = mutsMan/total) |> 
  mutate(adjBurdenSingle = mutsSingle/total) |> 
  mutate(indelBurden = indels/total) |> 
  mutate(indelBurdenSingle = indelsSingle/total) |> 
  select(Sample_PD_ID, muts, mutsMan, mutsSingle, indels, indelsSingle, total, burden, burdenMan, adjBurdenSingle, indelBurden, indelBurdenSingle) |> 
  drop_na()

#Find counts of masked and passed variants
maskedCounts <- allCallsTarg |> 
  mutate(FILTER = if_else(FILTER == "PASS", FILTER, "MASKED")) |> 
  mutate(TYPE = if_else(TYPE %in% c("snv", "dnv", "mnv"), "snv", "indel")) |> 
  group_by(Sample_PD_ID, FILTER, TYPE) |> summarize(count = n(), .groups = "drop") |> 
  pivot_wider(id_cols = Sample_PD_ID, names_from = c(FILTER,TYPE), names_sep = "_", values_from = count, values_fill = 0) |> 
  left_join(targetedSamples, by = "Sample_PD_ID") |> 
  left_join(burdens, by = "Sample_PD_ID") |> 
  left_join(seqMetrics |> select(ss_ID, contamination), by = "ss_ID") |> 
  mutate(maskedProportion = MASKED_snv/PASS_snv) |> 
  mutate(maskedProportionIndel = MASKED_indel/PASS_indel) |> 
  mutate(above5 = if_else(maskedProportion > 5, T,F)) |> 
  mutate(contam1 = if_else(contamination > 0.002,T,F)) |> 
  mutate(label = if_else(tissue == "Sperm" & (maskedProportion > 5 | contamination > 0.0025 | burdenMan > 1e-7), str_sub(PD_ID, 6,8), "")) |> 
  mutate(concern = if_else(tissue == "Sperm" & (maskedProportion > 5 | contamination > 0.0025 | burdenMan > 1e-7), T, F)) 

```

## b) Manual indel filtering
Indel bug where they are being called even at masked sites. Manually exclude these vars
### Indel position bed
```{r collapse}
# Write out list of sites to get coverage for in each sample
for(sample in (targetedSamples |> pull(Sample_PD_ID))) {
  indelsToCheck <- allCallsTarg0 |> 
    filter(FILTER == "PASS" & TYPE != "snv") |> 
    filter(Sample_PD_ID == sample) |>
    mutate(startBed = start - 1) |> 
    mutate(endBed = start + str_length(ref) - 1) |> 
    select(chr, startBed, endBed) |> 
    arrange(chr, startBed)
  write_tsv(indelsToCheck, paste0(path, "postNextflow/cov/indelFilter/", sample, ".vars.bed"), col_names = F)
}
```

#### Cov bed intersect
```{bash collapse}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/indelFilter/
rm jobLogs/intersect*
for sample in `cut -f1 ../../../targetedSampleList.txt`;
  do echo $sample
  bsub -o jobLogs/intersect.$sample.out -e jobLogs/intersect.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; sort -T tmp -k1,1 -k2,2n $sample.vars.bed > $sample.vars.sorted.bed; bedtools intersect -a ../source/$sample.cov.bed -b $sample.vars.sorted.bed -wa > $sample.cov.bed"
done

# Group results
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/indelFilter/
rm allIndelCov.bed
for sample in `cut -f1 ../../../targetedSampleList.txt`;
  do echo $sample
  sed "s/$/\t$sample/" $sample.cov.bed >> allIndelCov.bed
done

```

### Process Indel Cov
```{r collapse}
# Process cov
indelsExpanded <- allCallsTarg0 |> 
  filter(FILTER == "PASS" & TYPE != "snv") |> 
  mutate(length = str_length(ref)) |> 
  rowwise() |> 
  do({
    copy_count <- seq_len(.$length)
    data.frame(
      chr = rep(.$chr, .$length),
      start = rep(.$start, .$length),
      length = rep(.$length, .$length),
      Sample_PD_ID = rep(.$Sample_PD_ID, .$length), 
      pos = .$start + copy_count - 1
    )
  }) |> 
  ungroup() |> distinct() |> 
  # Add coverage
  left_join(read_tsv(paste0(path, "postNextflow/cov/indelFilter/allIndelCov.bed"), col_types = 'c-dcc', col_names = c("chr", "pos", "DUPLEX_COV", "Sample_PD_ID")) |> distinct() |> 
  mutate(DUPLEX_COV = as.numeric(str_sub(DUPLEX_COV, 7, -1))), by = join_by(Sample_PD_ID, pos, chr)) |> 
  mutate(DUPLEX_COV = replace_na(DUPLEX_COV, 0))


```

## c) Contam filtering
### Create loci file
```{r lociFile}
# Noticed several samples in targeted2 have high masked snp counts so performing filtering of germline snps within cohort to check if contamination is between the samples within the cohort
# Targeted Positions For SNP check - will check cohort bams at all of these positions
targetedPos <-  allCallsTarg |> bind_rows(indelsExpanded |> select(chr, start = pos)) |> 
  distinct(chr, start) |> 
  arrange(chr, start)

write_tsv(targetedPos, "/Users/mn7/volumes/mn7_lustre/sperm/targeted/contamFilter/variantLoci.txt", col_names = F)
write_tsv(allCallsTarg, "/Users/mn7/volumes/mn7_lustre/sperm/targeted/contamFilter/allCallsTarg.tsv")
# For annotating in/out of panel
write_tsv(targetedPos |> mutate(end = start) |> mutate(start = end-1), "/Users/mn7/volumes/mn7_lustre/sperm/targeted/contamFilter/allCallsTarg.bed", col_names = F)

```

#### Vaf filter script
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
nano filterVaf.sh
```{bash vafScipt}
#!/bin/bash

# Check if the number of arguments is correct
if [ "$#" -ne 2 ]; then
    echo "Usage: bash filterVaf.sh input_file output_file"
    exit 1
fi

# Set the input and output file paths
input_file="$1"
output_file="$2"

# Execute the awk command for filtering and calculation
awk -F'\t' 'BEGIN {OFS="\t"} {
    split($5, values, ",");
    refA = values[1];
    refB = values[2];
    altA = values[3];
    altB = values[4];
    vaf = (altA + altB) / (refA + refB + altA + altB);
    if (vaf >= 0.3) {
        print $1, $2, $3, $4, vaf;
    }
}' "$input_file" > "$output_file"
```

### Germline Calls
```{bash germline}
mkdir -p ijobLogsT1
mkdir -p ijobLogsT2
mkdir -p ijobLogsEX
mkdir -p germVarsT1
mkdir -p germVarsT2
mkdir -p germVarsEX

#Targeted 1
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
for sample in `grep "targeted1" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsT1/germ.$sample.err -o ijobLogsT1/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/T1/$sample.neat.cram | bcftools call -v -m -Ov > germVarsT1/$sample.vcf"
done
#Targeted 2
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT2/*
for sample in `grep "targeted2" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q long -e ijobLogsT2/germ.$sample.err -o ijobLogsT2/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/T2/$sample.neat.cram | bcftools call -v -m -Ov > germVarsT2/$sample.vcf"
done
#Exome
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/*
for sample in `grep "exome1" ../targetedSampleList.txt | cut -f3 `;
  do echo $sample
  bsub -q basement -e ijobLogsEX/germ.$sample.err -o ijobLogsEX/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/EX/$sample.neat.cram | bcftools call -v -m -Ov  > germVarsEX/$sample.vcf"
done

#Exome 2
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/*
for sample in `grep "exome2" ../targetedSampleList.txt | cut -f3 `;
  do echo $sample
  bsub -q basement -e ijobLogsEX/germ.$sample.err -o ijobLogsEX/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/EX/$sample.neat.cram | bcftools call -v -m -Ov  > germVarsEX/$sample.vcf"
done

#Exome 3
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
for sample in `grep "exome3" ../targetedSampleList.txt  | cut -f3 `;
  do echo $sample
  bsub -q basement -e ijobLogsEX/germ.$sample.err -o ijobLogsEX/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/EX/$sample.neat.cram | bcftools call -v -m -Ov  > germVarsEX/$sample.vcf"
done

#Exome 4
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
for sample in `grep "exome4" ../targetedSampleList.txt  | cut -f3 `;
  do echo $sample
  bsub -q basement -e ijobLogsEX/germ.$sample.err -o ijobLogsEX/germ.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools mpileup -Ou -f /lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa /lustre/scratch127/casm/team294rr/mn7/sperm/neatCrams/EX/$sample.neat.cram | bcftools call -v -m -Ov  > germVarsEX/$sample.vcf"
done
```

#### Create Masking file
```{bash maskingFile}
#Filter to usable file for masking

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT2/filter*
for sample in `grep "targeted" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsT2/filter.$sample.err -o ijobLogsT2/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' germVarsT*/$sample.vcf > germVarsT2/$sample.int.vcf;  ./filterVaf.sh germVarsT2/$sample.int.vcf germVarsT2/$sample.vaf.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/filter*
for sample in `grep "exome" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsEX/filter.$sample.err -o ijobLogsEX/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' germVarsEX/$sample.vcf | grep -v '\.' > germVarsEX/$sample.int.vcf;  ./filterVaf.sh germVarsEX/$sample.int.vcf germVarsEX/$sample.vaf.vcf"
done

#Group results for all
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
nano maskGerm.sh
#!/bin/bash
module load bedtools
cat germVars*/*.vaf.vcf | awk -F'\t' 'BEGIN {OFS="\t"} {print $1, $2-1, $2}' | sort -k1,1 -k2,2n | bedtools merge > toMaskGerm.bed

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT2/mask*
bsub -q normal -e ijobLogsT2/mask.err -o ijobLogsT2/mask.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 ./maskGerm.sh

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
cp /lustre/scratch124/casm/team78pipelines/reference/human/GRCH37d5/botseq/NOISE.sorted.bed.gz .
gunzip NOISE.sorted.bed.gz
module load bedtools; cat toMaskGerm.bed NOISE.sorted.bed | sort -k1,1 -k2,2n | bedtools merge > custom.NOISE.sorted.masked.bed; bgzip custom.NOISE.sorted.masked.bed; tabix -f custom.NOISE.sorted.masked.bed.gz


#Copy to nanoseq directory to mask regions
cp toMaskGerm.bed $NF
# Then can run nanoseq again with these 

#Make unique sites version for dnds mask
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
cp /lustre/scratch124/casm/team78pipelines/reference/human/GRCH37d5/botseq/SNP.sorted.bed.gz . 
gunzip SNP.sorted.bed.gz
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter

bsub -q normal -e %J.err -o %J.out -R 'select[mem>=10000] rusage[mem=10000]' -M10000 "module load bedtools; bedtools subtract -a toMaskGerm.bed -b NOISE.sorted.bed > tmp.dndsTwinsUK_Mask.bed; bedtools subtract -a tmp.dndsTwinsUK_Mask.bed -b SNP.sorted.bed > dndsTwinsUK_Mask.bed; bgzip dndsTwinsUK_Mask.bed; tabix -f dndsTwinsUK_Mask.bed.gz"

```

#### Variant Germline check
```{bash variantFilter}
#Filter to usable file for variants
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT1/filter*
for sample in `grep "targeted1" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsT1/filter.$sample.err -o ijobLogsT1/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsT1/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsT1/$sample.flt.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT2/filter*
for sample in `grep "targeted2" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsT2/filter.$sample.err -o ijobLogsT2/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsT2/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsT2/$sample.flt.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsT2/filter*
for sample in `grep "exome" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsEX/filter.$sample.err -o ijobLogsEX/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsEX/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsEX/$sample.flt.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/filter*
for sample in `grep "exome2" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsEX/filter.$sample.err -o ijobLogsEX/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsEX/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsEX/$sample.flt.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/filter*
for sample in `grep "exome3" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsEX/filter.$sample.err -o ijobLogsEX/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsEX/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsEX/$sample.flt.vcf"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm ijobLogsEX/filter*
for sample in `grep "exome4" ../targetedSampleList.txt | cut -f3`;
  do echo $sample
  bsub -q normal -e ijobLogsEX/filter.$sample.err -o ijobLogsEX/filter.$sample.out -R 'select[mem>=1000] rusage[mem=1000]' -M1000 "module load bcftools; bcftools view -Ou -T variantLoci.txt germVarsEX/$sample.vcf | bcftools query -i 'DP>10' -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/DP4\n' > germVarsEX/$sample.flt.vcf"
done

#Group results for all
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/contamFilter
rm groupedGermCounts.tsv
for sample in $(cut -f3 ../targetedSampleList.txt);
  do echo $sample
  cat germVars*/$sample.flt.vcf | sed "s/$/\t$sample/" >> groupedGermCounts.tsv
done
```

### Filter for Variant Contaminating
```{r varContam, fig.width= 12, fig.height=12}
bamCounts <- read_tsv("/Users/mn7/volumes/mn7_lustre/sperm/targeted/contamFilter/groupedGermCounts.tsv", col_types = 'cicccc', col_names = c("chr", "pos", "ref", "alt", "DP4", "ss_ID")) |> 
  separate(DP4, into = c("RefA", "RefB", "AltA", "AltB"), sep = ",", convert = T) |> 
  mutate(vaf = (AltA+AltB)/(RefA + RefB +AltA+AltB)) |> 
  left_join(targetedSamples |> select(Sample_PD_ID, ss_ID, target), by = "ss_ID") |> 
  select(chr,start = pos,ref,alt,vaf,contamSource = Sample_PD_ID, contamTarget = target) 

anyCounts <- bamCounts |> 
  filter(vaf > .3) |> 
  group_by(chr,start) |> summarise(varCount = n(), .groups = "drop")
hist(anyCounts$varCount)

# Update indel filtering with any cohort SNPs overlapping indel sites
indelsFilter <- indelsExpanded |> 
  left_join(anyCounts |> rename(pos = start), by = join_by(chr, pos)) |> mutate(varCount = replace_na(varCount, 0)) |>
  mutate(noCov = if_else(DUPLEX_COV == 0 | varCount > 0, 1, 0)) |>
  # mutate(noCov = if_else(DUPLEX_COV == 0, 1, 0)) |> 
  group_by(chr,start,Sample_PD_ID) |> summarize(noCov = sum(noCov), .groups = "drop") |> 
  mutate(indelFilter = if_else(noCov > 0, "manualMASK", "PASS")) 
table(indelsFilter$indelFilter)
table(indelsFilter$noCov)

snpFilterVars0 <- allCallsTarg0 |> 
  mutate(class = if_else(TYPE == "snv", "snv", "indel")) |> 
  mutate(FILTER = if_else(FILTER == "PASS", FILTER, "MASKED")) |> 
  filter(FILTER == "PASS") |> 
  mutate(FILTER = if_else(BAM_VAF >= 0.01 | DUPLEX_VAF >= 0.1, "alleleFreqThreshold", FILTER, missing = FILTER)) |> 
    # Cohort germline vars
  left_join(anyCounts, by = c("chr", "start"))  |> 
  mutate(varCount = replace_na(varCount, 0)) |> 
  mutate(FILTER = if_else(varCount > 0, "cohortMask", FILTER)) |> 
  # Indels at sites that were excluded from snv calling
  left_join(indelsFilter |> select(-noCov), by = join_by(chr, start, Sample_PD_ID)) |>
  mutate(indelFilter = replace_na(indelFilter, "PASS")) |>
  mutate(FILTER = if_else(indelFilter != "PASS" & TYPE != "snv", "indelMASK", FILTER)) |> 
  select(-c(indelFilter))

snpFilterVars01 <- snpFilterVars0 |> 
  # Flag variants that were already found above vaf cutoff threshold in another indiv as likely artefactual
  left_join(allCallsTarg0 |>
              filter(BAM_VAF > 0.01) |> group_by(chr,start,ref,alt) |> summarise(countAboveVAF = n(), .groups = "drop"), by = join_by(chr, start, ref, alt)) |>
  mutate(countAboveVAF = replace_na(countAboveVAF, 0)) |>
  mutate(FILTER = if_else(FILTER == "PASS" & countAboveVAF > 0,  "alleleFreqThreshold", FILTER)) |>
    # Manually filter recurrent artefact
  mutate(FILTER = if_else(start == 16358408 & chr == "1", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 142499205 & chr == "7", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 150421622 & chr == "3", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 57221548 & chr == "1", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 47614244 & chr == "1", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 1537444 & chr == "16", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 33476303 & chr == "1", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 74183022 & chr == "6", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 10823582 & chr == "11", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 179300869 & chr == "2", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 19360559 & chr == "9", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 105414451 & chr == "14", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 101730036 & chr == "8", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 16893723 & chr == "1", "manualAnnot", FILTER)) |>
  mutate(FILTER = if_else(start == 16893792 & chr == "1", "manualAnnot", FILTER)) 


table(snpFilterVars01 |> filter(TYPE == "snv") |> pull(FILTER))
table(snpFilterVars01 |> filter(TYPE != "snv") |> pull(FILTER))

snpFilterVars <- snpFilterVars01 |> 
  filter(FILTER == "PASS") 

write_tsv(snpFilterVars, "/Users/mn7/volumes/mn7_lustre/sperm/targeted/contamFilter/snpFilterVars.tsv")

```

#### Bam VAF Plot
```{r bamVAF, fig.height=12, fig.width=12}
vaf_colours <- c("MASKED" = "#fb8072",
                 "cohortMask" = "#fdb462",
                 "indelMASK" = "cadetblue",
                 "manualAnnot" = "grey60",
                 "alleleFreqThreshold" = "darkorchid3",
                 "dbsnp" = "#addd8e",
                 "shearwater" = "lightpink",
                 "NEI_IND" = "#91003f",
                 "PASS" = "#80b1d3")


#Visualize each set pre and post cohort filter
p_initialVAF <- allCallsTarg0 |> 
  mutate(TYPE = if_else(TYPE == "snv", "Substitutions", "Indels")) |> 
  mutate(TYPE = factor(TYPE, levels = c("Substitutions", "Indels"), ordered = TRUE)) |> 
  mutate(FILTER = if_else(FILTER == "dbsnp;shearwater", "dbsnp", FILTER)) |>
  mutate(BAM_VAF = if_else(BAM_VAF == 0, BAM_VAF_BQ10, BAM_VAF)) |> 
  mutate(BAM_VAF = if_else(BAM_VAF == 0, DUPLEX_VAF, BAM_VAF)) |> 
  mutate(FILTER = factor(FILTER, levels = names(vaf_colours), ordered = TRUE)) |> 
  ggplot(aes(BAM_VAF, after_stat(count), fill = FILTER)) +
  scale_fill_manual(values = vaf_colours) +
  scale_x_log10(limits = c(7e-5, 1e-1)) +
  geom_density(position = "stack") +
  ylab("Density") +
  guides(fill=guide_legend(title="Pipeline filters")) +
  facet_wrap(~TYPE, scales = "free_y", ncol = 2) +
  theme_pubr() +
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))

p_cohortMaskVAF <- snpFilterVars01 |> 
  mutate(TYPE = if_else(TYPE == "snv", "Substitutions", "Indels")) |> 
  mutate(TYPE = factor(TYPE, levels = c("Substitutions", "Indels"), ordered = TRUE)) |> 
  mutate(BAM_VAF = if_else(BAM_VAF == 0, BAM_VAF_BQ10, BAM_VAF)) |> 
  mutate(BAM_VAF = if_else(BAM_VAF == 0, DUPLEX_VAF, BAM_VAF)) |> 
  mutate(FILTER = factor(FILTER, levels = names(vaf_colours), ordered = TRUE)) |> 
  ggplot(aes(BAM_VAF, after_stat(count), fill = FILTER)) +
  scale_fill_manual(values = vaf_colours) +
  scale_x_log10(limits = c(7e-5, 1e-1)) +
  geom_density(position = "stack") +
  guides(fill=guide_legend(title="Additional filters")) +
  ylab("Density") +
  facet_wrap(~TYPE, scales = "free_y", ncol = 2) + 
  theme_pubr() +
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))

p_initialVAF/p_cohortMaskVAF +  plot_annotation(tag_levels = "a") 

png(paste0(localPath, 'pQC_variantFilters.png'), height=10, width=12)
p_initialVAF/p_cohortMaskVAF + plot_annotation(tag_levels = "a")
dev.off()
```

#### CohortMask
```{r bamFilter, fig.height=7, fig.width=14}

#Remove variants that are SNPs in other samples
p_cohortMask <- snpFilterVars0 |> bind_rows(allCallsTarg |> filter(FILTER != "PASS")) |> 
  select(-varCount) |>  left_join(anyCounts, by = c("chr", "start"))  |> mutate(varCount = replace_na(varCount, 0)) |> 
  filter(TYPE == "snv") |> 
  mutate(FILTER = if_else(FILTER == "PASS", FILTER, "MASKED_other")) |> 
  mutate(BAM_VAF = if_else(BAM_VAF == 0, BAM_VAF_BQ10, BAM_VAF)) |> 
  mutate(varCount = replace_na(varCount, 0)) |> mutate(FILTER = if_else(varCount > 0, "cohortMask", FILTER)) |> 
  mutate(target = factor(target, levels = c("targeted1", "targeted2", "exome1", "exome2", "exome3", "exome4"), ordered = TRUE)) |> 
  ggplot(aes(BAM_VAF, after_stat(count), fill = FILTER)) +
  scale_fill_manual(values = c('#fdb462', '#fb8072','#80b1d3')) +
  scale_x_log10() +
  geom_density(position = "stack") +
  ylab("Substitution density") +
  guides(fill=guide_legend(title="Post bam filter"))+ 
  facet_wrap(~target, scales = "free_y",ncol = 6) + 
  theme_pubr() +
  theme(legend.position = "right", strip.background = element_blank())


p_cohortMaskInd <- snpFilterVars0 |> bind_rows(allCallsTarg |> filter(FILTER != "PASS")) |> 
  select(-varCount) |> left_join(anyCounts, by = c("chr", "start")) |> mutate(varCount = replace_na(varCount, 0)) |> 
  filter(TYPE != "snv") |> 
  mutate(FILTER = if_else(FILTER == "PASS", FILTER, "MASKED_other")) |> 
  mutate(BAM_VAF = if_else(BAM_VAF == 0, BAM_VAF_BQ10, BAM_VAF)) |> 
  mutate(FILTER = if_else(varCount > 0, "cohortMask", FILTER)) |> 
  mutate(target = factor(target, levels = c("targeted1", "targeted2", "exome1", "exome2", "exome3" ,"exome4"), ordered = TRUE)) |> 
  ggplot(aes(BAM_VAF, after_stat(count), fill = FILTER)) +
  scale_fill_manual(values = c('#fdb462', '#fb8072','#80b1d3')) +
  scale_x_log10() +
  geom_density(position = "stack") +
  ylab("Indel density") +
  guides(fill=guide_legend(title="Post bam filter"))+ 
  facet_wrap(~target, scales = "free_y",ncol = 6) + 
  theme_pubr() +
  theme(legend.position = "right", strip.background = element_blank())

p_cohortMask/p_cohortMaskInd

png(paste0(localPath, 'pQC_cohortMask.png'), height=7, width=14)
p_cohortMask/p_cohortMaskInd
dev.off()

```

#### PostFilter Contam
```{r postFilterContam, fig.height=7, fig.width=7}

burdensPost <- burdens |> 
  left_join(snpFilterVars |> 
              filter(TYPE %in% c("snv", "dnv", "mnv")) |> 
              group_by(Sample_PD_ID) |> summarize(mutsPost = sum(TIMES_CALLED), adjMutsPostSingle = n()) , by = "Sample_PD_ID") |> 
  mutate(burdenPost = mutsPost/total) |> 
  left_join(snpFilterVars |> 
              filter(TYPE %in% c("del", "ins")) |> 
              group_by(Sample_PD_ID) |> summarize(indelsPost = sum(TIMES_CALLED), adjIndelPostSingle = n()) , by = "Sample_PD_ID") |> 
  mutate(indelsPost = replace_na(indelsPost, 0)) |> mutate(adjIndelPostSingle = replace_na(adjIndelPostSingle, 0)) |> 
  mutate(burdenIndelPost = indelsPost/total) |> 
  mutate(adjIndelBurdenPostSingle = adjIndelPostSingle/total) 

maskedCountsPost <- allCallsTarg |> 
  left_join(anyCounts, by = c("chr", "start")) |> mutate(varCount = replace_na(varCount, 0)) |> filter(varCount == 0) |> 
  mutate(FILTER = if_else(FILTER == "PASS", FILTER, "MASKED")) |> 
  mutate(TYPE = if_else(TYPE %in% c("snv", "dnv", "mnv"), "snv", "indel")) |> 
  group_by(Sample_PD_ID, FILTER, TYPE) |> summarize(count = n(), .groups = "drop") |> 
  pivot_wider(id_cols = Sample_PD_ID, names_from = c(FILTER,TYPE), names_sep = "_", values_from = count, values_fill = 0) |> 
  left_join(targetedSamples, by = "Sample_PD_ID") |> 
  left_join(burdensPost, by = "Sample_PD_ID")|> 
  left_join(seqMetrics, by = join_by(Sample_PD_ID, PD_ID, target, ss_ID, family_ID, age_at_sampling, tissue, tissue_timepoint, twinStatus, nanoseq)) |> 
  mutate(maskedProportionPost = MASKED_snv/PASS_snv) |> 
  mutate(maskedProportionPostIndel = MASKED_indel/PASS_indel) |> 
  left_join(maskedCounts |> select(Sample_PD_ID, maskedProportion, maskedProportionIndel), by = "Sample_PD_ID") |> 
  mutate(above5 = if_else(maskedProportion > 5, T,F)) |> 
  mutate(label = if_else(tissue == "Sperm" & (maskedProportion > 5 | burdenPost > 1e-7), str_sub(PD_ID, 6,8), "")) |> 
  mutate(concern = if_else(tissue == "Sperm" & (maskedProportion > 5 |  burdenPost > 1e-7), T, F))

```

### Corrected burdens
Using shorted version of code from NanoSeq pipeline to correct burdens for trinucleotide composition (https://github.com/cancerit/NanoSeq/blob/develop/R/nanoseq_results_plotter.R)
```{r burdensCorrected}
#Write out filtered and corrected burdens
burdensCorrected0 <- burdensPost |> 
  select(Sample_PD_ID, total, muts = mutsPost,  burden = burdenPost, indels = indelsPost, indelBurden = burdenIndelPost)

# Background full genome trinuc composition
genome_counts <- tibble(trinuc = c("ACA", "ACC", "ACG", "ACT", "ATA", "ATC", "ATG", "ATT", "CCA", "CCC", "CCG", "CCT", "CTA", "CTC", "CTG", "CTT", "GCA", "GCC", "GCG", "GCT", "GTA", "GTC", "GTG", "GTT", "TCA", "TCC", "TCG", "TCT", "TTA", "TTC", "TTG", "TTT"),
                genomeCount = c(115415924, 66550070, 14381094, 92058521, 117976329, 76401029, 105094288, 142651503, 105547494, 75238490,
    15801067, 101628641, 73791042, 96335416, 115950255, 114180747, 82414099, 68090507, 13621251, 80004082,
    64915540, 54055728, 86012414, 83421918, 112085858, 88336615, 12630597, 126566213, 119020255, 112827451,
    108406418, 219915599), totalCount = 2861326455) |> 
  mutate(genomeFraction = genomeCount/totalCount)

# Trinucleotides covered per sample and ratio to full genome
tri_bg <- read_tsv(paste0(path, "postNextflow/trinuc.txt"), col_types = cols(), col_names = c("trinuc", "trinucCount", "Sample_PD_ID")) |> 
  left_join(genome_counts, by = join_by(trinuc)) |> left_join(burdensCorrected0 |> select(Sample_PD_ID, total), by = join_by(Sample_PD_ID)) |> 
  mutate(sampleFraction = trinucCount/total) |> 
  mutate(ratioToGenome = sampleFraction/genomeFraction) |> 
  select(Sample_PD_ID, trinuc, ratioToGenome)

# Observed Trinuc mutations adjusted by ratio of background to genome
burdensCorr <- snpFilterVars |> drop_na(TRI) |> filter(TRI != "NA") |> 
  group_by(TRI, Sample_PD_ID) |> summarize(count = sum(TIMES_CALLED), .groups = "drop") |> 
  mutate(trinuc = str_sub(TRI, 1, 3)) |> 
  left_join(tri_bg, by = join_by(Sample_PD_ID, trinuc)) |> 
  mutate(trint_onto_genome = count/ratioToGenome) |> 
  group_by(Sample_PD_ID) |> summarize(mutsCorr = sum(trint_onto_genome)) 

burdensCorrected <- burdensCorrected0 |> left_join(burdensCorr, by = join_by(Sample_PD_ID)) |> 
  mutate(burdenCorr = mutsCorr/total)

```

#### SNP burdens
```{r contam, fig.height=7, fig.width=10}

pPostMaskedProp <- ggplot(maskedCountsPost, aes(maskedProportion, maskedProportionPost, fill = target, label = label)) +
  geom_abline(slope=1, linetype = "dashed") +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  ylim(c(0,15)) +
  xlim(c(0,15)) +
  xlab("Pre Filter (masked SNPs / passed variants)") +
  ylab("Post Filter (masked SNPs / passed variants)") +
  theme_minimal()   +
  theme(legend.position = "none")
pPostBurdenProp <- ggplot(maskedCountsPost, aes(x = burdenMan, y = burdenPost, fill = target, label = label)) +
  geom_abline(slope=1, linetype = "dashed") +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  xlab("Pre Filter Burden") +
  ylab("Post Filter Burden") +
  theme_minimal()  +
  theme(legend.position = "none")

ggarrange(pPostMaskedProp, pPostBurdenProp)

allpostBurden <- maskedCountsPost |> 
                  pivot_longer(cols = c(burdenMan, burdenPost), names_to = "burdenType", values_to = "burdens") |> 
                  mutate(burdenType = str_replace(burdenType, "burdenMan", "burden")) 
pAllPostBurden <- allpostBurden |> 
  ggplot(aes(x =  age_at_sampling, y = burdens, fill = target, colour = target, label = label)) + 
  geom_smooth(method='lm', alpha = 0.2) +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  xlab('Age (years)') + 
  ylab('Mutations per bp') + 
  theme_minimal() + 
  ylim(0,1e-7) +
  facet_wrap(~burdenType, nrow = 2)
pAllPostBurden

((pPostMaskedProp / pPostBurdenProp  + plot_layout(guides = 'auto')) | pAllPostBurden) + plot_layout(guides = 'collect')

png(paste0(localPath, 'pQC_prePostFilterComp.png'), height=7, width=10, res = 300, unit = "in")
((pPostMaskedProp / pPostBurdenProp  + plot_layout(guides = 'auto')) | pAllPostBurden) + plot_layout(guides = 'collect')
dev.off()

```

#### ContamSummary
```{r thesisContamFig}

pPostMaskedProp2 <- ggplot(maskedCountsPost, aes(maskedProportion, maskedProportionPost, fill = target, label = label)) +
  geom_abline(slope=1, linetype = "dashed") +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  ylim(c(0,15)) +
  xlim(c(0,15)) +
  xlab("Pre Filter (masked SNPs / passed variants)") +
  ylab("Post Filter (masked SNPs / passed variants)") +
  theme_pubr()   +
  theme(legend.position = "none")

pPreContam + pPostMaskedProp2 + plot_annotation(tag_levels = 'a') + plot_layout(guides = "collect")

png(paste0(localPath, 'pQC_ContamSummary.png'), height=5, width=10)
pPreContam + pPostMaskedProp2 + plot_annotation(tag_levels = 'a') + plot_layout(guides = "collect")
dev.off()
```

#### Indel burdens
```{r contam, fig.height=7, fig.width=10}

pPostMaskedPropIndel <- ggplot(maskedCountsPost, aes(maskedProportionIndel, maskedProportionPostIndel, fill = target, label = label)) +
  geom_abline(slope=1, linetype = "dashed") +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  ylim(c(0,15)) +
  xlim(c(0,15)) +
  xlab("Pre Filter (masked Indel / passed Indel)") +
  ylab("Post Filter (masked Indel / passed Indel)") +
  theme_minimal()   +
  theme(legend.position = "none")
pPostBurdenPropIndel <- ggplot(maskedCountsPost, aes(x = indelBurden, y = burdenIndelPost, fill = target, label = label)) +
  geom_abline(slope=1, linetype = "dashed") +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  xlab("Pre Filter Indel Burden") +
  ylab("Post Filter Indel Burden") +
  theme_minimal()  +
  theme(legend.position = "none")

ggarrange(pPostMaskedPropIndel, pPostBurdenPropIndel)

allpostBurdenIndel <- maskedCountsPost |> dplyr::rename(indelBurdenPost = burdenIndelPost) |> 
                  pivot_longer(cols = c(indelBurden, indelBurdenPost), names_to = "burdenType", values_to = "burdens")
pAllPostBurdenIndel <- allpostBurdenIndel |> 
  ggplot(aes(x =  age_at_sampling, y = burdens, fill = target, colour = target, label = label)) + 
  geom_smooth(method='lm', alpha = 0.2) +
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  xlab('Age (years)') + 
  ylab('Mutations per bp') + 
  theme_minimal() + 
  ylim(0,NA) +
  facet_wrap(~burdenType, nrow = 2, scales = "free_y")
pAllPostBurdenIndel

((pPostMaskedPropIndel / pPostBurdenPropIndel  + plot_layout(guides = 'auto')) | pAllPostBurdenIndel) + plot_layout(guides = 'collect')

png(paste0(localPath, 'pQC_prePostFilterCompIndel.png'), height=7, width=10, res = 300, unit = "in")
((pPostMaskedPropIndel / pPostBurdenPropIndel  + plot_layout(guides = 'auto')) | pAllPostBurdenIndel) + plot_layout(guides = 'collect')
dev.off()

```


## d) Sperm Counts
```{r contam, fig.height=7, fig.width=7}

# Calculate concentration in M/ml (million per ml)
spermCounts <- read_xlsx("~/Google Drive/My Drive/Sperm/nanoSampleMeta/spermCounting.xlsx") |> 
  drop_na() |> 
  mutate(sperm_conc = (SpermCount/SpermRows) * 1/20 * Dilution) |> 
  select(PD_ID, sperm_conc) |> 
  mutate(spermCategory = if_else(sperm_conc >= 15, "Normal", "Oligospermia")) |> 
  mutate(spermCategory = if_else(sperm_conc == 0, "Azoospermia", spermCategory)) |> 
  left_join(targetedSamples |> select(PD_ID, Sample_PD_ID, age_at_sampling), by = "PD_ID") |> 
  drop_na() |> mutate(spermCategory = fct_relevel(spermCategory, c("Oligospermia", "Normal"))) |> 
  mutate(source = "TwinsUK")


spermCats <- tibble(spermCategory = c("Azoospermia", "Oligospermia", "Normal"),
                    xmins = c(0,1,15),
                    xmaxs = c(0.99,14.99,Inf)) |>
  mutate(spermCategory = fct_relevel(spermCategory, c("Azoospermia", "Oligospermia", "Normal")))

set.seed(17)
pSpermCountsDist <- ggplot(spermCounts) + 
  geom_rect(data = spermCats, aes(xmin = xmins, xmax = xmaxs, ymin = -Inf, ymax = Inf, fill = spermCategory), alpha = 0.2) + 
  geom_jitter(data = spermCounts, aes(sperm_conc, source, fill = spermCategory), size=3, pch=21, col='white', stroke=0.25) +
  
  theme_minimal() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank()) +
  xlab("Sperm Concentration (million/mL)")
pSpermCountsDist

pSpermCountTarg <- ggplot(maskedCountsPost |> filter(tissue == "Sperm") |> left_join(spermCounts), aes(x = age_at_sampling, y = burdenPost, fill = spermCategory,  label = label)) + 
  geom_point(size=3, pch=21, col='white', stroke=0.25) +
  geom_text_repel(colour = "grey60",
                  arrow = arrow(angle = 0, length = unit(0.02, "npc")),
                box.padding = 1, max.overlaps = Inf) +
  xlab('Age (years)') + 
  ylab('Mutations per bp') + 
  theme_minimal() + 
  ylim(0,NA)
ggarrange(pSpermCountsDist, pSpermCountTarg, nrow = 2, heights = c(1,2))

png(paste0(localPath, 'pQC_preSpermCounts.png'), height=7, width=7, res = 300, units = "in")
ggarrange(pSpermCountsDist, pSpermCountTarg, nrow = 2, heights = c(1,2))
dev.off()
```

## e) Passed QC
Samples/variants allowed to progress to main analyses
```{r passQC}
targSamplesPassingQC <- maskedCountsPost |> 
  # comment out sampleID for public code
  pull(Sample_PD_ID) 

targetedSamplesFiltered <- targetedSamples |> 
  filter(Sample_PD_ID %in% targSamplesPassingQC) 

#Write out filtered metadata locally
write_tsv(targetedSamplesFiltered |> 
  mutate(indiv_ID = str_sub(PD_ID, 1,7)) , paste0(metaPath,"targetedSamplesFiltered.tsv"))

#Write out filtered sample list on farm
write_tsv(targetedSamplesFiltered |> select(Sample_PD_ID, PD_ID, ss_ID, tissue, target), paste0(path,"targetedSamplesFiltered.txt"), col_names = F)

#Write out filtered variant list
write_tsv(snpFilterVars |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID), paste0(paperPath, "data/snpFilterVars.tsv"))

#Write out filtered burden
write_tsv(burdensCorrected |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID), paste0(paperPath, "data/burdensFiltered.tsv"))
```

### VEP input files
#### Output vars
```{r vep}
# Format to annotated with VEP then read back in annotated and merge to original file
vepInputTjoint <- read_tsv(paste0(paperPath, "data/snpFilterVars.tsv"), col_types = cols()) |> 
  mutate(blank = ".") |> 
  # ID useful for joining indels back up
  mutate(id = paste(chr,start,ref,alt, sep = "_")) |> 
  select(chr, start, id, ref, alt, blank2 = blank, blank3 = blank, blank4 = blank) |> 
  arrange(chr, as.numeric(start)) 

write_tsv(vepInputTjoint, paste0(path, "postNextflow/vep/filteredTargVars.vcf"), col_names = F) 

# Write out for sigs with IDs
sigInputTjoint <- read_tsv(paste0(paperPath, "data/snpFilterVars.tsv"), col_types = cols()) |> 
  mutate(blank = ".") |> 
  # ID useful for joining indels back up
  mutate(id = paste(chr,start,ref,alt,Sample_PD_ID, sep = "_")) |> 
  select(chr, start, id, ref, alt, blank2 = blank, blank3 = blank, blank4 = blank) |> 
  arrange(chr, as.numeric(start)) 

write_tsv(sigInputTjoint, paste0(path, "postNextflow/vep/sigInput.vcf"), col_names = F) 
```

#### Check high vaf variants before filtering
```{r variants}
# Check variants just above cutoff
over1vars <- allCallsTarg0 |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID) |> 
  left_join(anyCounts, by = c("chr", "start")) |> 
  mutate(varCount = replace_na(varCount, 0)) |> 
  filter(varCount == 0 & FILTER == "PASS") |> 
  filter(BAM_VAF > 0.01 | DUPLEX_VAF >= 0.1 ) |> 
  mutate(blank = ".") |> 
  # ID useful for joining indels back up
  mutate(id = paste(chr,start,ref,alt, sep = "_")) |> 
  select(chr, start, id, ref, alt, blank2 = blank, blank3 = blank, blank4 = blank) |> 
  arrange(chr, as.numeric(start)) |> 
  distinct()

write_tsv(over1vars, paste0(path, "postNextflow/vep/over1Vars.vcf"), col_names = F) 
```

#### Check contam variants
``` {r contamVars}

contamVars <- allCallsTarg0 |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID) |> 
  left_join(anyCounts, by = c("chr", "start")) |> 
  mutate(varCount = replace_na(varCount, 0)) |> 
  filter((varCount > 0  | is.na(DUPLEX_COV))& FILTER == "PASS") |> 
  mutate(blank = ".") |> 
  # ID useful for joining indels back up
  mutate(id = paste(chr,start,ref,alt, sep = "_")) |> 
  select(chr, start, id, ref, alt, blank2 = blank, blank3 = blank, blank4 = blank) |> 
  arrange(chr, as.numeric(start))  |> 
  distinct()

write_tsv(contamVars, paste0(path, "postNextflow/vep/contamVars.vcf"), col_names = F) 

```

# 4. Analysis Files
## a) Coverage
### i) Main
#### Indiv cov stats
```{bash covStats}
#Make different coverage file versions including:
#A) Remove manually masked sites from coverage
#B) Format files to remove trinuc context then sort
#C) Restrict to targeted regions for inPanel cov stats

#T1
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm cov/jobLogs/sumCov*
for sample in `grep "targeted1" ../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o cov/jobLogs/sumCov.$sample.out -e cov/jobLogs/sumCov.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; bedtools subtract -a cov/source/$sample.cov.bed -b ../contamFilter/toMaskGerm.bed > cov/masked/$sample.cov.bed; sed 's/;/\t/g' cov/masked/$sample.cov.bed | cut -f 1-3,6 | sort -T tmp -k1,1 -k2,2n > cov/targCut/$sample.cov.bed; bedtools intersect -a cov/targCut/$sample.cov.bed -b ../genomicRegions/twist-small_panel-v1.bed > cov/inPanel/$sample.inPanelCov.bed"
done

#T2
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
for sample in `grep "targeted2" ../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o cov/jobLogs/sumCov.$sample.out -e cov/jobLogs/sumCov.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; bedtools subtract -a cov/source/$sample.cov.bed -b ../contamFilter/toMaskGerm.bed > cov/masked/$sample.cov.bed; sed 's/;/\t/g' cov/masked/$sample.cov.bed | cut -f 1-3,6 | sort -T tmp -k1,1 -k2,2n > cov/targCut/$sample.cov.bed; bedtools intersect -a cov/targCut/$sample.cov.bed -b ../genomicRegions/panelV2.bed > cov/inPanel/$sample.inPanelCov.bed"
done

#EX
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
for sample in `grep "exome" ../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o cov/jobLogs/sumCov.$sample.out -e cov/jobLogs/sumCov.$sample.err -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M 100000 "module load bedtools;  bedtools subtract -a cov/source/$sample.cov.bed -b ../contamFilter/toMaskGerm.bed > cov/masked/$sample.cov.bed; sed 's/;/\t/g' cov/masked/$sample.cov.bed | cut -f 1-3,6 | sort -T tmp -k1,1 -k2,2n > cov/exCut/$sample.cov.bed; bedtools intersect -a cov/exCut/$sample.cov.bed -b ../genomicRegions/exomePanel_humgen_twist.bed > cov/inPanel/$sample.inPanelCov.bed"
done

#calc covstats
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
nano statsCoverage.sh

#!/bin/bash
sample="$1"
bpUnique=$(wc -l *ut/$sample.cov.bed | awk '{print $1}')
bpTotal=$(awk -F '\t' '{sum+=$4;}END{print sum;}' *ut/$sample.cov.bed)
bpMedian=$(cat *ut/$sample.cov.bed | datamash -s median 4 )
bpUniquePanel=$(wc -l inPanel/$sample.inPanelCov.bed | awk '{print $1}')
bpTotalPanel=$(awk -F '\t' '{sum+=$4;}END{print sum;}' inPanel/$sample.inPanelCov.bed)
bpMedianPanel=$(cat inPanel/$sample.inPanelCov.bed | datamash -s median 4 )
echo "${sample} ${bpUnique} ${bpTotal} ${bpMedian} ${bpUniquePanel} ${bpTotalPanel} ${bpMedianPanel}" > covStats/$sample.stats.tsv

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
rm jobLogs/covStats.*
for sample in `cut -f1 ../../targetedSamplesFiltered.txt`;
  do echo $sample
  bsub -q normal -o jobLogs/covStats.$sample.out -e jobLogs/covStats.$sample.err -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M 20000 ./statsCoverage.sh $sample
done

#Group results for all
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm statsCoverage.tsv
for sample in `cut -f1 ../targetedSamplesFiltered.txt`;
  do echo $sample
  cat cov/covStats/$sample.stats.tsv >> statsCoverage.tsv
done
```

#### Basic cov
```{r basicCov}
#Coverage summary
covSummaryTarg <- read_delim(paste0(path, "postNextflow/statsCoverage.tsv"), delim = " ", col_types = cols(), col_names = c("Sample_PD_ID", "bpUnique","bpTotal", "bpMedian", "bpUniquePanel","bpTotalPanel", "bpMedianPanel")) |>
  left_join(targetedSamplesFiltered  |> select(Sample_PD_ID, PD_ID, target, age_at_sampling, nanoseq, tissue, tissue_timepoint), by = "Sample_PD_ID") |> 
  mutate(percentGenomeCov = bpUnique/2867437753 * 100) |> 
  mutate(avgDuplexCov = bpTotal/bpUnique) |> 
  mutate(percentGenomeCovPanel = bpUniquePanel/2867437753 * 100) |> 
  mutate(avgDuplexCovPanel = bpTotalPanel/bpUniquePanel) |> 
  mutate(tissue_timepoint = as.factor(tissue_timepoint))

covSummaryTargMerged <- covSummaryTarg |> 
  # Merge targeted 1 with targeted 2 replicates
  group_by(PD_ID, nanoseq, age_at_sampling) |> summarize(bpUnique = max(bpUnique), bpTotal = sum(bpTotal), bpUniquePanel = max(bpUniquePanel), bpTotalPanel = sum(bpTotalPanel), .groups = "drop") |> 
  mutate(percentGenomeCov = bpUnique/2867437753 * 100) |> 
  mutate(avgDuplexCov = bpTotal/bpUnique) |> 
  mutate(percentGenomeCovPanel = bpUniquePanel/2867437753 * 100) |> 
  mutate(avgDuplexCovPanel = bpTotalPanel/bpUniquePanel) 

write_tsv(covSummaryTarg, paste0(paperPath, "data/covSummaryTarg.tsv"))
write_tsv(covSummaryTargMerged, paste0(paperPath, "data/covSummaryTargMerged.tsv"))
```

#### Full cohort cov
```{bash covSums}
#Make summary files with coverage for all indivs at all positions then Get sum of coverage at each site

#Script
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
nano getTotalCov.sh

#!/bin/bash

#Targ
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/targCut
module load bedtools
bedtools unionbedg -i $(ls *.bed) -header -names $(ls *.bed) > ../summaryCov.bed
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
awk 'OFS="\t" {sum=0; for (col=4; col<=NF; col++) sum += $col; print $1, $2, $3, sum;}' summaryCov.bed | tail -n +2 > totalCov.bed

#Ex
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/exCut
bedtools unionbedg -i $(ls *.bed) -header -names $(ls *.bed) > ../exomeSummaryCov.bed
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
awk 'OFS="\t" {sum=0; for (col=4; col<=NF; col++) sum += $col; print $1, $2, $3, sum;}' exomeSummaryCov.bed | tail -n +2 > exomeTotalCov.bed

#Merge
cat totalCov.bed exomeTotalCov.bed | sort -T tmp -k1,1 -k2,2n | bedtools merge -d -1 -c 4 -o sum > totalCovMerged.bed

#Submit
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
bsub -q long -o jobLogs/sumCov.%J.out -e jobLogs/sumCov.%J.err -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 ./getTotalCov.sh

```

#### TriNuc Annotation
```{bash trinucCov}

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/triNuc
nano triNucBed.sh
#!/bin/bash
# Targeted
rm triNucLong.txt
for sample in `grep "targeted" ../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  cut -f 1 -d ";" ../cov/masked/$sample.cov.bed | cut -f 1,3,4 >> triNucLong.txt
done

sort -T tmp -k1,1 -k2,2n triNucLong.txt | uniq > triNucUniq.txt

# Exome
rm triNucLongEx.txt
for sample in `grep "exome" ../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  cut -f 1 -d ";" ../cov/masked/$sample.cov.bed | cut -f 1,3,4 >> triNucLongEx.txt
done

sort -T tmp -k1,1 -k2,2n triNucLongEx.txt | uniq > triNucUniqEx.txt

# Merged
cat triNucUniqEx.txt triNucUniq.txt | sort -T tmp -k1,1 -k2,2n | uniq > triNucUniqMerged.txt

#Convert to bed for VEP
cat triNucUniqMerged.txt | awk 'BEGIN {FS="\t"; OFS="\t"} {print  $1, $2-1, $2, $3}' | bgzip -c > triNucUniqMerged.bed.gz
tabix -p bed triNucUniqMerged.bed.gz


cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/triNuc
bsub -o jobLogs/triNuc.%J.out -e jobLogs/triNuc.%J.err -q long -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 ./triNucBed.sh
```

### ii) Coding regions
#### Generate Coding Regions/Pos selected genes regions
##### Part in R
```{r covCoding}

codingRegions <- read_tsv(paste0(path, "genomicRegions/gencode.v40lift37.basic.annotation.gtf.gz"), comment = "#", col_names = c("chr", "type", "start", "stop"), col_types = 'c-cdd----') |> 
  filter(type %in% c("CDS", "start_codon", "stop_codon")) |> 
  mutate(chr = str_remove(chr,"chr")) |> 
  # Subtract 1 for bed and 2 for splice sites
  mutate(bedStart = start - 3) |> 
  mutate(bedStop = stop + 2) |>
  select(chr, bedStart, bedStop)

write_tsv(codingRegions, paste0(path, "genomicRegions/codingRegions19_unsorted.bed"), col_names = F)


posSelectGenes <- read_tsv(paste0(dndsPath, "sigGenes.tsv"), col_types = cols()) |> distinct(gene_name)

codingRegionsPosSelectGenes <- read_tsv(paste0(path, "genomicRegions/gencode.v40lift37.basic.annotation.gtf.gz"), comment = "#", col_names = c("chr", "type", "start", "stop", "gene"), col_types = 'c-cdd---c') |> 
  filter(type %in% c("CDS", "start_codon", "stop_codon")) |> 
  mutate(gene = str_remove(gene, ".*gene_name \"")) |> 
  mutate(gene = str_remove(gene, "\".*")) |> 
  filter(gene %in% posSelectGenes$gene_name) |> 
  mutate(chr = str_remove(chr,"chr")) |> 
  # Subtract 1 for bed and 2 for splice sites
  mutate(bedStart = start - 3) |> 
  mutate(bedStop = stop + 2) |>
  select(chr, bedStart, bedStop)

write_tsv(codingRegionsPosSelectGenes, paste0(path, "genomicRegions/codingRegionsPosGenes19_unsorted.bed"), col_names = F)
```

##### Part in bash
```{bash covCoding}
#Sort coding regions file
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/genomicRegions
module load bedtools; sort -T tmp -k1,1 -k2,2n codingRegions19_unsorted.bed | bedtools merge >  codingRegions19.bed
module load bedtools; sort -T tmp -k1,1 -k2,2n codingRegionsPosGenes19_unsorted.bed | bedtools merge >  codingRegionsPosGenes19.bed
```

### iii) Trinuc coding burden
#### Script to sum trinucletotides
```{bash sumTri}
#!/bin/bash

# Initialize an associative array to store the sums for each 3-letter code
declare -A code_sums

# Read the input from stdin
while IFS=';' read -r code value; do
    # Add the value to the sum for the code
    code_sums["$code"]=$((code_sums["$code"] + value))
done

# Write the results to the output file
for code in "${!code_sums[@]}"; do
  echo "$code;${code_sums["$code"]}"
done
```

#### Coding TriNuc bash
```{bash covCoding}

#Run script per sample full and posGenes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding
rm ../jobLogs/codingTri*
for sample in `cat ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o ../jobLogs/codingTri.$sample.out -e ../jobLogs/codingTri.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; bedtools intersect -a ../masked/$sample.cov.bed -b ../../../genomicRegions/codingRegionsPosGenes19.bed -wa | cut -f4 | cut -f 1,3 -d ';' | ./triCountCoding.sh > $sample.tri.posGenes.txt; bedtools intersect -a ../masked/$sample.cov.bed -b ../../../genomicRegions/codingRegions19.bed -wa | cut -f4 | cut -f 1,3 -d ';' | ./triCountCoding.sh > $sample.tri.coding.txt"
  done


# Group results
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding
rm triCodingCov.txt
rm triCodingCovPosGenes.txt
for sample in `cat ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  sed "s/$/;$sample/" $sample.tri.coding.txt >> triCodingCov.txt
  sed "s/$/;$sample/" $sample.tri.posGenes.txt >> triCodingCovPosGenes.txt
done
```

#### Run on genomes
```{r genomesCod}
REvars <- read_tsv(paste0("/Users/mn7/volumes/mn7_lustre/sperm/re_nanoseq/","twinsUK/output/variantsFiltered.tsv"), col_types = cols()) |> 
  distinct(chr, start) |> 
  mutate(end = start) |> mutate(start = end-1)
write_tsv(REvars, paste0(path, "postNextflow/cov/covCoding/genomes/genomeVars.bed"), col_names = F)
```

##### Genomes bash
```{bash genomesCov}
#Run script per sample full and posGenes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding
rm ../cov/jobLogs/codingGenomes*
for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
  do echo $sample
  bsub -o ../jobLogs/codingGenomes.$sample.out -e ../jobLogs/codingGenomes.$sample.err -q long -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "module load bedtools; gunzip -c /lustre/scratch126/casm/team294rr/mn7/sperm/NanoSeq/Nextflow/outNextflow/NanoSeq/$sample/post/$sample.cov.bed.gz > genomes/$sample.cov.bed; bedtools intersect -a genomes/$sample.cov.bed -b ../../../genomicRegions/codingRegions19.bed -wa | cut -f4 | cut -f 1,3 -d ';' | ./triCountCoding.sh > genomes/$sample.tri.txt"
done

# Group results
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding/genomes
rm triCodingCovGenomes.txt
for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
do echo $sample
  sed "s/$/;$sample/" $sample.tri.txt >> triCodingCovGenomes.txt
done
```

#### Variant Coding Annot
```{bash covCoding}
#Targeted
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding
module load bedtools; sort -T tmp -k1,1 -k2,2n ../../../contamFilter/allCallsTarg.bed > allCallsTarg.sorted.bed
module load bedtools; bedtools intersect -a allCallsTarg.sorted.bed -b ../../../genomicRegions/codingRegionsPosGenes19.bed > vars.codingPosGenes.bed
bedtools intersect -a allCallsTarg.sorted.bed -b ../../../genomicRegions/codingRegions19.bed > vars.coding.bed

#Genomes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding
module load bedtools; sort -T tmp -k1,1 -k2,2n genomes/genomeVars.bed >  genomes/genomeVarsSorted.bed
module load bedtools; bedtools intersect -a genomes/genomeVarsSorted.bed -b ../../../genomicRegions/codingRegionsPosGenes19.bed > genomes/varsGenome.codingPosGenes.bed
bedtools intersect -a genomes/genomeVarsSorted.bed -b ../../../genomicRegions/codingRegions19.bed > genomes/varsGenome.coding.bed
```

#### Process coding R
```{r covCodingProcess}
# Background full genome trinuc composition
genome_counts <- tibble(tri = c("ACA", "ACC", "ACG", "ACT", "ATA", "ATC", "ATG", "ATT", "CCA", "CCC", "CCG", "CCT", "CTA", "CTC", "CTG", "CTT", "GCA", "GCC", "GCG", "GCT", "GTA", "GTC", "GTG", "GTT", "TCA", "TCC", "TCG", "TCT", "TTA", "TTC", "TTG", "TTT"),
                genomeCount = c(115415924, 66550070, 14381094, 92058521, 117976329, 76401029, 105094288, 142651503, 105547494, 75238490,
    15801067, 101628641, 73791042, 96335416, 115950255, 114180747, 82414099, 68090507, 13621251, 80004082,
    64915540, 54055728, 86012414, 83421918, 112085858, 88336615, 12630597, 126566213, 119020255, 112827451,
    108406418, 219915599), totalCount = 2861326455) |> 
  mutate(genomeFraction = genomeCount/totalCount)

# For converting tri to pyr context
trinucConvert <- analysisTargVars |> mutate(tri = str_sub(TRI, 1,3)) |> 
  distinct(tri, trinuc) |> drop_na() |> dplyr::rename(tri0 = trinuc)

reSamples <- read_tsv(paste0(metaPath,"reSamplesTwinsUKFiltered.tsv"), col_types = cols()) |> filter(tissue == "Sperm")

# Counts coding and non-coding
triCodingCov <- read_tsv(paste0(path, "postNextflow/trinuc.txt"), col_types = cols(), col_names = c("tri", "trinucAll", "Sample_PD_ID")) |> 
  filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID) |> mutate(nanoseq = "targeted") |> 
  bind_rows(read_tsv("/Users/mn7/volumes/mn7_lustre/sperm/re_nanoseq/twinsUK/postNextflow/trinuc.txt", col_types = cols(), col_names = c("tri", "trinucAll", "Sample_PD_ID")) |> 
  filter(Sample_PD_ID %in% reSamples$PD_ID) |> mutate(nanoseq = "genome")) |> 
  # Add coding
  left_join(read_delim(paste0(path, "postNextflow/cov/covCoding/triCodingCov.txt"), delim = ";", col_names = c("tri0", "trinucCoding", "Sample_PD_ID"), col_types = 'cdc') |> bind_rows(read_delim(paste0(path, "postNextflow/cov/covCoding/genomes/triCodingCovGenomes.txt"), delim = ";", col_names = c("tri0", "trinucCoding", "Sample_PD_ID"), col_types = 'cdc')) |> 
              # Add pyr context
              left_join(trinucConvert, by = join_by(tri0)) |> select(-tri0) |> 
              group_by(tri, Sample_PD_ID) |> summarize(trinucCoding = sum(trinucCoding), .groups = "drop"), by = join_by(tri, Sample_PD_ID)) |> 
  mutate(trinucNonCoding = trinucAll - trinucCoding) |> 
  left_join(read_delim(paste0(path, "postNextflow/cov/covCoding/triCodingCovPosGenes.txt"), delim = ";", col_names = c("tri", "trinucCodingPosGene", "Sample_PD_ID"), col_types = 'cdc'), by = join_by(tri, Sample_PD_ID)) |> 
  # Split off coding for targeted genes in pos select genes but use same for genomes
  mutate(trinucAll_NoPos = if_else(nanoseq == "targeted", trinucAll - trinucCodingPosGene, trinucAll)) |> 
  mutate(trinucCodingOther = if_else(nanoseq == "targeted", trinucCoding - trinucCodingPosGene, trinucCoding)) |> 
  pivot_longer(cols = starts_with("trinuc"), names_to = "region", names_prefix = "trinuc", values_to = "trinucCount") |> 
  # Add whole genome fractions
  left_join(genome_counts, by = join_by(tri)) 

# Get total counts
totals <- triCodingCov |> group_by(Sample_PD_ID, region) |> summarize(total = sum(trinucCount), .groups = "drop")

# Calculate ratios
triCodingRatios <- triCodingCov |> 
  left_join(totals, by = join_by(Sample_PD_ID, region)) |> 
  mutate(sampleFraction = trinucCount/total) |> 
  mutate(ratioToGenome = sampleFraction/genomeFraction) |> 
  # mutate(ratioToGenome = 1) |>
  select(Sample_PD_ID, region, tri, ratioToGenome) |> 
  filter(region != "All") |> 
  drop_na()

# Observed Trinuc mutations adjusted by ratio of background to genome
burdenCodingCorr0 <- analysisTargVars |> filter(TYPE == "snv")|>
  left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/vars.coding.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(region = "CodingOther"), by = join_by(chr, start)) |> 
  mutate(region = replace_na(region, "NonCoding")) |> 
  left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/vars.codingPosGenes.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(selectGene = T), by = join_by(chr, start)) |> 
  mutate(selectGene = replace_na(selectGene, F)) |> 
  mutate(region = if_else(selectGene, "CodingPosGene", region)) |> 
  # Add genomes
  bind_rows(read_tsv(paste0("/Users/mn7/volumes/mn7_lustre/sperm/re_nanoseq/","twinsUK/output/variantsFiltered.tsv"), col_types = cols()) |>
              filter(TYPE == "snv" & PD_ID %in% reSamples$PD_ID) |>  
              left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/genomes/varsGenome.coding.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(region = "CodingOther"), by = join_by(chr, start)) |> 
  mutate(region = replace_na(region, "NonCoding")) |> mutate(Sample_PD_ID = PD_ID)) 

burdenCodingCorr1 <- burdenCodingCorr0 |> 
  # Full coding
  bind_rows(burdenCodingCorr0 |> filter(region %in% c("CodingPosGene","CodingOther")) |> mutate(region = "Coding")) |> 
  # All_noPos
  bind_rows(burdenCodingCorr0 |> filter(region %in% c("NonCoding","CodingOther")) |> mutate(region = "All_NoPos")) |> 
  group_by(TRI, region, Sample_PD_ID) |> summarize(count = sum(TIMES_CALLED), .groups = "drop") |> 
  mutate(tri = str_sub(TRI, 1, 3)) |> 
  left_join(triCodingRatios, by = join_by(Sample_PD_ID, tri, region)) |> 
  mutate(trint_onto_genome = count/ratioToGenome) |> 
  drop_na() |> 
  group_by(Sample_PD_ID, region) |> summarize(muts = sum(count), mutsCorr = sum(trint_onto_genome), .groups = "drop") |> 
  left_join(totals, by = join_by(Sample_PD_ID, region)) |> 
  mutate(burden = muts/total) |> 
  mutate(burdenCorr = mutsCorr/total) |> 
  select(Sample_PD_ID, region, burden, burdenCorr) |> 
  complete(Sample_PD_ID, region, fill = list(burden = 0, burdenCorr = 0)) 

burdenCodingCorr <- burdenCodingCorr1 |> select(-burden) |> 
  pivot_wider(names_from = region, names_prefix = "burden", values_from = burdenCorr)

burdenCoding <- burdenCodingCorr1 |> select(-burdenCorr) |> 
  pivot_wider(names_from = region, names_prefix = "burden", values_from = burden)

write_tsv(burdenCoding,  paste0(paperPath, "data/burdensCoding.tsv"))
write_tsv(burdenCodingCorr,  paste0(paperPath, "data/burdensCodingCorr.tsv"))
```

#### Process Indel coding R
```{r covCodingProcessIndel}

# Observed Trinuc mutations adjusted by ratio of background to genome
burdenCodingIndel0 <- analysisTargVars |> filter(TYPE %in% c("ins", "del")) |>
  left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/vars.coding.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(region = "CodingOther"), by = join_by(chr, start)) |> 
  mutate(region = replace_na(region, "NonCoding")) |> 
  left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/vars.codingPosGenes.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(selectGene = T), by = join_by(chr, start)) |> 
  mutate(selectGene = replace_na(selectGene, F)) |> 
  mutate(region = if_else(selectGene, "CodingPosGene", region)) |> 
  # Add genomes
  bind_rows(read_tsv(paste0("/Users/mn7/volumes/mn7_lustre/sperm/re_nanoseq/","twinsUK/output/variantsFiltered.tsv"), col_types = cols()) |>
              filter(TYPE %in% c("ins", "del") & PD_ID %in% reSamples$PD_ID) |>  
              left_join(read_tsv(paste0(path, "postNextflow/cov/covCoding/genomes/varsGenome.coding.bed"), col_names = c("chr", "start"), col_types = 'c-d') |> mutate(region = "CodingOther"), by = join_by(chr, start)) |> 
  mutate(region = replace_na(region, "NonCoding")) |> mutate(Sample_PD_ID = PD_ID)) 

burdenCodingIndel<- burdenCodingIndel0 |> 
  # Full coding
  bind_rows(burdenCodingIndel0 |> filter(region %in% c("CodingPosGene","CodingOther")) |> mutate(region = "Coding")) |> 
  # All_noPos
  bind_rows(burdenCodingIndel0 |> filter(region %in% c("NonCoding","CodingOther")) |> mutate(region = "All_NoPos")) |> 
  group_by(Sample_PD_ID, region) |> summarize(muts = sum(TIMES_CALLED), .groups = "drop") |> 
  left_join(totals, by = join_by(Sample_PD_ID, region)) |> 
  mutate(burden = muts/total) |> 
  select(Sample_PD_ID, region, burden) |> 
  complete(Sample_PD_ID, region, fill = list(burden = 0)) |> 
  pivot_wider(names_from = region, names_prefix = "indelBurden", values_from = burden)


write_tsv(burdenCodingIndel,  paste0(paperPath, "data/burdenCodingIndel.tsv"))

```

#### compare Trinuc
```{r targBurden, fig.height=5, fig.width=7}
target_colours <- c("Targeted" = "#CC5800",
                     "Exome" = "#FFAD66",
                    "Genome" = "#52C4CC")
# Create a data frame from the trinucleotide frequencies
trinucleotide_df0 <-  burdenCodingCorr0 |> bind_rows(burdenCodingCorr0 |> filter(region %in% c("CodingPosGene","CodingOther")) |> mutate(region = "Coding")) |> mutate(nanoseq = replace_na(nanoseq, "Genome")) |> 
  group_by(TRI,region, nanoseq) |> summarize (count = sum(TIMES_CALLED), .groups = "drop") |> 
  complete(TRI,region, nanoseq, fill = list(count = 0)) |> 
  mutate(mutType = paste0(str_sub(TRI, 2, 2),str_sub(TRI, 4,5))) |> drop_na() |> 
  mutate(mutType = if_else(str_detect(TRI, "CG>T"), "CpG>T", mutType)) |> 
  filter(region %in% c("NonCoding","Coding"))

sumTRI <- trinucleotide_df0 |> group_by(nanoseq, region) |> summarise(total = sum(count), .groups = "drop")

p_Tri3 <- trinucleotide_df0 |> left_join(sumTRI, by = join_by(region, nanoseq)) |> 
  group_by(mutType, nanoseq, total, region) |> summarize(count = sum(count), .groups = "drop")|> 
  mutate(prop = count/total) |> mutate(nanoseq = fct_relevel(nanoseq, c("Targeted", "Exome",  "Genome"))) |> 
  ggplot(aes(x = nanoseq, y = prop, fill = region)) +
  geom_point(position = position_dodge(width = 0.5), size=3.5, pch=21, col='white', stroke=0.25) + 
  # scale_fill_manual(values = target_colours,  name = "NanoSeq type") +
  xlab("Mutation Type") +
  ylab("Proportion") +
  facet_wrap(~mutType, scales = "free_x") +
  ylim(0,NA) +
  theme_pubr() + 
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))
p_Tri3


triCovRegionsSummary <- triCodingCov |> select(tri, Sample_PD_ID, region, trinucCount) |> 
  mutate(trinucCount = replace_na(trinucCount, 0)) |> 
  left_join(targetedSamplesFiltered |> select(Sample_PD_ID, nanoseq), by = join_by(Sample_PD_ID)) |> 
  mutate(nanoseq = replace_na(nanoseq, "Genome")) |> 
  group_by(nanoseq, region, tri) |> summarize(trinucCount = sum(trinucCount), .groups = "drop") 

tri_df_mutRate <- trinucleotide_df0 |> mutate(tri = str_sub(TRI, 1,3)) |> 
  left_join(triCovRegionsSummary, by = join_by(region, nanoseq, tri)) |> 
  group_by(mutType, nanoseq, region) |> summarize(count = sum(count), trinucCount = sum(trinucCount), .groups = "drop") |> 
  mutate(rate = count/trinucCount)

p_TrimutRate <- ggplot(tri_df_mutRate |> mutate(nanoseq = fct_relevel(nanoseq, c("Targeted", "Exome",  "Genome"))), aes(x = mutType, y = rate, fill = nanoseq)) +
  geom_point(position = position_dodge(width = 0.5), size=3.5, pch=21, col='white', stroke=0.25) + 
  scale_fill_manual(values = target_colours,  name = "NanoSeq type") +
  xlab("Mutation Type") +
  ylab("Mutation Rate") +
  facet_wrap(~region, scales = "free_x") +
  ylim(0,NA) +
  theme_pubr() + 
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))
p_TrimutRate

```

#### compare Trinuc Syn
```{r targBurden, fig.height=5, fig.width=7}
target_colours <- c("Targeted" = "#CC5800",
                     "Exome" = "#FFAD66",
                    "Genome" = "#52C4CC")
# Create a data frame from the trinucleotide frequencies
trinucleotide_df0 <- burdenCodingCorr0 |> bind_rows(burdenCodingCorr0 |> filter(region %in% c("CodingPosGene","CodingOther")) |> mutate(region = "Coding")) |> mutate(nanoseq = replace_na(nanoseq, "Genome")) |> 
  group_by(TRI,region, nanoseq) |> summarize (count = sum(TIMES_CALLED), .groups = "drop") |> 
  complete(TRI,region, nanoseq, fill = list(count = 0)) |> 
  mutate(mutType = paste0(str_sub(TRI, 2, 2),str_sub(TRI, 4,5))) |> drop_na() |> 
  mutate(mutType = if_else(str_detect(TRI, "CG>T"), "CpG>T", mutType)) |> 
  filter(region %in% c("NonCoding","Coding")) |> filter(nanoseq != "Genome")

sumTRI <- trinucleotide_df0 |> group_by(region) |> summarise(total = sum(count), .groups = "drop")

triCovRegionsSummary <- triCodingCov |> select(tri, Sample_PD_ID, region, trinucCount) |> 
  mutate(trinucCount = replace_na(trinucCount, 0)) |> 
  left_join(targetedSamplesFiltered |> select(Sample_PD_ID, nanoseq), by = join_by(Sample_PD_ID)) |> 
  mutate(nanoseq = replace_na(nanoseq, "Genome")) |> 
  group_by(nanoseq, region, tri) |> summarize(trinucCount = sum(trinucCount), .groups = "drop") |> 
  filter(nanoseq != "Genome") |> group_by(region, tri) |> summarize(trinucCount = sum(trinucCount)) |> 
  filter(region %in% c("Coding", "NonCoding"))

tri_df_mutRate <- trinucleotide_df0 |> mutate(tri = str_sub(TRI, 1,3)) |> 
  left_join(triCovRegionsSummary, by = join_by(region, tri)) |> 
  group_by(mutType, region) |> summarize(count = sum(count), trinucCount = sum(trinucCount), .groups = "drop") |> 
  mutate(rate = count/trinucCount)

p_TrimutRate <- ggplot(tri_df_mutRate, aes(x = mutType, y = rate, fill = region)) +
  geom_point(position = position_dodge(width = 0.5), size=3.5, pch=21, col='white', stroke=0.25) + 
  xlab("Mutation Type") +
  ylab("Mutation Rate") +
  ylim(0,NA) +
  theme_pubr() + 
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))
p_TrimutRate

```

#### Coding region coverage + trinuc files
```{bash codingRegionCovTrinuc}
# Use coding regions to generate coding region specific versions of coverage and trinucleotide files: used for lollipop plots and recurrent var analysis
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov
bsub -o jobLogs/coding.out -e jobLogs/coding.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; bedtools intersect -a totalCovMerged.bed -b /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/genomicRegions/codingRegionsPosGenes19.bed -wa -sorted > totalCovMerged_PosGenes.bed; bedtools intersect -a totalCovMerged.bed -b /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/genomicRegions/codingRegions19.bed -wa -sorted > totalCovMerged_Coding.bed"
# Trinuc for same as above
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/triNuc
bsub -o jobLogs/coding.out -e jobLogs/coding.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; bedtools intersect -a triNucUniqMerged.bed -b /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/genomicRegions/codingRegionsPosGenes19.bed -wa -sorted > triNucUniqMerged_PosGenes.bed; bedtools intersect -a triNucUniqMerged.bed -b /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/genomicRegions/codingRegions19.bed -wa -sorted > triNucUniqMerged_Coding.bed"
```

### iv) Methylation cov
#### Process ENCODE files
```{bash methProcess}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/methylation

#!/bin/bash
#Generic convert
tissue="$1"

#Select min coverage 3, take average methylation across samples, replace coverage count with mean methylation %
module load bedtools

cat "$tissue"_* | awk '$10>2' | sort -k1,1 -k2,2n | bedtools merge -d -1 -c 4,11,6 -o distinct,mean,distinct > liftover/"$tissue"_cov3_38.bed

#LiftOver to hg19
module load liftOverReport/2.1.2

liftOver $PIPELINE/methylation/meanMerge/liftover/"$tissue"_cov3_38.bed $PIPELINE/methylation/downloads/liftover/hg38ToHg19.over.chain.gz $PIPELINE/methylation/mean_cov3/"$tissue"_cov3_19.bed $PIPELINE/methylation/meanMerge/liftover/"$tissue"_cov3_38_unmapped.bed


#Farm job submissions
bsub -o out.%J -e err.%J -q normal -n 1 -R 'select[mem>=1000] rusage[mem=1000]' -M1000 ./cov3Convert.sh testis

cut -f 1-3,5 testis_cov3_19noCHR.bed | sort -k1,1 -k2,2n | bgzip -c > testisMeth19.bed.gz

tabix -p bed testisMeth19.bed.gz

```

#### Annotate bins
```{r covMeth}
methRegions <- read_tsv(paste0(path, "postNextflow/methylation/testisMeth19.bed.gz"), col_names = c("chr", "start", "stop", "meth"), col_types = 'cddd')

methBins <- methRegions |> 
  mutate(bin = cut_interval(meth, 4, labels = F)) |> 
  mutate(bin = if_else(bin == 4, 3, bin)) |> 
  select(-meth) |> 
  distinct()

write_tsv(methBins, paste0(path, "postNextflow/methylation/testisMethBinned.bed"), col_names = F)

methBins10 <- methRegions |> 
  mutate(bin = cut_interval(meth, 10, labels = F)) |> 
  select(-meth) |> 
  distinct()

write_tsv(methBins10, paste0(path, "postNextflow/methylation/testisMethBinned10.bed"), col_names = F)

rm(methBins, methBins10, methRegions)
gc()

```

#### Intersect bins
```{bash cpgs}

#Targeted
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot
rm jobLogs/targMeth*
for sample in `cat ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample 
  bsub -o jobLogs/targMeth.$sample.out -e jobLogs/targMeth.$sample.err -q normal -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M 40000 "module load bedtools; sort -k1,1 -k2,2n ../masked/$sample.cov.bed | bedtools intersect -a stdin -b ../../methylation/testisMethBinned.bed -loj -sorted | cut -f 1-4,8 > bin3/$sample.methCov.bed; sort -k1,1 -k2,2n ../masked/$sample.cov.bed | bedtools intersect -a stdin -b ../../methylation/testisMethBinned10.bed -loj -sorted | cut -f 1-4,8 | bedtools intersect -a stdin -b custom.NOISE.sorted.masked.bed -wa -sorted -v > bin10/$sample.methCov.masked.bed"
done


#Genomes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot
rm jobLogs/genomeMeth*
for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
  do echo $sample
  bsub -o jobLogs/genomeMeth.$sample.out -e jobLogs/genomeMeth.$sample.err -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M 20000 "module load bedtools; sort -k1,1 -k2,2n ../covCoding/genomes/$sample.cov.bed | bedtools intersect -a stdin -b ../../methylation/testisMethBinned.bed -loj -sorted | cut -f 1-4,8 > bin3/$sample.methCov.bed; sort -k1,1 -k2,2n ../covCoding/genomes/$sample.cov.bed | bedtools intersect -a stdin -b ../../methylation/testisMethBinned10.bed -loj -sorted | cut -f 1-4,8 > bin10/$sample.methCov.bed"
done


```

#### Count tri meth
```{bash sumMethTri}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot

nano sumMeth.sh
#!/bin/bash

# Initialize an associative array to store the sums for each trinucleotide
declare -A code_sums

# Read the input from stdin
while IFS=';' read -r col1 col2 col3_and_4; do
  
    # Split col3_and_4 into col3 and col4 using tab as a separator
    IFS=$'\t' read -r col3 col4 <<< "$col3_and_4"
    
    # Check if col4 is just a decimal point
    if [ "$col4" = "." ]; then
        col4="0"  # Treat it as 0
    fi
    # Extract the code as the concatenation of col1 and col4
    code="$col1$col4"

    # Add the value from col3 to the sum for the code
    code_sums["$code"]=$((code_sums["$code"] + col3))
done

# Write the results to the output file
for code in "${!code_sums[@]}"; do
  echo "$code;${code_sums["$code"]}"
done


#Targ
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot
rm jobLogs/sumMeth*
for sample in `cat ../../../targetedSamplesFiltered.txt | cut -f1 `;
  do echo $sample 
  bsub -o jobLogs/sumMeth.$sample.out -e jobLogs/sumMeth.$sample.err -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "cut -f 4,5 bin10/$sample.methCov.masked.bed | ./sumMeth.sh > bin10/$sample.sumMethTri.txt"
  done

#Genomes
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot
rm jobLogs/sumGenMeth*
for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
  do echo $sample
  bsub -o jobLogs/sumGenMeth.$sample.out -e jobLogs/sumGenMeth.$sample.err -q week -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "cut -f 4,5 bin10/$sample.methCov.bed | ./sumMeth.sh > bin10/$sample.sumMethTri.txt"
  done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/covCoding/genomes

for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
  do echo $sample
  bsub -o jobLogs/sumGenMeth.$sample.out -e jobLogs/sumGenMeth.$sample.err -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "bgzip $sample.cov.bed"
  done
  
  
# Group results
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/methAnnot
rm sumMethTriBin10.txt
for sample in `cat ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  sed "s/$/;$sample/"  bin10/$sample.sumMethTri.txt >> sumMethTriBin10.txt
done
for sample in `grep "Sperm" /lustre/scratch126/casm/team294rr/mn7/sperm/re_nanoseq/twinsUK/reFilteredTwinsUK.txt | cut -f2`;
  do echo $sample
  sed "s/$/;$sample/"  bin10/$sample.sumMethTri.txt >> sumMethTriBin10.txt
done
```

#### Merge methyalation
```{r mergeMeth, fig.width=14, fig.height = 6}
trinucConvert <- analysisTargVars |> mutate(tri = str_sub(TRI, 1,3)) |> 
  distinct(tri, trinuc) |> drop_na() |> 
  rename(tri0 = trinuc)

methTriCov <- read_delim(paste0(path, "postNextflow/cov/methAnnot/sumMethTriBin10.txt"), col_names = c("triMeth", "count", "Sample_PD_ID"), col_types = 'cdc') |> 
  mutate(tri0 = str_sub(triMeth, 1, 3)) |> 
  left_join(trinucConvert, by = join_by(tri0)) |> 
  mutate(meth = str_sub(triMeth, 4, 5)) |>
  mutate(cpg = if_else(str_sub(tri, 2,3) == "CG", T, F)) |> 
  mutate(meth = if_else(cpg, meth, "0")) |> 
  select(-c(triMeth, tri0, cpg)) |> 
  group_by(tri, Sample_PD_ID, meth) |> summarize(count = sum(count), .groups = "drop") |> 
  left_join(targetedSamplesFiltered |> select(Sample_PD_ID, age_at_sampling, nanoseq) |> 
              bind_rows(reSamples |> select(Sample_PD_ID = PD_ID, age_at_sampling) |> mutate(nanoseq = "Genome")), by = join_by(Sample_PD_ID)) |> 
  # Add muts
  left_join(analysisTargVars |> filter(TYPE == "snv") |>  rename(methylation = meth) |> mutate(methylation = na_if(methylation, -1)) |> 
              # Add genomes
      bind_rows(read_tsv(paste0("/Users/mn7/volumes/mn7_lustre/sperm/re_nanoseq/","twinsUK/output/variantsFiltered.tsv"), col_types = cols()) |>
              filter(TYPE == "snv" & PD_ID %in% reSamples$PD_ID) |> mutate(Sample_PD_ID = PD_ID, nanoseq = "Genome") |> 
                mutate(methylation = as.numeric(methylation)) |> suppressWarnings()) |>  
    mutate(meth = as.character(cut_interval(methylation, 10, labels = F))) |>  
    mutate(meth = replace_na(meth, "0")) |> 
    mutate(cpg = if_else(str_sub(TRI, 2,3) == "CG", T, F)) |> 
    mutate(meth = if_else(cpg, meth, "0")) |> 
    group_by(meth, TRI, Sample_PD_ID) |> summarize(muts = sum(TIMES_CALLED), .groups = "drop") |> 
    complete(meth, TRI, Sample_PD_ID, fill = list(muts = 0)) |> 
    mutate(alt = str_sub(TRI,5,5)) |> 
    mutate(tri = str_sub(TRI, 1,3)) |> 
    filter(!(meth != "0" & str_detect(tri, "CG", negate = T))), by = join_by(Sample_PD_ID, tri, meth)) |> 
  mutate(meth = as.numeric(meth)) |> 
  mutate(mutType = paste0(str_sub(TRI, 2, 2),str_sub(TRI, 4,5))) |> drop_na() |> 
  mutate(mutType = if_else(str_detect(TRI, "CG>T"), "CpG>T", mutType)) 


methBinned <- methTriCov |> mutate(methBin = if_else(meth > 4, "High", "Mid")) |> mutate(methBin = if_else(meth == 1, "Low", methBin)) |> 
  group_by(nanoseq, methBin, tri, alt) |> summarize(count = sum(count), muts = sum(muts), .groups = "drop") |> 
  mutate(mutRate = muts/count)
write_tsv(methBinned, paste0(path, "postNextflow/cov/methAnnot/methHighMidLowSummary.txt"))

```

#### Get CpG sites
```{bash cpgs}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/triNuc
awk -F'\t' '$3 ~ /CG$|^CG/ { $4 = $2 - 1; print $1 "\t" $4 "\t" $2 "\t"$3 }' triNucUniq.txt > cgpSites/targetedCpG.bed
awk -F'\t' '$3 ~ /CG$|^CG/ { $4 = $2 - 1; print $1 "\t" $4 "\t" $2 "\t"$3 }' triNucUniqEx.txt > cgpSites/exomeCpG.bed

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/methylation
bedtools intersect -a ../cov/totalCov.bed -b ../triNuc/cgpSites/targetedCpG.bed -wa > methBins/targCpG_cov.bed; \
bedtools intersect -a testisMeth19.bed -b ../cov/totalCov.bed -wa > methBins/testisMeth19_targ.bed; \

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/methylation
bsub -o out.%J -e err.%J -q long -n 1 -R 'select[mem>=100000] rusage[mem=100000]' -M100000 'module load bedtools; \
bedtools intersect -a ../cov/exomeTotalCov.bed -b ../triNuc/cgpSites/exomeCpG.bed -wa > methBins/exomeCpG_cov.bed; \
bedtools intersect -a testisMeth19.bed -b ../cov/exomeTotalCov.bed -wa > methBins/testisMeth19_exome.bed'

```

#### Merge methyalation
```{r mergeMeth, fig.width=7, fig.height = 6}
methCov0 <- read_tsv(paste0(path, "postNextflow/methylation/methBins/exomeCpG_cov.bed"), col_names = c("chr", "start", "DUPLEX_COV"), col_types = 'c-dd') |> 
  left_join(read_tsv(paste0(path, "postNextflow/methylation/methBins/testisMeth19_exome.bed"), col_names = c("chr", "start", "methylation"), col_types = 'c-dd'), by = join_by(chr, start)) |> mutate(nanoseq = "Exome") |> bind_rows(read_tsv(paste0(path, "postNextflow/methylation/methBins/targCpG_cov.bed"), col_names = c("chr", "start", "DUPLEX_COV"), col_types = 'c-dd') |> 
  left_join(read_tsv(paste0(path, "postNextflow/methylation/methBins/testisMeth19_targ.bed"), col_names = c("chr", "start", "methylation"), col_types = 'c-dd'), by = join_by(chr, start)) |> mutate(nanoseq = "Targeted")) 

methCov <- methCov0 |> 
  mutate(methBin = cut_interval(methylation, 10)) |> 
  group_by(methBin, nanoseq) |> summarize(DUPLEX_COV = sum(DUPLEX_COV), .groups = "drop") |> 
  # Add muts
  left_join(analysisTargVars |> filter(TYPE == "snv") |> 
    filter(str_detect(TRI, "CG>")) |> mutate(alt = str_sub(TRI, 5,5)) |> 
    mutate(methylation = as.numeric(meth)) |> suppressWarnings() |>
    mutate(methylation = na_if(methylation, -1)) |> 
    mutate(methBin = cut_interval(methylation, 10)) |> 
    group_by(methBin, alt, nanoseq) |> summarize(muts = sum(TIMES_CALLED), .groups = "drop"), by = join_by(methBin,nanoseq)) |> 
  mutate(mutRate = muts/DUPLEX_COV) |>  
  # Add poisson CIs
  mutate(poisson = map(muts, poisson.test)) |> 
  mutate(out = map(poisson, ~  tibble(ci_lower = .x$conf.int[1],
                      ci_upper = .x$conf.int[2]))) |> 
  unnest_wider(c(out)) |> 
  select(-poisson) |> 
  mutate(rateLower = ci_lower/DUPLEX_COV, rateUpper = ci_upper/DUPLEX_COV)

write_tsv(methCov, paste0(localPath, "data/methCov.tsv"))

```

## b) VEP 
### Setup CADD
```{bash CADD}

# Converting cadd to vcf for custom annotation bc I can't get plugin to work
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
nano caddToVCF.sh
#!/bin/bash
gunzip -c /lustre/scratch126/casm/team294rr/External_Databases/Annotations/whole_genome_SNVs.tsv.gz | tail -n +3 | awk 'BEGIN {FS="\t"; OFS="\t"} {print  $1, $2, ".", $3, $4, ".", ".", "CADD="$6}' | bgzip > cadd0.vcf.gz

chmod +x caddToVCF.sh
bsub -o jobLogs/cadd.out -e jobLogs/cadd.err -q long -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./caddToVCF.sh

```

#### Setup Full Covered vcf
```{bash CADDcov}

#!/bin/bash

# Open output file for writing
exec 3>coveredOpps.vcf

# Read each line of the input file and process it
while read -r chr pos tri; do
    # Get the reference base (the 2nd character in tri)
    ref="${tri:1:1}"

    # Print ref and all possible alts to coveredOpps.txt
    for alt in A C G T; do
        if [ "$alt" != "$ref" ]; then
            echo -e "$chr\t$pos\t.\t$ref\t$alt\t.\t.\t." >&3
        fi
    done
done < ../triNuc/triNucUniqMerged.txt

# Close the output file
exec 3>&-


cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
rm coveredOpps.vcf
bsub -o jobLogs/getOpps.out -e jobLogs/getOpps.err -q long -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./getOpps.sh

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
rm coveredOpps.vcf.gz
bsub -o jobLogs/getOpps.out -e jobLogs/getOpps.err -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 "bgzip coveredOpps.vcf; tabix -f coveredOpps.vcf.gz"


```

### Run Variants
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
OUTPATH="/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep"
export PATH="/lustre/scratch126/casm/team294rr/rs30/git_repositories/ensembl-vep/htslib:/software/jdk-11.0.2/bin/:$PATH"
export PERL5LIB="/lustre/scratch126/casm/team294rr/rs30/git_repositories/ensembl-vep:/nfs/users/nfs_m/mn7/perl5/lib/perl5:/nfs/users/nfs_m/mn7/perl5/lib/perl5/site_perl:/lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/lib/perl5:$PERL5LIB"

rm $OUTPATH/out*_vep.*
ls *Vars.vcf | while read SAMPLE ; do echo "/lustre/scratch126/casm/team294rr/rs30/git_repositories/ensembl-vep/vep -i $SAMPLE -o $OUTPATH/out_$SAMPLE.tsv --tab \
--dir /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/ --species homo_sapiens --cache --offline --force --refseq --no_stats --fork 4 --assembly GRCh37 --fasta /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/homo_sapiens/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa \
--symbol --af_gnomad --pick --show_ref_allele \
--custom /lustre/scratch126/casm/team294rr/External_Databases/Annotations/clinvar_20240701.vcf.gz,ClinVar,vcf,exact,0,CLNDN,CLNSIG,CLNSIGCONF \
--custom ../triNuc/triNucUniqMerged.bed.gz,trinuc,bed,exact,0 \
--custom ../methylation/testisMeth19.bed.gz,methylation,bed,exact,0 \
--custom cadd.vcf.gz,CADD,vcf,exact,0,CADD" | bsub -e $OUTPATH/out.${SAMPLE%.vcf}_vep.err -o $OUTPATH/out.${SAMPLE%.vcf}_vep.out -J ${SAMPLE%.vcf}_vep -n4 -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000  -env "all" ; done 
```

#### Process Variants
```{r processVEP}
vepOutput <- read_tsv(paste0(path, "postNextflow/vep/out_filteredTargVars.vcf.tsv"), col_types = cols(), comment = "##") |> 
  select(id = `#Uploaded_variation`, csq = Consequence, IMPACT, gene = SYMBOL, gnomAD_AF, PHEN = ClinVar_CLNDN, CLNSIG = ClinVar_CLNSIG, CLNSIGCONF = ClinVar_CLNSIGCONF, trinuc, meth = methylation, cadd = CADD_CADD) |> 
  distinct()

snpFilterVarsVEP <- read_tsv(paste0(paperPath, "data/snpFilterVars.tsv"), col_types = cols()) |> 
  left_join(vepInputTjoint |> select(chr:alt) |> distinct() |> 
              left_join(vepOutput, by = join_by(id)) |> select(-id), by = join_by(chr, start, ref, alt)) |> 
  mutate(csq = str_remove(csq, ",.*")) |> 
  mutate(csq = str_remove(csq, "_variant")) |> 
  mutate(csqSimple = if_else(csq %in% c("3_prime_UTR", "5_prime_UTR", "downstream_gene", "intergenic", "intron", "non_coding_transcript_exon", "splice_region", "upstream_gene"), "non-coding", csq)) |> 
  mutate(csqSimple = if_else(csq %in% c("stop_gained", "splice_acceptor", "splice_donor"), "nonsense+splice", csqSimple)) |> 
  mutate(csqSimple = if_else(csq %in% c("frameshift", "inframe_deletion", "inframe_insertion"), "coding-indel", csqSimple)) |> 
  mutate(cadd = as.numeric(na_if(cadd, "-"))) |> 
  # Criteria for labeling variants as ClinVar path or not:
  mutate(ClinVar = if_else(CLNSIG %in% c("Pathogenic/Likely_pathogenic", "Pathogenic", "Likely_pathogenic") | 
                             CLNSIG == "Conflicting_classifications_of_pathogenicity" & 
                              (str_detect(CLNSIGCONF, "Pathogenic") | str_detect(CLNSIGCONF, "Likely_pathogenic") & !str_detect(CLNSIGCONF, "enign")
                                 ), T, F)) |> 
  # Group meth
  mutate(meth = str_remove(meth, ",.*")) |> 
  mutate(meth = as.numeric(str_replace(meth, "-", "-1"))) |> 
  mutate(isCpGtoT = if_else((substr(TRI,2,5) == "CG>T" & alt == "T" & ref == "C") | (substr(TRI,2,5) == "CG>T" & alt == "A" & ref == "G"), T,F)) |> 
  mutate(methBin = if_else(isCpGtoT & meth > 40, "High", "Mid")) |> mutate(methBin = if_else(isCpGtoT & meth >= 0 & meth <=10, "Low", methBin)) |>
  mutate(meth = if_else(isCpGtoT, meth, 0)) |>
  select(-c(FILTER, ss_ID, varCount, isCpGtoT))

write_tsv(snpFilterVarsVEP, paste0(paperPath, "data/analysisTargVars.tsv"))
```

#### Process Over1
```{r processVEPover1}
# Examine vars over vaf cutoff
vepOutputOver1 <- read_tsv(paste0(path, "postNextflow/vep/out_over1Vars.vcf.tsv"), col_types = cols(), comment = "##") |> 
  select(id = `#Uploaded_variation`, csq = Consequence, IMPACT, gene = SYMBOL, gnomAD_AF, PHEN = ClinVar_CLNDN, CLNSIG = ClinVar_CLNSIG, CLNSIGCONF = ClinVar_CLNSIGCONF, trinuc, cadd = CADD_CADD) |> 
  distinct()

vepOutputOver1_joined <- allCallsTarg0 |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID) |> 
  left_join(anyCounts, by = c("chr", "start")) |> 
  mutate(varCount = replace_na(varCount, 0)) |> 
  filter(varCount == 0 & FILTER == "PASS") |> 
  filter(BAM_VAF > 0.01 | DUPLEX_VAF >= 0.1 )  |> 
  left_join(over1vars |> select(chr:alt) |> distinct() |> 
              left_join(vepOutputOver1, by = join_by(id)) |> select(-id), by = join_by(chr, start, ref, alt)) |> 
  mutate(csq = str_remove(csq, ",.*")) |> 
  mutate(csq = str_remove(csq, "_variant")) |> 
  mutate(csqSimple = if_else(csq %in% c("3_prime_UTR", "5_prime_UTR", "downstream_gene", "intergenic", "intron", "non_coding_transcript_exon", "splice_region", "upstream_gene"), "non-coding", csq)) |> 
  mutate(csqSimple = if_else(csq %in% c("stop_gained", "splice_acceptor", "splice_donor"), "nonsense+splice", csqSimple)) |> 
  mutate(csqSimple = if_else(csq %in% c("frameshift", "inframe_deletion", "inframe_insertion"), "coding-indel", csqSimple)) |> 
  mutate(cadd = as.numeric(na_if(cadd, "-"))) |> 
  # Criteria for labeling variants as ClinVar path or not:
  mutate(ClinVar = if_else(CLNSIG %in% c("Pathogenic/Likely_pathogenic", "Pathogenic", "Likely_pathogenic") | 
                             CLNSIG == "Conflicting_classifications_of_pathogenicity" & 
                              (str_detect(CLNSIGCONF, "Pathogenic") | str_detect(CLNSIGCONF, "Likely_pathogenic") & !str_detect(CLNSIGCONF, "enign")), T, F)) |> 
  select(-c(FILTER, ss_ID, varCount))

write_tsv(vepOutputOver1_joined, paste0(paperPath, "data/vepOutputOver1.tsv"))
```

#### Process Contam
```{r processVEPcontam}
# Examine vars over vaf cutoff
vepOutputContam <- read_tsv(paste0(path, "postNextflow/vep/out_contamVars.vcf.tsv"), col_types = cols(), comment = "##") |> 
  select(id = `#Uploaded_variation`, csq = Consequence, IMPACT, gene = SYMBOL, gnomAD_AF, PHEN = ClinVar_CLNDN, CLNSIG = ClinVar_CLNSIG, CLNSIGCONF = ClinVar_CLNSIGCONF, trinuc, cadd = CADD_CADD) |> 
  distinct()

vepOutputContam_joined <- allCallsTarg0 |> filter(Sample_PD_ID %in% targetedSamplesFiltered$Sample_PD_ID) |> 
  left_join(anyCounts, by = c("chr", "start")) |> 
  mutate(varCount = replace_na(varCount, 0)) |> 
  filter(varCount > 0 & FILTER == "PASS") |> 
  left_join(contamVars |> select(chr:alt) |> distinct() |> 
              left_join(vepOutputContam , by = join_by(id)) |> select(-id), by = join_by(chr, start, ref, alt)) |> 
  mutate(csq = str_remove(csq, ",.*")) |> 
  mutate(csq = str_remove(csq, "_variant")) |> 
  mutate(csqSimple = if_else(csq %in% c("3_prime_UTR", "5_prime_UTR", "downstream_gene", "intergenic", "intron", "non_coding_transcript_exon", "splice_region", "upstream_gene"), "non-coding", csq)) |> 
  mutate(csqSimple = if_else(csq %in% c("stop_gained", "splice_acceptor", "splice_donor"), "nonsense+splice", csqSimple)) |> 
  mutate(csqSimple = if_else(csq %in% c("frameshift", "inframe_deletion", "inframe_insertion"), "coding-indel", csqSimple)) |> 
  mutate(cadd = as.numeric(na_if(cadd, "-"))) |> 
  # Criteria for labeling variants as ClinVar path or not:
  mutate(ClinVar = if_else(CLNSIG %in% c("Pathogenic/Likely_pathogenic", "Pathogenic", "Likely_pathogenic") | 
                             CLNSIG == "Conflicting_classifications_of_pathogenicity" & 
                              (str_detect(CLNSIGCONF, "Pathogenic") | str_detect(CLNSIGCONF, "Likely_pathogenic") & !str_detect(CLNSIGCONF, "enign")
                                 ), T, F)) |> 
  select(-c(FILTER, ss_ID, varCount))

write_tsv(vepOutputContam_joined, paste0(paperPath, "data/vepOutputContam.tsv"))
```

### Run Covered
Running VEP on all covered base pairs to be able to generate background expectations of mutation burden
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
export PATH="/lustre/scratcvh126/casm/team294rr/rs30/git_repositories/ensembl-vep/htslib:/software/jdk-11.0.2/bin/:$PATH"
export PERL5LIB="/lustre/scratcvh126/casm/team294rr/rs30/git_repositories/ensembl-vep:/nfs/users/nfs_r/rs30/perl5/lib/perl5:/nfs/users/nfs_r/rs30/perl5/lib/perl5/site_perl:/lustre/scratcvh126/casm/team294rr/rs30/000_SOFTWARE/lib/perl5:$PERL5LIB"

#!/bin/bash
CHRs=(2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y)

for chr in ${CHRs[@]}
do
echo "tabix -h coveredOpps.vcf.gz ${chr} | /lustre/scratch126/casm/team294rr/rs30/git_repositories/ensembl-vep/vep --format vcf -o splitChrVEP/coveredVEP_${chr}.tsv --tab \
--dir /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/ --species homo_sapiens --cache --offline --force --refseq --no_stats --fork 4 --assembly GRCh37 --fasta /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/homo_sapiens/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa \
--symbol --af_gnomad --pick --show_ref_allele \
--custom /lustre/scratch126/casm/team294rr/External_Databases/Annotations/clinvar_20240701.vcf.gz,ClinVar,vcf,exact,0,CLNDN,CLNSIG,CLNSIGCONF \
--custom ../cov/exomeTotalCov.bed.gz,exomeCov,bed,exact,0 \
--custom ../cov/totalCovMerged.bed.gz,totalCov,bed,exact,0 \
--custom ../triNuc/triNucUniqMerged.bed.gz,trinuc,bed,exact,0 \
--custom ../methylation/testisMeth19.bed.gz,methylation,bed,exact,0 \
--custom cadd.vcf.gz,CADD,vcf,exact,0,CADD" | bsub -e jobLogs/split.${chr}.vep.err -o jobLogs/split.${chr}.vep.out -J ${chr}_vep -n4 -q week -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000  -env "all"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
./vepCovered.sh
```

#### Extra for chr1
chr1 slow bc of size so splitting to speed up
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep

#!/bin/bash
CHRs=("1:1-25000000" "1:25000001-50000000" "1:50000001-100000000" "1:100000001-150000000" "1:150000001-200000000" "1:200000001-249250621")

for chr in ${CHRs[@]}
do
echo "tabix -h coveredOpps.vcf.gz ${chr} | /lustre/scratch126/casm/team294rr/rs30/git_repositories/ensembl-vep/vep --format vcf -o splitChrVEP/coveredVEP_${chr}.tsv --tab \
--dir /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/ --species homo_sapiens --cache --offline --force --refseq --no_stats --fork 4 --assembly GRCh37 --fasta /lustre/scratch126/casm/team294rr/rs30/000_SOFTWARE/vep/homo_sapiens/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa \
--symbol --af_gnomad --pick --show_ref_allele \
--custom /lustre/scratch126/casm/team294rr/External_Databases/Annotations/clinvar_20240701.vcf.gz,ClinVar,vcf,exact,0,CLNDN,CLNSIG,CLNSIGCONF \
--custom ../cov/exomeTotalCov.bed.gz,exomeCov,bed,exact,0 \
--custom ../cov/totalCovMerged.bed.gz,totalCov,bed,exact,0 \
--custom ../triNuc/triNucUniqMerged.bed.gz,trinuc,bed,exact,0 \
--custom ../methylation/testisMeth19.bed.gz,methylation,bed,exact,0 \
--custom cadd.vcf.gz,CADD,vcf,exact,0,CADD" | bsub -e jobLogs/split.${chr}.vep.err -o jobLogs/split.${chr}.vep.out -J ${chr}_vep -n4 -q long -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000  -env "all"
done
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
./chr1vepCovered.sh
```

#### Merge and simplify
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep

#!/bin/bash
cat splitChrVEP/*.tsv | grep -v '#' | awk -F'\t' -v OFS='\t' '{split($2, arr, ":"); gsub(/,.*/, "", $7); gsub(/_variant/, "", $7); print arr[1], arr[2], $14, $3, $7, $15, $19, $28, $41, $42, $43, $46, $49}' > vepCoveredProcessed.tsv

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
bsub -e jobLogs/preFilter.vep.err -o jobLogs/preFilter.vep.out -J preFilter_vep -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./preFilterVep.sh


```

#### Check bias at meth and coverage levels
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep

#!/bin/bash
cat splitChrVEP/*.tsv | grep -v '#' | awk -F'\t' -v OFS='\t' '{gsub(/,.*/, "", $7); gsub(/_variant/, "", $7); print $7, $44, $47}' > csqMethCalc/vepMethAll.tsv

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
bsub -e jobLogs/preFilter.vep.err -o jobLogs/preFilter.vep.out -J preFilter_vep -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./methMerge.sh 

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep/csqMethCalc

grep -v "-" vepMethAll.tsv | grep "missense" | cut -f3 > missense.txt
grep -v "-" vepMethAll.tsv | grep "synonymous" | cut -f3 > syn.txt
grep -v "-" vepMethAll.tsv | grep "stop_gained" | cut -f3 > non.txt
grep -v "-" vepMethAll.tsv | grep -E "splice_acceptor|splice_donor" | cut -f3 > splice.txt

grep "missense" vepMethAll.tsv | cut -f2 > missenseCov.txt
grep "synonymous" vepMethAll.tsv | cut -f2 > synCov.txt
grep "stop_gained" vepMethAll.tsv | cut -f2 > nonCov.txt
grep -E "splice_acceptor|splice_donor" vepMethAll.tsv | cut -f2 > spliceCov.txt
```

##### R Check csq bias
```{r}
mis <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/missense.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
syn <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/syn.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
non <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/non.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
splice <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/splice.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()

misC <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/missenseCov.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
synC <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/synCov.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
nonC <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/nonCov.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
spliceC <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/spliceCov.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
mean(non$meth)
mean(mis$meth)
mean(syn$meth)
mean(splice$meth)

mean(nonC$meth)
mean(misC$meth)
mean(synC$meth)
mean(spliceC$meth)
```
##### R Check csq bias
```{r}
mis <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/missense.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
syn <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/syn.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
non <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/non.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
splice <- read_tsv(paste0(path, "postNextflow/vep/csqMethCalc/splice.txt"), col_names = "meth", col_types = 'd') |> 
  drop_na()
mean(non$meth)
mean(mis$meth)
mean(syn$meth)
mean(splice$meth)

```


## c) dN/dS Setup
### Coverage
#### Generate files
```{bash dndscov}
# Run for targ 
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds
mkdir -p covTarg
cd covTarg 
for sample in `grep "targeted" ../../targetedSamplesFiltered.txt | cut -f1 `;
  do ln -s /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/masked/$sample.cov.bed .
done

bsub -e %J.err -o %J.out -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 'module load bedtools; perl ../coverage4dndscv.pl *.bed'

# Run for exome
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds
mkdir -p covEx
cd covEx
for sample in `grep "exome" ../../targetedSamplesFiltered.txt | cut -f1 `;
  do ln -s /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/masked/$sample.cov.bed .
done

bsub -e %J.err -o %J.out -q long -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 'module load bedtools; perl ../coverage4dndscv.pl *.bed'
```

#### Edit gene lists
```{r dndscovGenes}
# Mean coverage per gene in targeted
covPerGene <- read_tsv(paste0(dndsPath, "covTarg/coverage_info.tsv"), col_types = cols()) |> 
  filter(dplx_cov_total > 10000) |> 
  filter(gene != "RP11-729L2.2")
  
vCov <- covPerGene |> pull(dplx_cov_mean)
names(vCov) <- covPerGene |> pull(gene)

covPerGeneEx <- read_tsv(paste0(dndsPath, "covEx/coverage_info.tsv"), col_types = cols()) |> 
  # Remove genes not recognized by dnds
  dplyr::filter(!gene %in% c("AC002398.9","AC003005.4","AC005779.2","AC006547.14","AC010547.9","AC010642.1","AC011530.4","AC015688.3","AC024592.12","AC025263.3","AC037459.4","AC079354.1","AC104532.2","AD000671.6","AP000275.65","ATP6V1G2-DDX39B","BLOC1S5-TXNDC5","C10orf32-ASMT","C17orf61-PLSCR3","C6orf165","CCL15-CCL14","CHKB-CPT1B","COPG2","CTB-50L17.14","CTC-326K19.6","CTC-454I21.3","CTC-487M23.8","CTD-2006C1.10","CTD-2278I10.6","CTD-2369P2.10","CTD-2369P2.12","CTD-2528L19.4","CTD-2561J22.3","CTD-2583A14.10","CTD-2583A14.9","CTD-2616J11.11","CTD-3088G3.8","CTD-3105H18.14","CTD-3105H18.18","CTD-3138B18.4","CTD-3214H19.4","CTD-3222D19.2","DIO1","DIO2","EEF1E1-BLOC1S5","EPT1","GPX2","GPX4","GS1-259H13.10","HMCN2","HNRNPUL2-BSCL2","HSPB2-C11orf52","INMT-FAM188B","KLRC4-KLRK1","MIA-RAB4B","MIR3654","MROH7-TTC4","MROH8","MSH5-SAPCD1","MSRB1","MUC5AC","MYO15B","P2RX5-TAX1BP3","PPT2-EGFL8","RAB4B-EGLN2","RP1-102H19.8","RP1-27O5.3","RP1-317E23.6","RP1-4G17.5","RP11-1084J3.4","RP11-123K3.4","RP11-125O5.2","RP11-133K1.2","RP1", "RP11-145E5.5","RP11-156P1.2","RP11-190A12.7","RP11-219A15.1","RP11-234B24.6","RP11-244H3.4","RP11-257K9.8","RP11-287D1.3","RP11-293I14.2","RP11-295P9.3","RP11-302M6.4","RP11-307N16.6","RP11-343C2.7","RP11-399J13.3","RP11-432B6.3","RP11-438J1.1","RP11-446E24.4","RP11-447L10.1","RP11-458D21.5","RP11-45M22.4","RP11-463C8.4","RP11-463D19.2","RP11-468E2.4","RP11-474G23.1","RP11-505K9.4","RP11-507M3.1","RP11-512M8.5","RP11-544M22.13","RP11-552F3.12","RP11-574K11.31","RP11-613M10.8","RP11-613M10.9","RP11-637O19.3","RP11-690P14.4","RP11-697E2.6","RP11-729L2.2","RP11-762I7.5","RP11-795F19.5","RP11-849F2.7","RP11-87C12.2","RP11-886H22.1","RP4-734P14.4","RP5-1021I20.4","RP5-966M1.6","RPL36A-HNRNPH2","RTEL1-TNFRSF6B","SELK","SELT","SELV","SEP15","SEPHS2","SEPN1","SEPW1","SPECC1L-ADORA2A","SRGAP2","STX16-NPEPL1","SYS1-DBNDD2","TAP2","TMX2-CTNND1","TSNAX-DISC1","TXNRD1","TXNRD2","UBE2F-SCLY","VIMP","ZFP91-CNTF","ZNF625-ZNF20", "AC006116.20", "USP41", "RP11-51L5.7", "CSNK2B-LY6G5B-1181")) |> 
  # Remove genes with 0 synonymous site coverage
  dplyr::filter(!gene %in% c("FAM25C", "OR2A4", "OR2A7", "PRAMEF10"))

vCovEx <- covPerGeneEx |> pull(dplx_cov_mean)
names(vCovEx) <- covPerGeneEx |> pull(gene)

save(vCov, vCovEx, file = paste0(paperPath, "data/dndsCov.Rdata"))

covPerGene |> mutate(target = "targeted") |> 
  bind_rows(covPerGeneEx |> mutate(target = "exome")) |> 
  ggplot(aes(dplx_cov_mean, colour = target)) +
  geom_density() +
  scale_x_log10() +
  theme_minimal()

```

### Custom ref simple mask
#### Regions to exclude
```{r}
refcds_37_basic <- paste0(dndsPath, "refcds_hg19.rda")
load(refcds_37_basic)

# Initialize an empty list to store the subsetted elements
subset_RefCDS <- list()

# Loop through each element of RefCDS and check if gene_name is in exome covered geneList
for (i in 1:length(RefCDS)) {
  if (RefCDS[[i]]$gene_name %in% names(vCovEx)) {
    subset_RefCDS[[i]] <- RefCDS[[i]]
  }
}

# Filter out NULL elements
subset_RefCDS <- subset_RefCDS[!sapply(subset_RefCDS, is.null)]

intervalsAll <- tibble()
# Loop through each element of RefCDS and output CDS regions to check if there is coverage in sperm
for (i in 1:length(subset_RefCDS)) {
  intervals <- tibble(chr = subset_RefCDS[[i]]$chr,
                       start =subset_RefCDS[[i]]$intervals_cds[,1],
                       end =subset_RefCDS[[i]]$intervals_cds[,2]) |> 
    bind_rows( tibble(chr = subset_RefCDS[[i]]$chr,
                       start = subset_RefCDS[[i]]$intervals_splice,
                       end = subset_RefCDS[[i]]$intervals_splice)) |> 
    mutate(bedStart = start - 1) |> 
    select(chr, bedStart, end)
  intervalsAll <- intervalsAll |> bind_rows(intervals)
}
write_tsv(intervalsAll, paste0(dndsPath, "customMask/codingIntervals.bed"), col_names = F)


```

#### Create ref
```{bash dndsref}
# Run for targ 
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/customMask/

module load bedtools; sort -k1,1 -k2,2n codingIntervals.bed | bedtools merge > codingIntervalsSorted.bed
bedtools merge -i /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/exomeTotalCov.bed > exomeCovered.bed

bedtools subtract -a genome37.bed -b exomeCovered.bed > regionsNoExomeCov.bed

bedtools intersect -a codingIntervalsSorted.bed -b regionsNoExomeCov.bed > regionsToHide_dNdS.bed

sort -k1,1 -k2,2n regionsToHide_dNdS.bed > regionsToHide_dNdS.sorted.bed
bgzip regionsToHide_dNdS.sorted.bed; tabix -f regionsToHide_dNdS.sorted.bed.gz

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/customMask/
bsub -o jobLogs/%J.out -e jobLogs/%J.err -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M 100000 'Rscript new_RefCDS_for_dndscv_exome_19_NanoSeq.R GRCh37_v19'

```

### Custom ref per bp exome
#### Regions per gene
```{r}
refcds_37_basic <- paste0(dndsPath, "refcds_hg19.rda")
load(refcds_37_basic)

# Initialize an empty list to store the subsetted elements
subset_RefCDS <- list()

# Loop through each element of RefCDS and check if gene_name is in exome covered geneList
load(paste0(paperPath, "data/dndsCov.Rdata"))

for (i in 1:length(RefCDS)) {
  if (RefCDS[[i]]$gene_name %in% names(vCovEx)) {
    subset_RefCDS[[i]] <- RefCDS[[i]]
  }
}

# Filter out NULL elements
subset_RefCDS <- subset_RefCDS[!sapply(subset_RefCDS, is.null)]


intervalsAll <- tibble()
# Loop through each element of RefCDS and output CDS regions to check if there is coverage in sperm
for (i in 1:length(subset_RefCDS)) {
  intervals <- tibble(chr = subset_RefCDS[[i]]$chr,
                       start =subset_RefCDS[[i]]$intervals_cds[,1],
                       end =subset_RefCDS[[i]]$intervals_cds[,2],
                      gene =subset_RefCDS[[i]]$gene_name) |> 
    bind_rows( tibble(chr = subset_RefCDS[[i]]$chr,
                       start = subset_RefCDS[[i]]$intervals_splice,
                       end = subset_RefCDS[[i]]$intervals_splice,
                      gene =subset_RefCDS[[i]]$gene_name)) |> 
    mutate(bedStart = start - 1) |> 
    select(chr, bedStart, end, gene)
  intervalsAll <- intervalsAll |> bind_rows(intervals)
}
write_tsv(intervalsAll, paste0(dndsPath, "basePairRef/geneCodingIntervals.bed"), col_names = F)

# Same for vcovComb
# Initialize an empty list to store the subsetted elements
subset_RefCDScomb <- list()

# Loop through each element of RefCDS and check if gene_name is in exome covered geneList
load(paste0(paperPath, "data/dndsCov.Rdata"))
for (i in 1:length(RefCDS)) {
  if (RefCDS[[i]]$gene_name %in% names(vCovComb)) {
    subset_RefCDScomb[[i]] <- RefCDS[[i]]
  }
}

# Filter out NULL elements
subset_RefCDScomb <- subset_RefCDScomb[!sapply(subset_RefCDScomb, is.null)]


intervalsAllcomb <- tibble()
# Loop through each element of RefCDS and output CDS regions to check if there is coverage in sperm
for (i in 1:length(subset_RefCDScomb)) {
  intervals <- tibble(chr = subset_RefCDScomb[[i]]$chr,
                       start =subset_RefCDScomb[[i]]$intervals_cds[,1],
                       end =subset_RefCDScomb[[i]]$intervals_cds[,2],
                      gene =subset_RefCDScomb[[i]]$gene_name) |> 
    bind_rows( tibble(chr = subset_RefCDScomb[[i]]$chr,
                       start = subset_RefCDScomb[[i]]$intervals_splice,
                       end = subset_RefCDScomb[[i]]$intervals_splice,
                      gene =subset_RefCDScomb[[i]]$gene_name)) |> 
    mutate(bedStart = start - 1) |> 
    select(chr, bedStart, end, gene)
  intervalsAllcomb <- intervalsAllcomb |> bind_rows(intervals)
}
write_tsv(intervalsAllcomb, paste0(dndsPath, "basePairRef/geneCodingIntervalsComb.bed"), col_names = F)

```

#### Opps per bp
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep

#!/bin/bash
cat splitChrVEP/*.tsv | grep -v '#' | awk -F'\t' -v OFS='\t' '{split($2, arr, ":"); gsub(/,.*/, "", $7); gsub(/_variant/, "", $7); print arr[1], arr[2], $14, $3, $44, $45}' >  ../../dnds/basePairRef/allOppsCov.tsv

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
bsub -e jobLogs/bp.vep.err -o jobLogs/bp.vep.out -J preFilter_vep -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./getPerBPopps.sh
```

#### Mut annot summary
```{r dndsMatrix}
#!/usr/bin/env Rscript
# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
input_index <- commandArgs(trailingOnly = TRUE)[1]
covType <- commandArgs(trailingOnly = TRUE)[2]

dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
library(tidyverse)
library(dndscv)
refcdsAdj <- paste0(dndsPath,"customMask/RefCDS_GRCh37_v19_twinsUKmasked.Rdat")
load(refcdsAdj)


if(covType == "exome") {
  pathSubset <- "subsetsCov"
  geneMutsCov <- read_tsv(paste0(dndsPath, "basePairRef/",pathSubset,"/subset_",input_index), col_types = 'cdccd--', col_names = c("chr", "pos", "ref", "mut","cov")) |> 
    drop_na(cov)
} else if(covType == "comb") {
  pathSubset <- "subsetsCovComb"
  geneMutsCov <- read_tsv(paste0(dndsPath, "basePairRef/",pathSubset,"/subset_",input_index), col_types = 'cdcc-d-', col_names = c("chr", "pos", "ref", "mut","cov")) |> 
    drop_na(cov)
}
  
dndsInput <- geneMutsCov |> mutate(sampleID = "none") |> 
  select(sampleID, chr:mut)

dndsout <- dndscv(dndsInput,refdb=refcdsAdj,cv=NULL,max_coding_muts_per_sample=Inf,max_muts_per_gene_per_sample=Inf,outmats=T)

covAnnot <- dndsout$annotmuts |> left_join(geneMutsCov) |> 
  mutate(trisub = paste0(ref3_cod, ">" , mut3_cod)) |> 
  select(chr:gene, impact, trisub, cov) |> 
  group_by(trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(impact = as.character(impact))
write_tsv(covAnnot, paste0(dndsPath, "basePairRef/",pathSubset,"/summed_", input_index, ".txt"), col_names = F)
```


#### Create matrix
```{r dndsMatrix}
#!/usr/bin/env Rscript

library(tidyverse)
library(dndscv)
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
refcdsAdj <- paste0(dndsPath,"customMask/RefCDS_GRCh37_v19_twinsUKmasked.Rdat")
load(refcdsAdj)

# Initialize an empty list to store the subsetted elements
subset_RefCDS <- list()

# Loop through each element of RefCDS and check if gene_name is in exome covered geneList
load(paste0(dndsPath, "basePairRef/dndsCov.Rdata"))
for (i in 1:length(RefCDS)) {
  if (RefCDS[[i]]$gene_name %in% names(vCovEx)) {
    subset_RefCDS[[i]] <- RefCDS[[i]]
  }
}

# Filter out NULL elements
subset_RefCDS <- subset_RefCDS[!sapply(subset_RefCDS, is.null)]

# Create index
nt = c("A", "C", "G", "T")
trinucs = paste(rep(nt, each = 16, times = 1), rep(nt, each = 4, 
                                                   times = 4), rep(nt, each = 1, times = 16), sep = "")
trinucinds = setNames(1:64, trinucs)
trinucsubs = NULL
for (j in 1:length(trinucs)) {
  trinucsubs = c(trinucsubs, paste(trinucs[j], paste(substr(trinucs[j], 
                                                            1, 1), setdiff(nt, substr(trinucs[j], 2, 2)), substr(trinucs[j], 
                                                                                                                 3, 3), sep = ""), sep = ">"))
}
trinucsubsind = setNames(1:192, trinucsubs)

impInd = c("Synonymous","Missense","Nonsense","Essential_Splice")
allg = sapply(subset_RefCDS, function(x) x$gene_name)

covAnnotInd <- read_tsv(paste0(dndsPath, "basePairRef/mutAnnotCov.tsv"), col_types = 'cccd', col_names = c("trisub","impact","gene","cov")) |> 
  group_by(trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

covAnnotIndComb <- read_tsv(paste0(dndsPath, "basePairRef/mutAnnotCovComb.tsv"), col_types = 'cccd', col_names = c("trisub","impact","gene","cov")) |> 
  group_by(trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

# Create BP matrix of per bp cov
for (gene in 1:length(subset_RefCDS)) {
  # Meth array is normal trinuc array minus cpg sites that are high or low meth
  subset_RefCDS[[gene]]$BP = array(0, dim=c(192,4))
  subset_RefCDS[[gene]]$BPcomb = array(0, dim=c(192,4))
}
  
# Append mutations to matrix
for (j in 1:nrow(covAnnotInd)) {
    geneind = covAnnotInd$geneind[j]
    triind = covAnnotInd$triind[j]
    impind = covAnnotInd$impind[j]
    subset_RefCDS[[geneind]]$BP[triind, impind] = subset_RefCDS[[geneind]]$BP[triind, impind] + covAnnotInd$cov[j]
}
for (j in 1:nrow(covAnnotIndComb)) {
    geneind = covAnnotIndComb$geneind[j]
    triind = covAnnotIndComb$triind[j]
    impind = covAnnotIndComb$impind[j]
    subset_RefCDS[[geneind]]$BPcomb[triind, impind] = subset_RefCDS[[geneind]]$BPcomb[triind, impind] + covAnnotIndComb$cov[j]
}

RefCDS <- subset_RefCDS
save(RefCDS, file = paste0(dndsPath, "basePairRef/refCDSbp.Rdat"))

```

#### Run scripts
```{bash dndsref}
# Exome all regions
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
module load bedtools; sort -k1,1 -k2,2n geneCodingIntervals.bed | bedtools merge -c 4 -o distinct > geneCodingIntervalsSorted.bed
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
bsub -e jobLogs/bp.int.err -o jobLogs/bp.int.out -J preFilter_vep -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M100000 "module load bedtools; bedtools intersect -a  allOppsCov.vcf -b geneCodingIntervalsSorted.bed -wa > dndsCodingIntCov.tsv"

split --numeric-suffixes=1 -l "1000000" "dndsCodingIntCov.tsv" "subsetsCov/subset_"

# Comb all regions
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
module load bedtools; sort -k1,1 -k2,2n geneCodingIntervalsComb.bed | bedtools merge -c 4 -o distinct > geneCodingIntervalsSortedComb.bed
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
bsub -e jobLogs/bp.intC.err -o jobLogs/bp.intC.out -J preFilter_vep -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M100000 "module load bedtools; bedtools intersect -a  allOppsCov.vcf -b geneCodingIntervalsSortedComb.bed -wa > dndsCodingIntCovComb.tsv"

split --numeric-suffixes=1 -l "1000000" "dndsCodingIntCovComb.tsv" "subsetsCovComb/subset_"

# Pull out regions being annotated for multiple genes
grep "," geneCodingIntervalsSorted.bed > multiGeneRegions.bed


# Exome version
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
for i in {01..98}; do
    echo ${i}
    # Submit a job with the number as an input argument
    bsub -e jobLogs/bp_${i}.err -o jobLogs/bp_${i}.out -J preFilter_vep_${i} -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 "Rscript annot_dNdS.R ${i} exome"
done
# Comb version
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
for i in {01..98}; do
    echo ${i}
    # Submit a job with the number as an input argument
    bsub -e jobLogs/bp_${i}.err -o jobLogs/bp_${i}.out -J preFilter_vep_${i} -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 "Rscript annot_dNdS.R ${i} comb"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
cat subsetsCov/summed* > mutAnnotCov.tsv
cat subsetsCovComb/summed* > mutAnnotCovComb.tsv

# Creates per bp ref with both exome only and comb in annotations of ref object
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
bsub -e jobLogs/bp.ref.err -o jobLogs/bp.ref.out -J preFilter_vep -q normal -R 'select[mem>=200000] rusage[mem=200000] span[hosts=1]' -M200000 "Rscript createRef.R"
```

### Trinuc Ref Meth adjust
#### Script filter meth sites
```{r dndsMatrix}

#!/usr/bin/env Rscript

# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
input_file <- commandArgs(trailingOnly = TRUE)[1]

library(tidyverse)

# dnds format variant file
methVars <- read_tsv(paste0(input_file, ".tsv"), col_types = 'cdccddcd', col_names = c("chr", "pos", "ref", "alt", "covEx", "covComb", "tri","meth")) |> 
  mutate(triSub = paste0(tri, ">", substr(tri,1,1), alt, substr(tri,3,3))) |> 
  mutate(isCpGtoT = if_else((substr(triSub,2,3) == "CG" & alt == "T") | (substr(triSub,1,2) == "CG" & alt == "A"), T,F)) |> 
  filter(isCpGtoT) |> 
  mutate(methGroup = if_else(meth <= 10, "low", "none")) |> 
  mutate(methGroup = if_else(meth > 40, "high", methGroup)) |> 
  filter(methGroup %in% c("low", "high")) |> 
  select(chr, pos, ref, mut = alt, covEx, covComb, methGroup)

write_tsv(methVars, paste0("summarized.", input_file, ".tsv"))
```

#### Create adjust Matrix BP
Version correcting for bp coverage
```{r dndsMatrix}
#!/usr/bin/env Rscript
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
library(tidyverse)
library(dndscv)
refcdsAdj <- paste0(dndsPath,"customMask/RefCDS_GRCh37_v19_twinsUKmasked.Rdat")
load(refcdsAdj)

methMuts <- read_tsv(paste0(dndsPath, "meth_dNdS/summarized.vepMethCov.tsv"), col_types = 'cdccddc')

dndsInput <- methMuts |> mutate(sampleID = "none") |> 
  select(sampleID, chr:mut) 

# annotate mutations
dndsout = dndscv(dndsInput, refdb=refcdsAdj,cv=NULL,max_coding_muts_per_sample=Inf,max_muts_per_gene_per_sample=Inf,outmats=T)

methAnnot = dndsout$annotmuts |> left_join(methMuts) |> 
  mutate(trisub = paste0(ref3_cod, ">" , mut3_cod)) |> 
  mutate(methsub = paste0("z_", methGroup, trisub))  |> 
  mutate(across(c(10:15), as.character))

# Create index
nt = c("A", "C", "G", "T")
trinucs = paste(rep(nt, each = 16, times = 1), rep(nt, each = 4, 
                                                   times = 4), rep(nt, each = 1, times = 16), sep = "")
trinucinds = setNames(1:64, trinucs)
trinucsubs = NULL
for (j in 1:length(trinucs)) {
  trinucsubs = c(trinucsubs, paste(trinucs[j], paste(substr(trinucs[j], 
                                                            1, 1), setdiff(nt, substr(trinucs[j], 2, 2)), substr(trinucs[j], 
                                                                                                                 3, 3), sep = ""), sep = ">"))
}
trinucsubsind = setNames(1:192, trinucsubs)

methSubs <- sort(unique(c(methAnnot$methsub, trinucsubs)))
methSubsInd = setNames(1:208, methSubs)
impInd = c("Synonymous","Missense","Nonsense","Essential_Splice")
allg = sapply(RefCDS, function(x) x$gene_name)

# Add index
methAnnotInd <- methAnnot |> 
  filter(gene %in% allg) |> 
  drop_na(covEx) |> 
  filter(impact %in% impInd) |> 
  mutate(geneind = match(gene, allg)) |> 
  mutate(methind = match(methsub, methSubs)) |> 
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd))
methAnnotIndComb <- methAnnot |> 
  filter(gene %in% allg) |> 
  drop_na(covComb) |> 
  filter(impact %in% impInd) |> 
  mutate(geneind = match(gene, allg)) |> 
  mutate(methind = match(methsub, methSubs)) |> 
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd))

# Create M matrix of methSubs for each gene
for (gene in 1:length(RefCDS)) {
  # Meth array is normal trinuc array minus cpg sites that are high or low meth
  RefCDS[[gene]]$M = RefCDS[[gene]]$L - dndsout$N[,,gene]
  # Append the zeros matrix to the bottom and add in cpg sites at new index
  RefCDS[[gene]]$M <- rbind(RefCDS[[gene]]$M, matrix(0, nrow = 16, ncol = 4))
}

# Append mutations to matrix
for (j in 1:nrow(methAnnotInd)) {
    geneind = methAnnotInd$geneind[j]
    methind = methAnnotInd$methind[j]
    impind = methAnnotInd$impind[j]
    RefCDS[[geneind]]$M[methind, impind] = RefCDS[[geneind]]$M[methind, impind] + 1
}

Mall = array(sapply(RefCDS, function(x) x$M), dim = c(208, 
                                                        4, length(RefCDS)))
save(Mall, methSubs, file = "meth_dNdS_array.Rdata")

# Version for per BP
for (gene in 1:length(RefCDS)) {
  # Append the zeros matrix to the bottom and add in cpg sites at new index
  RefCDS[[gene]]$M_BP <- rbind(RefCDS[[gene]]$BP, matrix(0, nrow = 16, ncol = 4))
  RefCDS[[gene]]$M_BPcomb <- rbind(RefCDS[[gene]]$BPcomb, matrix(0, nrow = 16, ncol = 4))
}

# Subtract from original cat and append mutations to new category
for (j in 1:nrow(methAnnotInd)) {
    geneind = methAnnotInd$geneind[j]
    methind = methAnnotInd$methind[j]
    triind = methAnnotInd$triind[j]
    impind = methAnnotInd$impind[j]
    RefCDS[[geneind]]$M_BP[triind, impind] = RefCDS[[geneind]]$M_BP[triind, impind] - methAnnotInd$covEx[j]
    RefCDS[[geneind]]$M_BP[methind, impind] = RefCDS[[geneind]]$M_BP[methind, impind] + methAnnotInd$covEx[j]
}

# Version for per BP comb with targeted coverage
# Subtract from original cat and append mutations to new category
for (j in 1:nrow(methAnnotIndComb)) {
    geneind = methAnnotIndComb$geneind[j]
    methind = methAnnotIndComb$methind[j]
    triind = methAnnotIndComb$triind[j]
    impind = methAnnotIndComb$impind[j]
    RefCDS[[geneind]]$M_BPcomb[triind, impind] = RefCDS[[geneind]]$M_BPcomb[triind, impind] - methAnnotIndComb$covComb[j]
    RefCDS[[geneind]]$M_BPcomb[methind, impind] = RefCDS[[geneind]]$M_BPcomb[methind, impind] + methAnnotIndComb$covComb[j]
}

M_BPall = array(sapply(RefCDS, function(x) x$M_BP), dim = c(208, 4, length(RefCDS)))
save(M_BPall, methSubs, file = "methBP_dNdS_array.Rdata")
save(RefCDS, file = "methBP_RefCDS.Rdata")
```

#### Run scripts
```{bash maf}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/meth_dNdS/

#!/bin/bash
cat /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep/splitChrVEP/*.tsv | grep -v '#' | awk -F'\t' -v OFS='\t' '$47 != "-" {split($2, arr, ":"); gsub(/,.*/, "", $7); gsub(/_variant/, "", $7); print arr[1], arr[2], $14, $3, $44, $45, $46, $47}' > /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/meth_dNdS/vepMethCov.tsv

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/meth_dNdS/
bsub -e jobLogs/%J.err -o jobLogs/%J.out -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 ./getMethCovSites.sh 

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/meth_dNdS/
bsub -e jobLogs/%J.err -o jobLogs/%J.out -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 Rscript filterMethSites.R vepMethCov

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/meth_dNdS/
bsub -e jobLogs/%J.err -o jobLogs/%J.out -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 Rscript createArray.R

```

### Penta version
#### Variant files
```{r variantsPenta}
# Combined mutations
combVars <- collapsedTargVars |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt) |> 
  distinct()
combVarsMeth <- collapsedTargVars |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt, methGroup = methBin) |> 
  distinct()

# Exome only vars with meth annot
exomeVarsMeth <- analysisTargVars |> filter(nanoseq == "Exome") |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt, methGroup = methBin) |> 
  distinct()
exomeVars_dNdS <- analysisTargVars |> filter(nanoseq == "Exome") |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt) |> 
  distinct()
# Exome only vars with age
exomeVarsMethAge <- analysisTargVars |> filter(nanoseq == "Exome") |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt, methGroup = methBin, age = age_at_sampling) |> 
  distinct()
exomeVars_dNdSAge <- analysisTargVars |> filter(nanoseq == "Exome") |> 
  select(sampleID = indiv, chr, pos = start, ref, mut = alt, age = age_at_sampling) |> 
  distinct()

# Write to cluster for running penta models
write_tsv(combVars, paste0(dndsPath, "inputFor_dNdS/mutationsInput/combVars.tsv"))
write_tsv(combVarsMeth, paste0(dndsPath, "inputFor_dNdS/mutationsInput/combVarsMeth.tsv"))
write_tsv(exomeVars_dNdS, paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdS.tsv"))
write_tsv(exomeVarsMeth, paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMeth.tsv"))
write_tsv(exomeVars_dNdSAge, paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdSAge.tsv"))
write_tsv(exomeVarsMethAge, paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMethAge.tsv"))
```

#### Mut annot summary
```{r dndsMatrix}
#!/usr/bin/env Rscript
# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
input_index <- commandArgs(trailingOnly = TRUE)[1]
covType <- commandArgs(trailingOnly = TRUE)[2]

dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
library(tidyverse)
library(dndscv)
library(Rsamtools)
library(seqinr)
refcdsAdj <- paste0(dndsPath,"customMask/RefCDS_GRCh37_v19_twinsUKmasked.Rdat")
load(refcdsAdj)


if(covType == "exome") {
  pathSubset <- "pentaSubsetsCov"
  geneMutsCov <- read_tsv(paste0(dndsPath, "basePairRef/subsetsCov/subset_",input_index), col_types = 'cdccd--', col_names = c("chr", "pos", "ref", "mut","cov")) |> 
    drop_na(cov)
} else if(covType == "comb") {
  pathSubset <- "pentaSubsetsCovComb"
  geneMutsCov <- read_tsv(paste0(dndsPath, "basePairRef/subsetsCovComb/subset_",input_index), col_types = 'cdcc-d-', col_names = c("chr", "pos", "ref", "mut","cov")) |> 
    drop_na(cov)
}
  
dndsInput <- geneMutsCov |> mutate(sampleID = "none") |> 
  select(sampleID, chr:mut)

# Load function that annotates penta context
source(paste0(dndsPath, "basePairRef/dndsAnnotMutsPenta.R"))

dndsout <- dndscvAnnotPenta(dndsInput, genomefile = "/lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa", refdb=refcdsAdj,cv=NULL,max_coding_muts_per_sample=Inf,max_muts_per_gene_per_sample=Inf)

covAnnot <- dndsout |> left_join(geneMutsCov) |> 
  mutate(trisub = paste0(ref3_cod, ">" , mut3_cod)) |> 
  select(chr:gene, impact, trisub, penta_sub, cov) |> 
  group_by(trisub,penta_sub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(impact = as.character(impact))
write_tsv(covAnnot, paste0(dndsPath, "basePairRef/",pathSubset,"/summed_", input_index, ".txt"), col_names = F)
```


#### Create matrix
```{r dndsMatrix}
#!/usr/bin/env Rscript

library(tidyverse)
library(dndscv)
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
refcdsAdj <- paste0(dndsPath,"customMask/RefCDS_GRCh37_v19_twinsUKmasked.Rdat")
load(refcdsAdj)

# Initialize an empty list to store the subsetted elements
subset_RefCDS <- list()

# Loop through each element of RefCDS and check if gene_name is in exome covered geneList
load(paste0(dndsPath, "basePairRef/dndsCov.Rdata"))
for (i in 1:length(RefCDS)) {
  if (RefCDS[[i]]$gene_name %in% names(vCovEx)) {
    subset_RefCDS[[i]] <- RefCDS[[i]]
  }
}

# Filter out NULL elements
subset_RefCDS <- subset_RefCDS[!sapply(subset_RefCDS, is.null)]

# TRINUC
nt = c("A", "C", "G", "T")
trinucs = paste(rep(nt, each = 16, times = 1), rep(nt, each = 4, 
                                                   times = 4), rep(nt, each = 1, times = 16), sep = "")
trinucinds = setNames(1:64, trinucs)
trinucsubs = NULL
for (j in 1:length(trinucs)) {
  trinucsubs = c(trinucsubs, paste(trinucs[j], paste(substr(trinucs[j], 
                                                            1, 1), setdiff(nt, substr(trinucs[j], 2, 2)), substr(trinucs[j], 
                                                                                                                 3, 3), sep = ""), sep = ">"))}
trinucsubsind = setNames(1:192, trinucsubs)

impInd = c("Synonymous","Missense","Nonsense","Essential_Splice")
allg = sapply(subset_RefCDS, function(x) x$gene_name)

# PENTA
pentanuc_list = paste(rep(nt,each=4^4,times=1),rep(nt,each=4^3,times=4),rep(nt,each=4^2,times=4^2),rep(nt,each=4,times=4^3),rep(nt,each=1,times=4^4), sep="")
pentanuc_subs = c(sapply(pentanuc_list, function(x) paste(x, paste(substr(x,1,2),nt[nt!=substr(x,3,3)],substr(x,4,5),sep=""), sep=">")))
pentanuc_subs_ind = 1:3072; names(pentanuc_subs_ind) = pentanuc_subs

message("Read in files...")
covAnnotInd0 <- read_tsv(paste0(dndsPath, "basePairRef/mutPentaAnnotCov.tsv"), col_types = 'ccccd', col_names = c("trisub","pentasub", "impact","gene","cov")) |> 
  group_by(pentasub,trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") 

covAnnotIndTri <- covAnnotInd0 |> 
  group_by(trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

covAnnotIndPenta <- covAnnotInd0 |> select(-trisub) |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(pentaind = match(pentasub, pentanuc_subs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

covAnnotIndComb0 <- read_tsv(paste0(dndsPath, "basePairRef/mutPentaAnnotCovComb.tsv"), col_types = 'ccccd', col_names = c("trisub","pentasub","impact","gene","cov")) |> 
  group_by(pentasub,trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop")

covAnnotIndCombTri <- covAnnotIndComb0 |> 
  group_by(trisub,impact,gene) |> summarize(cov = sum(cov), .groups = "drop") |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

covAnnotIndCombPenta <- covAnnotIndComb0 |> select(-trisub) |> 
  mutate(geneind = match(gene, allg)) |>
  mutate(pentaind = match(pentasub, pentanuc_subs)) |> 
  mutate(impind = match(impact, impInd)) |> 
  filter(impact %in% impInd) |> 
  drop_na(geneind)

message("Create ref matrices...")
# Create BP matrix of per bp cov
for (gene in 1:length(subset_RefCDS)) {
  subset_RefCDS[[gene]]$BP = array(0, dim=c(192,4))
  subset_RefCDS[[gene]]$BPcomb = array(0, dim=c(192,4))
  subset_RefCDS[[gene]]$BP_Penta = array(0, dim=c(3072,4))
  subset_RefCDS[[gene]]$BP_Pentacomb = array(0, dim=c(3072,4))
}
  
# Append mutations to matrix
for (j in 1:nrow(covAnnotIndTri)) {
    geneind = covAnnotIndTri$geneind[j]
    triind = covAnnotIndTri$triind[j]
    impind = covAnnotIndTri$impind[j]
    subset_RefCDS[[geneind]]$BP[triind, impind] = subset_RefCDS[[geneind]]$BP[triind, impind] + covAnnotIndTri$cov[j]
}
for (j in 1:nrow(covAnnotIndPenta)) {
    geneind = covAnnotIndPenta$geneind[j]
    pentaind = covAnnotIndPenta$pentaind[j]
    impind = covAnnotIndPenta$impind[j]
    subset_RefCDS[[geneind]]$BP_Penta[pentaind, impind] = subset_RefCDS[[geneind]]$BP_Penta[pentaind, impind] + covAnnotIndPenta$cov[j]
}
for (j in 1:nrow(covAnnotIndCombTri)) {
    geneind = covAnnotIndCombTri$geneind[j]
    triind = covAnnotIndCombTri$triind[j]
    impind = covAnnotIndCombTri$impind[j]
    subset_RefCDS[[geneind]]$BPcomb[triind, impind] = subset_RefCDS[[geneind]]$BPcomb[triind, impind] + covAnnotIndCombTri$cov[j]
}
for (j in 1:nrow(covAnnotIndCombPenta)) {
    geneind = covAnnotIndCombPenta$geneind[j]
    pentaind = covAnnotIndCombPenta$pentaind[j]
    impind = covAnnotIndCombPenta$impind[j]
    subset_RefCDS[[geneind]]$BP_Pentacomb[pentaind, impind] = subset_RefCDS[[geneind]]$BP_Pentacomb[pentaind, impind] + covAnnotIndCombPenta$cov[j]
}

RefCDS <- subset_RefCDS
outFile <- paste0(dndsPath, "basePairRef/refCDSbpPenta.Rdat")
message(paste0("Saving to ", outFile))
save(RefCDS, file = outFile)

```


#### Meth adjust
```{r dndsMatrix}
#!/usr/bin/env Rscript
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
library(Rsamtools)
library(seqinr)
library(dndscv)
library(tidyverse)
refcdsAdj <- paste0(dndsPath,"basePairRef/refCDSbpPenta.Rdat")
load(refcdsAdj)
load(paste0(dndsPath, "basePairRef/gr_genes.Rdata"))

methMuts <- read_tsv(paste0(dndsPath, "meth_dNdS/summarized.vepMethCov.tsv"), col_types = 'cdccddc')

dndsInput <- methMuts |> mutate(sampleID = "none") |> 
  select(sampleID, chr:mut) 

# Load function that annotates penta context
source(paste0(dndsPath, "basePairRef/dndsAnnotMutsPenta.R"))


dndsout <- dndscvAnnotPenta(dndsInput, genomefile = "/lustre/scratch124/casm/team78pipelines/reference/human/GRCh37d5/genome.fa", refdb=refcdsAdj,cv=NULL,max_coding_muts_per_sample=Inf,max_muts_per_gene_per_sample=Inf)


methAnnot = dndsout |> left_join(methMuts) |> 
  mutate(trisub = paste0(ref3_cod, ">" , mut3_cod)) |> 
  mutate(methsub = paste0("z_", methGroup, trisub))  |> 
  mutate(across(c(10:15), as.character)) |> 
  mutate(penta_methsub = paste0("z_", methGroup, penta_sub))

# TRI -------------------------------------------------------------
nt = c("A", "C", "G", "T")
trinucs = paste(rep(nt, each = 16, times = 1), rep(nt, each = 4, 
                                                   times = 4), rep(nt, each = 1, times = 16), sep = "")
trinucinds = setNames(1:64, trinucs)
trinucsubs = NULL
for (j in 1:length(trinucs)) {
  trinucsubs = c(trinucsubs, paste(trinucs[j], paste(substr(trinucs[j], 
                                                            1, 1), setdiff(nt, substr(trinucs[j], 2, 2)), substr(trinucs[j], 
                                                                                                                 3, 3), sep = ""), sep = ">"))}
trinucsubsind = setNames(1:192, trinucsubs)

# Meth
methSubs = trinucsubs

for (j in 1:length(trinucsubs)) {
  # Check for C>T substitution at CpG site: C>T means 6th character is "T"
  if (substr(trinucsubs[j], 6, 6) == "T" && substr(trinucsubs[j], 2, 2) == "C" && substr(trinucsubs[j], 3, 3) == "G") {
    # Add z_high and z_low prefixed substitutions for C>T at CpG
    methSubs = c(methSubs, 
                 paste0("z_high", trinucsubs[j]),
                 paste0("z_low", trinucsubs[j]))
  }
  # Check for G>A substitution at reverse CpG site: G>A means 6th character is "A"
  if (substr(trinucsubs[j], 6, 6) == "A" && substr(trinucsubs[j], 2, 2) == "G" && substr(trinucsubs[j], 1, 1) == "C") {
    # Add z_high and z_low prefixed substitutions for G>A at reverse CpG
    methSubs = c(methSubs, 
                 paste0("z_high", trinucsubs[j]),
                 paste0("z_low", trinucsubs[j]))
  }
}
# Create indices for methSubs
methSubsInd = setNames(1:length(methSubs), methSubs)



# PENTA -------------------------------------------------------------
pentanuc_list = paste(rep(nt,each=4^4,times=1),rep(nt,each=4^3,times=4),rep(nt,each=4^2,times=4^2),rep(nt,each=4,times=4^3),rep(nt,each=1,times=4^4), sep="")
pentanuc_subs = c(sapply(pentanuc_list, function(x) paste(x, paste(substr(x,1,2),nt[nt!=substr(x,3,3)],substr(x,4,5),sep=""), sep=">")))
pentanuc_subs_ind = 1:3072; names(pentanuc_subs_ind) = pentanuc_subs

methPentaSubs = pentanuc_subs

for (j in 1:length(pentanuc_subs)) {
  # Check for C>T substitution at CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "T" && substr(pentanuc_subs[j], 3, 3) == "C" && substr(pentanuc_subs[j], 4, 4) == "G") {
    # Add z_high and z_low prefixed substitutions for C>T at CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_high", pentanuc_subs[j]),
                      paste0("z_low", pentanuc_subs[j]))
  }
  # Check for G>A substitution at reverse CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "A" && substr(pentanuc_subs[j], 3, 3) == "G" && substr(pentanuc_subs[j], 2, 2) == "C") {
    # Add z_high and z_low prefixed substitutions for G>A at reverse CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_high", pentanuc_subs[j]),
                      paste0("z_low", pentanuc_subs[j]))
  }
}

# Create indices for methPentaSubs
methPentaSubsInd = setNames(1:length(methPentaSubs), methPentaSubs)

impInd = c("Synonymous","Missense","Nonsense","Essential_Splice")
allg = sapply(RefCDS, function(x) x$gene_name)

# Add index
methAnnotInd <- methAnnot |> 
  filter(gene %in% allg) |> 
  drop_na(covEx) |> 
  filter(impact %in% impInd) |> 
  mutate(geneind = match(gene, allg)) |> 
  mutate(methind = match(methsub, methSubs)) |> 
  mutate(pentamethind = match(penta_methsub, methPentaSubs)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(pentaind = match(penta_sub, pentanuc_subs)) |>
  mutate(impind = match(impact, impInd)) 
methAnnotIndComb <- methAnnot |> 
  filter(gene %in% allg) |> 
  drop_na(covComb) |> 
  filter(impact %in% impInd) |> 
  mutate(geneind = match(gene, allg)) |> 
  mutate(methind = match(methsub, methSubs)) |> 
  mutate(pentamethind = match(penta_methsub, methPentaSubs)) |>
  mutate(triind = match(trisub, trinucsubs)) |> 
  mutate(pentaind = match(penta_sub, pentanuc_subs)) |>
  mutate(impind = match(impact, impInd)) 

# Version for per BP
for (gene in 1:length(RefCDS)) {
  # Append the zeros matrix to the bottom and add in cpg sites at new index
  RefCDS[[gene]]$M_BP <- rbind(RefCDS[[gene]]$BP, matrix(0, nrow = 16, ncol = 4))
  RefCDS[[gene]]$M_BPcomb <- rbind(RefCDS[[gene]]$BPcomb, matrix(0, nrow = 16, ncol = 4))
  RefCDS[[gene]]$M_BP_Penta <- rbind(RefCDS[[gene]]$BP_Penta, matrix(0, nrow = 256, ncol = 4))
  RefCDS[[gene]]$M_BP_Pentacomb <- rbind(RefCDS[[gene]]$BP_Pentacomb, matrix(0, nrow = 256, ncol = 4))
}

# Subtract from original cat and append mutations to new category
for (j in 1:nrow(methAnnotInd)) {
    geneind = methAnnotInd$geneind[j]
    methind = methAnnotInd$methind[j]
    triind = methAnnotInd$triind[j]
    impind = methAnnotInd$impind[j]
    RefCDS[[geneind]]$M_BP[triind, impind] = RefCDS[[geneind]]$M_BP[triind, impind] - methAnnotInd$covEx[j]
    RefCDS[[geneind]]$M_BP[methind, impind] = RefCDS[[geneind]]$M_BP[methind, impind] + methAnnotInd$covEx[j]
}

# Version for per BP comb with targeted coverage
# Subtract from original cat and append mutations to new category
for (j in 1:nrow(methAnnotIndComb)) {
    geneind = methAnnotIndComb$geneind[j]
    methind = methAnnotIndComb$methind[j]
    triind = methAnnotIndComb$triind[j]
    impind = methAnnotIndComb$impind[j]
    RefCDS[[geneind]]$M_BPcomb[triind, impind] = RefCDS[[geneind]]$M_BPcomb[triind, impind] - methAnnotIndComb$covComb[j]
    RefCDS[[geneind]]$M_BPcomb[methind, impind] = RefCDS[[geneind]]$M_BPcomb[methind, impind] + methAnnotIndComb$covComb[j]
}
# Penta
for (j in 1:nrow(methAnnotInd)) {
    geneind = methAnnotInd$geneind[j]
    pentamethind = methAnnotInd$pentamethind[j]
    pentaind = methAnnotInd$pentaind[j]
    impind = methAnnotInd$impind[j]
    RefCDS[[geneind]]$M_BP_Penta[pentaind, impind] = RefCDS[[geneind]]$M_BP_Penta[pentaind, impind] - methAnnotInd$covEx[j]
    RefCDS[[geneind]]$M_BP_Penta[pentamethind, impind] = RefCDS[[geneind]]$M_BP_Penta[pentamethind, impind] + methAnnotInd$covEx[j]
}
for (j in 1:nrow(methAnnotIndComb)) {
    geneind = methAnnotIndComb$geneind[j]
    pentamethind = methAnnotIndComb$pentamethind[j]
    pentaind = methAnnotIndComb$pentaind[j]
    impind = methAnnotIndComb$impind[j]
    RefCDS[[geneind]]$M_BP_Pentacomb[pentaind, impind] = RefCDS[[geneind]]$M_BP_Pentacomb[pentaind, impind] - methAnnotIndComb$covComb[j]
    RefCDS[[geneind]]$M_BP_Pentacomb[pentamethind, impind] = RefCDS[[geneind]]$M_BP_Pentacomb[pentamethind, impind] + methAnnotIndComb$covComb[j]
}

save(RefCDS, file = "methBPPenta_RefCDS.Rdata")
M_BPall = array(sapply(RefCDS, function(x) x$M_BP), dim = c(208, 4, length(RefCDS)))
save(M_BPall, methSubs, file = "methBP_dNdS_array.Rdata")
M_BPPentaall = array(sapply(RefCDS, function(x) x$M_BP_Penta), dim = c(3328, 4, length(RefCDS)))
save(M_BPall, methSubs, file = "methBP_dNdS_array.Rdata")
save(RefCDS, file = "methBPPenta_RefCDS.Rdata")
```

#### Run scripts penta
```{bash dndsref}

# Exome version
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
for i in {01..98}; do
    echo ${i}
    # Submit a job with the number as an input argument
    bsub -e jobLogs/pentabp_${i}.err -o jobLogs/pentabp_${i}.out -J preFilter_vep_${i} -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 "Rscript annotPenta_dNdS.R ${i} exome"
done
# Comb version
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
for i in {01..98}; do
    echo ${i}
    # Submit a job with the number as an input argument
    bsub -e jobLogs/pentabp_${i}.err -o jobLogs/pentabp_${i}.out -J preFilter_vep_${i} -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 "Rscript annotPenta_dNdS.R ${i} comb"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
cat pentaSubsetsCov/summed* > mutPentaAnnotCov.tsv
cat pentaSubsetsCovComb/summed* > mutPentaAnnotCovComb.tsv

# Creates per bp ref with both exome only and comb in annotations of ref object
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/basePairRef/
bsub -e jobLogs/bp.ref.err -o jobLogs/bp.ref.out -J preFilter_vep -q normal -R 'select[mem>=40000] rusage[mem=40000] span[hosts=1]' -M40000 "Rscript createRefPenta.R"

# Adjust with methylation annotation
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS/
bsub -e jobLogs/%J.err -o jobLogs/%J.out -q normal -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 Rscript createMethArrayPenta.R

```

### Penta context
```{r dndsPentaContext}
tri <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/mle_submodel_TriMethExomeAll.tsv"), col_types = cols()) |> 
  filter(!name %in% c("wmis", "wspl", "wnon")) |> 
  # Handle meth
  mutate(meth = if_else(str_detect(name, "z_High"), "High", "Mid")) |> mutate(meth = if_else(str_detect(name, "z_Low"), "Low", meth)) |> 
  mutate(name = if_else(str_detect(name, "z_High"), str_sub(name, 7,14), name)) |> mutate(name = if_else(str_detect(name, "z_Low"), str_sub(name, 6,13), name)) |> 
  rename(tri = name, triRate = mle, tricilow = cilow, tricihigh = cihigh)

penta <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/mle_submodel_PentaMethExomeAll.tsv"), col_types = cols()) |> 
  # Remove no estimate
  filter(!name %in% c("wmis", "wspl", "wnon")) |> 
  # Handle meth
  mutate(meth = if_else(str_detect(name, "z_High"), "High", "Mid")) |> mutate(meth = if_else(str_detect(name, "z_Low"), "Low", meth)) |> 
  mutate(name = if_else(str_detect(name, "z_High"), str_sub(name, 7,18), name)) |> mutate(name = if_else(str_detect(name, "z_Low"), str_sub(name, 6,17), name)) |> 
  rename(penta = name, pentaRate = mle, pentacilow = cilow, pentacihigh = cihigh) |> 
  mutate(tri = paste0(str_sub(penta,2,4), ">", str_sub(penta,8,10)))

# Function to calculate standard error from confidence interval
calc_se <- function(ci_high, ci_low) {
  (ci_high - ci_low) / (2 * 1.96)  # CI to SE conversion assuming 95% CI
}

# Calculate the difference in rates, their standard errors, z-scores, and FDR-corrected p-values
pentaCompare <- penta |> left_join(tri, join_by(meth, tri)) |>
  mutate(
    # Calculate standard errors for pentanucleotide and trinucleotide contexts
    penta_se = calc_se(pentacihigh, pentacilow),
    tri_se = calc_se(tricihigh, tricilow),
    
    # Calculate the difference in mutation rates
    rate_diff = pentaRate - triRate,
    
    # Combined standard error for the difference
    diff_se = sqrt(penta_se^2 + tri_se^2),
    
    # Calculate z-score for the difference
    z_score = rate_diff / diff_se,
    
    # p-value from z-score (two-tailed test)
    p_value = 2 * pnorm(-abs(z_score)),
    
    # FDR-corrected p-value (Benjamini-Hochberg correction)
    p_adj_fdr = p.adjust(p_value, method = "fdr")
  )

pentaSig = pentaCompare |> arrange(p_adj_fdr)
write_tsv(pentaSig, paste0(paperPath, "extended/supTable_pentaMutRates.tsv"))

sigTris <- pentaSig |> filter(p_adj_fdr < 0.05) |> 
  group_by(tri, meth) |> summarize(count = n())
```

### Compare sig genes
```{r dndsGlobalComp, fig.height = 7, fig.width=4}

basic_ranked_genes <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_PentaMethCombAll.tsv"), col_types = cols()) |>
  arrange(-qglobal_cv) |> 
  pull(gene_name)

compGene_dNdSexome <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_TriCombAll.tsv"), col_types = cols()) |> 
  mutate(test = "BasePairCov") |> 
  bind_rows(read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_TriMethCombAll.tsv"), col_types = cols()) |> 
              mutate(test = "BasePairCov +\nCpGmeth")) |> 
  bind_rows(
    read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_PentaMethCombAll.tsv"), col_types = cols()) |> 
      mutate(test = "BasePairCov +\nCpGmeth +\nPenta")) |> 
  filter(qglobal_cv < 0.1) |>
  select(gene_name, test, qglobal_cv) |>
  mutate( rank = 2)

# Keep the bind_rows part unchanged and add ordering based on significance and gene rank
compGene_dNdScomb <- compGene_dNdSexome |> 
  bind_rows((read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_TriCombTarg.tsv"), col_types = cols()) |> 
              mutate(test = "BasePairCov")) |> 
  bind_rows(read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_TriMethCombTarg.tsv"), col_types = cols()) |> 
              mutate(test = "BasePairCov +\nCpGmeth")) |> 
  bind_rows(
    read_tsv(paste0(dndsPath, "inputFor_dNdS/results/sel_cv_PentaMethCombTarg.tsv"), col_types = cols()) |> 
      mutate(test = "BasePairCov +\nCpGmeth +\nPenta")) |> 
  filter(qglobal_cv < 0.1) |> 
  select(gene_name, test, qglobal_cv) |> 
  mutate(rank = 1)) |> 
  group_by(gene_name, test) |> 
  summarize(rank = max(rank), .groups = "drop") |> 
  mutate(Significant = if_else(rank == 2, "Exome-wide", "Restricted\nhypothesis")) |> 
  select(-rank) |> 
  complete(gene_name, test, fill = list(Significant = "NS")) |> 
  mutate(Significant = factor(Significant, levels = c("Exome-wide", "Restricted\nhypothesis", "NS"))) |> # Set order for significance
  mutate(gene_name = factor(gene_name, levels = basic_ranked_genes)) |> 
  filter(gene_name != "SEMG1")
```

### Run all dNdS models
#### Load large dNdS objects
Avoids running full functions
```{r dndsLoad}
# Gene/global tests
load(paste0(paperPath, "data/dndsObjects.Rdata"))
# Hotspot tests
load(paste0(paperPath, "data/hotspot_dNdSobjects.Rdata"))

```

##### Run dNdS
```{r dndsGlobal}

# Restricted hypothesis test on just target panel genes
dndsCombRHT <- dndscvMethBP(combVarsMeth |> select(-methGroup), cv=scores, refdb=methRefPath, gene_list = names(vCovTarg), max_coding_muts_per_sample = Inf, max_muts_per_gene_per_sample = Inf, methAnnotatedVars = combVarsMeth, methSubs = methSubs, methVersion = "methBPcomb")

# Write out muts for lollipop script
write_tsv(dndsComb$annotmuts, paste0(dndsPath, "dNdSannotMuts.tsv"))

# Quick reload of already created objects
# save(dndsExomeOnly, dndsComb, dndsCombRHT, file = paste0(paperPath, "data/dndsObjects.Rdata"))
```

##### Hotspot-level 
```{r sitedNdS}
# Exome-wide hotspot
refcds_37_bp10k <- paste0(dndsPath, "basePairRef/refCDSbp10kRound.Rdat")
load(refcds_37_bp10k)

totTargCov <- read_tsv("/Users/mn7/volumes/mn7_lustre/sperm/targeted/postNextflow/cov/totalCovMerged_Coding.bed", col_types = "c-dd", col_names = c("chr", "start", "cov"))

meanCov <- mean(totTargCov$cov)
combVars_codingCov <- collapsedTargVars |>
  left_join(totTargCov, by = join_by(chr, start)) |> 
  mutate(relmrCov = cov/meanCov) |>
   select(sampleID = indiv, chr, pos = start, ref, mut = alt, relmrCov) |> 
  drop_na() |> 
  distinct()

# Correct rvector by duplex depth
vCovExSite = vCovEx[!names(vCovEx) %in% genesExcludeNoSyn]
dndsCombNoCovBP10k <- dndscvBP(combVars_coding, refdb=refcds_37_bp10k, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf,
                            outmats = T, gene_list = names(vCovExSite), dc = vCovComb)

df_relmrCov <- combVars_codingCov |> 
  select(-sampleID) |> 
  distinct()

source(paste0(paperPath, "data/site_dndsCovGenePanel.R"))

exomeWideHotspots_dndsRelCov = sitedndsRelCov(dndsCombNoCovBP10k, min_recurr = 3, gene_list = names(vCovExSite), siteRelativeCoverage = df_relmrCov)

exomeWideHotspots_dndsRelCov_sig0 <- exomeWideHotspots_dndsRelCov$recursites |> 
  mutate(qval = signif(qval, 3), dnds = as.numeric(round(dnds)), mu = signif(mu, 3)) |> mutate(freq = as.numeric(freq)) |> 
  select(chr,pos,ref,mut,gene,aachange,impact,obs = freq, exp = mu,dnds_ratio = dnds,qval_exome = qval) 

exomeWideHotspots_dndsRelCov_sig <- exomeWideHotspots_dndsRelCov_sig0 |> filter(qval_exome<0.1) 

# Restricted hypothesis test: A priori hotspot sites from TCGA and DDD combined
hotspots_TCGA_DDD <- read_csv(paste0(paperPath,"data/New_dNdS_hotspots.csv"), col_types = cols()) |> 
  bind_rows(read_tsv("~/Google Drive/My Drive/Hurles/MutModel/processTrioDNMs/DDDmuts2020.txt", col_types = cols()) |> 
  select(symbol, chr = chrom, pos, ref, mut = alt)  |> 
  group_by(chr, pos, ref, mut) |> summarise(recur = n(), .groups = "drop") |> 
  filter(recur > 1) |> select(-recur)) |> 
  distinct(chr,pos,ref,mut) |> 
  mutate(sample = paste0("dummy", row_number())) |> 
  select(sample, chr,pos,ref,mut) |> 
  drop_na()

dnds_hotspots <- dndscv(mutations = hotspots_TCGA_DDD, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, refdb = refcds_37_nano)

siteHotspots_formatted <- dnds_hotspots$annotmuts |> 
  filter(impact != "no-SNV") |> 
  mutate(site = paste(chr,pos,ref,mut,gene, aachange,ref3_cod, mut3_cod, sep = ":")) |> 
  pull(site)

siteHotspots_dnds = sitedndsRelCov(dndsCombNoCovBP10k, min_recurr = 3, site_list = siteHotspots_formatted, siteRelativeCoverage = df_relmrCov)

siteHotspotsRHT_dnds_sig <- siteHotspots_dnds$recursites |> filter(qval<0.1) |>
  mutate(qval = signif(qval, 3), dnds = as.numeric(round(dnds)), mu = signif(mu, 3)) |> mutate(freq = as.numeric(freq)) |> 
  select(chr,pos,ref,mut,gene,aachange,impact,obs = freq, exp = mu,dnds_ratio = dnds,qval_RHT = qval) 

# Join exome-wide and RHT hotspots, save file and table
hotspotTable <- exomeWideHotspots_dndsRelCov_sig0 |> full_join(siteHotspotsRHT_dnds_sig) |> 
  filter(qval_exome < 0.1 | qval_RHT < 0.1)
write_tsv(hotspotTable, paste0(paperPath, "data/siteHotspots_dnds_sig.tsv"))

gt(hotspotTable)  |> cols_align(align = "left") |> 
  opt_table_font(weight = 500) |> gtsave(paste0(paperPath, "extended/Table_sigSitesdNdS.png"), expand = 10)

save(exomeWideHotspots_dndsRelCov, exomeWideHotspots_dndsRelCov_sig0, exomeWideHotspots_dndsRelCov_sig, siteHotspots_dnds, siteHotspotsRHT_dnds_sig , hotspotTable, file = paste0(paperPath, "data/hotspot_dNdSobjects.Rdata"))
```


#### Test model types
##### Submit script
```{r dndsScript}
#!/usr/bin/env Rscript

# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
inputSet <- commandArgs(trailingOnly = TRUE)[1]
refCDS_type <- commandArgs(trailingOnly = TRUE)[2]
geneSet <- commandArgs(trailingOnly = TRUE)[3]

library(Rsamtools)
library(seqinr)
library(dndscv)
library(tidyverse)
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"

# ref objects
load(paste0(dndsPath, "basePairRef/gr_genes.Rdata"))
refcds <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS/methBPPenta_RefCDS.Rdata"
fafile = paste0(dndsPath, "Homo_sapiens.GRCh37.75.dna.primary_assembly.fa")
# Covariates
load("/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/covariates_20pc_GRCh37-38.epi_strict_outliers.Rdat")
# Gene Lists
load(paste0(dndsPath, "inputFor_dNdS/dndsCov.Rdata"))
vCovTarg <- vCov[names(vCov) %in% names(vCovEx)]
vCovComb <- sapply(split(c(vCov, vCovEx), names(c(vCov, vCovEx))), sum)

if(geneSet == "All") {
  genelist = names(vCovEx)
} else if(geneSet == "Targ") {
  genelist = names(vCovTarg)
} else{
  genelist = read_tsv(paste0(dndsPath, "inputFor_dNdS/geneLists/", geneSet, ".tsv")) |> 
    filter(gene %in% names(vCovEx)) |> 
    pull(gene)
}

# Load custom function
source(paste0(dndsPath, "inputFor_dNdS/dndsPentaMethBPfunction.R"))

# Which dataset to load
if(inputSet == "Exome") {
  mutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdS.tsv"), col_types = cols())
  methMutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMeth.tsv"), col_types = cols())
  geneCov = vCovEx
} else if(inputSet == "Comb") {
  mutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/combVars.tsv"), col_types = cols())
  methMutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/combVarsMeth.tsv"), col_types = cols())
  geneCov = vCovComb
}

#Tri meth sub model
# TRI -------------------------------------------------------------
nt = c("A", "C", "G", "T")
trinucs = paste(rep(nt, each = 16, times = 1), rep(nt, each = 4, times = 4), rep(nt, each = 1, times = 16), sep = "")
trinucinds = setNames(1:64, trinucs)
trinucsubs = NULL
for (j in 1:length(trinucs)) {
  trinucsubs = c(trinucsubs, paste(trinucs[j], paste(substr(trinucs[j], 
                                                            1, 1), setdiff(nt, substr(trinucs[j], 2, 2)), substr(trinucs[j], 
                                                                                                                 3, 3), sep = ""), sep = ">"))}
trinucsubsind = setNames(1:192, trinucsubs)
# Meth
methSubs = trinucsubs
for (j in 1:length(trinucsubs)) {
  # Check for C>T substitution at CpG site: C>T means 6th character is "T"
  if (substr(trinucsubs[j], 6, 6) == "T" && substr(trinucsubs[j], 2, 2) == "C" && substr(trinucsubs[j], 3, 3) == "G") {
    # Add z_high and z_low prefixed substitutions for C>T at CpG
    methSubs = c(methSubs, 
                 paste0("z_High", trinucsubs[j]),
                 paste0("z_Low", trinucsubs[j]))
  }
  # Check for G>A substitution at reverse CpG site: G>A means 6th character is "A"
  if (substr(trinucsubs[j], 6, 6) == "A" && substr(trinucsubs[j], 2, 2) == "G" && substr(trinucsubs[j], 1, 1) == "C") {
    # Add z_high and z_low prefixed substitutions for G>A at reverse CpG
    methSubs = c(methSubs, 
                 paste0("z_High", trinucsubs[j]),
                 paste0("z_Low", trinucsubs[j]))
  }
}
# Create indices for methSubs
methSubsInd = setNames(1:length(methSubs), methSubs)
M_matrix = array("",dim=c(length(methSubs), 4))
M_matrix[,1] = methSubs
M_matrix[,2] = paste(methSubs,"*wmis",sep="")
M_matrix[,3] = paste(methSubs,"*wnon",sep="")
M_matrix[,4] = paste(methSubs,"*wspl",sep="")
substmodelMeth <- M_matrix
  
# Penta sub model
nt = c("A","C","G","T")
pentanuc_list = paste(rep(nt,each=4^4,times=1),rep(nt,each=4^3,times=4),rep(nt,each=4^2,times=4^2),rep(nt,each=4,times=4^3),rep(nt,each=1,times=4^4), sep="")
pentanuc_subs = c(sapply(pentanuc_list, function(x) paste(x, paste(substr(x,1,2),nt[nt!=substr(x,3,3)],substr(x,4,5),sep=""), sep=">")))
R_matrix = array("",dim=c(3072,4))
R_matrix[,1] = pentanuc_subs
R_matrix[,2] = paste(pentanuc_subs,"*wmis",sep="")
R_matrix[,3] = paste(pentanuc_subs,"*wnon",sep="")
R_matrix[,4] = paste(pentanuc_subs,"*wspl",sep="")

# PentaMethSubModel
methPentaSubs = pentanuc_subs
for (j in 1:length(pentanuc_subs)) {
  # Check for C>T substitution at CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "T" && substr(pentanuc_subs[j], 3, 3) == "C" && substr(pentanuc_subs[j], 4, 4) == "G") {
    # Add z_high and z_low prefixed substitutions for C>T at CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_High", pentanuc_subs[j]),
                      paste0("z_Low", pentanuc_subs[j]))
  }
  # Check for G>A substitution at reverse CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "A" && substr(pentanuc_subs[j], 3, 3) == "G" && substr(pentanuc_subs[j], 2, 2) == "C") {
    # Add z_high and z_low prefixed substitutions for G>A at reverse CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_High", pentanuc_subs[j]),
                      paste0("z_Low", pentanuc_subs[j]))
  }
}
M_matrix = array("",dim=c(length(methPentaSubs), 4))
M_matrix[,1] = methPentaSubs
M_matrix[,2] = paste(methPentaSubs,"*wmis",sep="")
M_matrix[,3] = paste(methPentaSubs,"*wnon",sep="")
M_matrix[,4] = paste(methPentaSubs,"*wspl",sep="")
substmodelMethPenta <- M_matrix


# Function run
if(refCDS_type == "Tri" & inputSet == "Exome") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, cv = scores, referenceVersion = "TriExome",  
                          refdb=refcds, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          gene_list = genelist,  
                          outmats = T)
} else if (refCDS_type == "Tri" & inputSet == "Comb") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, cv = scores,  referenceVersion = "TriComb",  
                          refdb=refcds, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          gene_list = genelist,  
                          outmats = T)
} else if (refCDS_type == "TriMeth" & inputSet == "Exome") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "TriMethExome", refdb=refcds, cv = scores, 
                          max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = substmodelMeth, gene_list = genelist, 
                          methAnnotatedVars = methMutations, methSubs = methSubs, outmats = T)
} else if (refCDS_type == "TriMeth" & inputSet == "Comb") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "TriMethComb",  refdb=refcds, cv = scores, 
                          max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = substmodelMeth, gene_list = genelist, 
                          methAnnotatedVars = methMutations, methSubs = methSubs, outmats = T)
} else if(refCDS_type == "Penta" & inputSet == "Exome") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, cv = scores, referenceVersion = "PentaExome",  
                          refdb=refcds, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = R_matrix, gene_list = genelist,  
                          outmats = T)
} else if (refCDS_type == "Penta" & inputSet == "Comb") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, cv = scores,  referenceVersion = "PentaComb",  
                          refdb=refcds, max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = R_matrix, gene_list = genelist,  
                          outmats = T)
} else if (refCDS_type == "PentaMeth" & inputSet == "Exome") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "PentaMethExome", refdb=refcds, cv = scores, 
                          max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = substmodelMethPenta, gene_list = genelist, 
                          methAnnotatedVars = methMutations, methSubs = methPentaSubs, outmats = T)
} else if (refCDS_type == "PentaMeth" & inputSet == "Comb") {
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "PentaMethComb",  refdb=refcds, cv = scores, 
                          max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                          sm = substmodelMethPenta, gene_list = genelist, 
                          methAnnotatedVars = methMutations, methSubs = methPentaSubs, outmats = T)
}

write_tsv(output$globaldnds, file = paste0(dndsPath, "inputFor_dNdS/results/globaldnds_", refCDS_type, inputSet, geneSet, ".tsv"))
write_tsv(output$sel_cv, file = paste0(dndsPath, "inputFor_dNdS/results/sel_cv_", refCDS_type, inputSet, geneSet, ".tsv"))
write_tsv(output$mle_submodel, file = paste0(dndsPath, "inputFor_dNdS/results/mle_submodel_", refCDS_type, inputSet, geneSet, ".tsv"))
aic = AIC(output$poissmodel)
write_tsv(as.data.frame(aic), file = paste0(dndsPath, "inputFor_dNdS/results/aic_", refCDS_type, inputSet, geneSet, ".tsv"))
save(output, file = paste0(dndsPath, "inputFor_dNdS/results/dndsout_", refCDS_type, inputSet, geneSet, ".Rdata"))
```

##### Age group test
```{r dndsScript}
#!/usr/bin/env Rscript

# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
ageSet <- commandArgs(trailingOnly = TRUE)[1]


library(Rsamtools)
library(seqinr)
library(dndscv)
library(tidyverse)
dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"

# ref objects
load(paste0(dndsPath, "basePairRef/gr_genes.Rdata"))
fafile = paste0(dndsPath, "Homo_sapiens.GRCh37.75.dna.primary_assembly.fa")
# Covariates
load("/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/covariates_20pc_GRCh37-38.epi_strict_outliers.Rdat")
# Gene Lists
load(paste0(dndsPath, "inputFor_dNdS/dndsCov.Rdata"))
vCovTarg <- vCov[names(vCov) %in% names(vCovEx)]
vCovComb <- sapply(split(c(vCov, vCovEx), names(c(vCov, vCovEx))), sum)


genelist = names(vCovEx)


# Load custom function
source(paste0(dndsPath, "inputFor_dNdS/dndsPentaMethBPfunction.R"))

# Penta sub model
nt = c("A","C","G","T")
pentanuc_list = paste(rep(nt,each=4^4,times=1),rep(nt,each=4^3,times=4),rep(nt,each=4^2,times=4^2),rep(nt,each=4,times=4^3),rep(nt,each=1,times=4^4), sep="")
pentanuc_subs = c(sapply(pentanuc_list, function(x) paste(x, paste(substr(x,1,2),nt[nt!=substr(x,3,3)],substr(x,4,5),sep=""), sep=">")))
R_matrix = array("",dim=c(3072,4))
R_matrix[,1] = pentanuc_subs
R_matrix[,2] = paste(pentanuc_subs,"*wmis",sep="")
R_matrix[,3] = paste(pentanuc_subs,"*wnon",sep="")
R_matrix[,4] = paste(pentanuc_subs,"*wspl",sep="")

# PentaMethSubModel
methPentaSubs = pentanuc_subs
for (j in 1:length(pentanuc_subs)) {
  # Check for C>T substitution at CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "T" && substr(pentanuc_subs[j], 3, 3) == "C" && substr(pentanuc_subs[j], 4, 4) == "G") {
    # Add z_high and z_low prefixed substitutions for C>T at CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_High", pentanuc_subs[j]),
                      paste0("z_Low", pentanuc_subs[j]))
  }
  # Check for G>A substitution at reverse CpG site in pentanucleotide
  if (substr(pentanuc_subs[j], 9, 9) == "A" && substr(pentanuc_subs[j], 3, 3) == "G" && substr(pentanuc_subs[j], 2, 2) == "C") {
    # Add z_high and z_low prefixed substitutions for G>A at reverse CpG
    methPentaSubs = c(methPentaSubs, 
                      paste0("z_High", pentanuc_subs[j]),
                      paste0("z_Low", pentanuc_subs[j]))
  }
}
M_matrix = array("",dim=c(length(methPentaSubs), 4))
M_matrix[,1] = methPentaSubs
M_matrix[,2] = paste(methPentaSubs,"*wmis",sep="")
M_matrix[,3] = paste(methPentaSubs,"*wnon",sep="")
M_matrix[,4] = paste(methPentaSubs,"*wspl",sep="")
substmodelMeth <- M_matrix


# Which dataset to load
refcds <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS/methBPPenta_RefCDS.Rdata"
if(ageSet == "Young") {
  mutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdSAge.tsv"), col_types = cols()) |> filter(age < 43) |> select(-age)
  methMutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMethAge.tsv"), col_types = cols()) |> filter(age < 43) |> select(-age)
  geneCov = vCovEx
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "PentaMethExome", refdb=refcds, cv = scores, 
                        max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                        sm = substmodelMeth, gene_list = genelist, #dc = geneCov, 
                        methAnnotatedVars = methMutations, methSubs = methPentaSubs, outmats = T)
  globdnds <- output$globaldnds |> mutate(age = "Age 26-42")
  write_tsv(globdnds, file = paste0(dndsPath, "inputFor_dNdS/results/globaldnds_", ageSet, ".tsv"))
} else if(ageSet == "Middle") {
  mutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdSAge.tsv"), col_types = cols()) |> filter(age >= 43 & age <59) |> select(-age)
  methMutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMethAge.tsv"), col_types = cols()) |> filter(age >= 43 & age <59) |> select(-age)
  geneCov = vCovEx
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "PentaMethExome", refdb=refcds, cv = scores, 
                        max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                        sm = substmodelMeth, gene_list = genelist, #dc = geneCov, 
                        methAnnotatedVars = methMutations, methSubs = methPentaSubs, outmats = T)
  globdnds <- output$globaldnds |> mutate(age = "Age 43-58")
  write_tsv(globdnds, file = paste0(dndsPath, "inputFor_dNdS/results/globaldnds_", ageSet, ".tsv"))
} else if(ageSet == "Old") {
  mutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVars_dNdSAge.tsv"), col_types = cols()) |> filter(age >= 59) |> select(-age)
  methMutations = read_tsv(paste0(dndsPath, "inputFor_dNdS/mutationsInput/exomeVarsMethAge.tsv"), col_types = cols()) |> filter(age >= 59) |> select(-age)
  geneCov = vCovEx
  output <- dndscvBPPenta(mutations, genomefile = fafile, referenceVersion = "PentaMethExome", refdb=refcds, cv = scores, 
                        max_muts_per_gene_per_sample = Inf, max_coding_muts_per_sample = Inf, 
                        sm = substmodelMeth, gene_list = genelist, #dc = geneCov, 
                        methAnnotatedVars = methMutations, methSubs = methPentaSubs, outmats = T)
  globdnds <- output$globaldnds |> mutate(age = "Age 59-74")
  write_tsv(globdnds, file = paste0(dndsPath, "inputFor_dNdS/results/globaldnds_", ageSet, ".tsv"))
}



```  

##### Submit jobs
```{bash dndsComp}
# Full exome penta and penta meth models
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS
bsub -o jobLogs/tri.out -e jobLogs/tri.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Exome Tri All
bsub -o jobLogs/triComb.out -e jobLogs/triComb.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Comb Tri All
bsub -o jobLogs/methtri.out -e jobLogs/methtri.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Exome TriMeth All
bsub -o jobLogs/methtriComb.out -e jobLogs/methtriComb.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Comb TriMeth All
bsub -o jobLogs/penta.out -e jobLogs/penta.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Exome Penta All
bsub -o jobLogs/pentaComb.out -e jobLogs/pentaComb.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Comb Penta All
bsub -o jobLogs/methPenta.out -e jobLogs/methPenta.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Exome PentaMeth All
bsub -o jobLogs/methPentaComb.out -e jobLogs/methPentaComb.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript runPenta.R Comb PentaMeth All

# Targeted RHT models
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS
rm jobLogs/*Targ.*
bsub -o jobLogs/TriCombTarg.out -e jobLogs/TriCombTarg.err -q normal -R 'select[mem>=16000] rusage[mem=16000] span[hosts=1]' -M 16000 Rscript runPenta.R Comb Tri Targ
bsub -o jobLogs/methTriCombTarg.out -e jobLogs/methTriCombTarg.err -q normal -R 'select[mem>=16000] rusage[mem=16000] span[hosts=1]' -M 16000 Rscript runPenta.R Comb TriMeth Targ
bsub -o jobLogs/pentaCombTarg.out -e jobLogs/pentaCombTarg.err -q normal -R 'select[mem>=16000] rusage[mem=16000] span[hosts=1]' -M 16000 Rscript runPenta.R Comb Penta Targ
bsub -o jobLogs/methPentaCombTarg.out -e jobLogs/methPentaCombTarg.err -q normal -R 'select[mem>=16000] rusage[mem=16000] span[hosts=1]' -M 16000 Rscript runPenta.R Comb PentaMeth Targ

# Age split 
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/inputFor_dNdS
bsub -o jobLogs/Young.out -e jobLogs/Young.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript ageGroupPenta.R Young
bsub -o jobLogs/Middle.out -e jobLogs/Middle.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript ageGroupPenta.R Middle
bsub -o jobLogs/Old.out -e jobLogs/Old.err -q normal -R 'select[mem>=32000] rusage[mem=32000] span[hosts=1]' -M 32000 Rscript ageGroupPenta.R Old


```

#### Gene Set enrichment

##### Gene lists
###### Sig gene drivers
```{r Siggenedrivers}

load(paste0(dndsPath, "globalAnalysis/geneLists.Rdata"))

write_tsv(tibble(gene = knownPosSelection), paste0(dndsPath, "geneSetEnrich/geneLists/driver_knownPosSelection.tsv"))
write_tsv(tibble(gene = known_cancer_and_germline), paste0(dndsPath, "geneSetEnrich/geneLists/driver_known_cancer_and_germline.tsv"))
write_tsv(tibble(gene = knownGermline), paste0(dndsPath, "geneSetEnrich/geneLists/driver_knownGermline.tsv"))
write_tsv(tibble(gene = knownGermline) |> filter(!gene %in% c("FAT1", "TRERF1")), paste0(dndsPath, "geneSetEnrich/geneLists/driver_knownGermlinePenta.tsv"))
write_tsv(tibble(gene = cancergenes), paste0(dndsPath, "geneSetEnrich/geneLists/driver_cancergenes.tsv"))

```


###### Germ cell expression
```{r xiaGermExp, fig.height = 6, fig.width=12}
#Fix genes formatted as dates
fixDatesTable <- tibble(gene = c("01-Dec","01-Sep","02-Sep","03-Mar","03-Sep","04-Mar","04-Sep","05-Mar","05-Sep","06-Mar","06-Sep","07-Mar","07-Sep","08-Mar","08-Sep","09-Mar","09-Sep","10-Mar","10-Sep","11-Mar","11-Sep","12-Sep","14-Sep"),
                        fix = c("DEC1","SEPT1","SEPT2","MARCH3","SEPT3","MARCH4","SEPT4","MARCH5","SEPT5","MARCH6","SEPT6","MARCH7","SEPT7","MARCH8","SEPT8","MARCH9","SEPT9","MARCH10","SEPT10","MARCH11","SEPT11","SEPT12","SEPT14"))

#HGNC IDs for all protein coding genes
ensembl_IDs <- read_tsv(paste0("/Users/mn7/volumes/mn7_lustre/pipelineInput/", "expression/hgncIDs2.txt"), col_types = 'ccccic', skip = 1, 
                    col_names = c('hgnc_id', 'gene_name', 'alias_symbol','old_symbol', 'entrez_gene_id', 'ensembl_gene_id')) |> 
  select(gene = gene_name, ensembl_gene_id) |> 
  distinct()

germCellLevel <- read_csv(paste0("/Users/mn7/volumes/mn7_lustre/pipelineInput/", "expression/expr_level_groups.csv"), col_types = cols(.default = "c")) |> 
  pivot_longer(1:9, names_to = "bin", values_to = "gene") |> 
  drop_na() |> 
  left_join(fixDatesTable, by ="gene") |> 
  mutate(gene = if_else(gene %in% fixDatesTable$gene, fix, gene)) |> 
  select(bin, gene) |> 
  #combine 1+2 and 7+8 as the 1 and 8 bins small/underpowered
  mutate(bin = if_else(bin %in% c("Group_Unexp"), "Unexp", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_1", "Group_2"), "neg6", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_3"), "neg6_to_neg4", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_4"), "neg4_to_neg2", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_5"), "neg2_to_0", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_6"), "0_to_2", bin)) |> 
  mutate(bin = if_else(bin %in% c("Group_7", "Group_8"), "over2", bin))

germCellCluster <- read_csv(paste0("/Users/mn7/volumes/mn7_lustre/pipelineInput/", "expression/expr_timing_clusters.csv"), col_types = cols(.default = "c"), skip = 3, col_names = c("Unexp", "Undiff_SSC", "Diff_SSC", "Spermatocyte", "Spermatid_1", "Spermatid_2")) |> 
  pivot_longer(1:6, names_to = "bin", values_to = "gene") |> 
  drop_na() |> 
  left_join(fixDatesTable, by ="gene") |> 
  mutate(gene = if_else(gene %in% fixDatesTable$gene, fix, gene)) |> 
  select(bin, gene) |> 
  filter(gene %in% names(vCovEx))

germCellExpr <- germCellLevel  |> bind_rows(germCellCluster) |> 
  filter(gene %in% names(vCovEx))

for (i in 1:length(unique(germCellExpr$bin))){
  germExBin <- unique(germCellExpr$bin)[i]
  gene_list_x <- germCellExpr |> filter(bin == germExBin) 
  write_tsv(gene_list_x, paste0(dndsPath, "geneSetEnrich/geneLists/expr_", germExBin, ".tsv"))
}

germExpressionFiltered <- germExprEx |> 
  rename(Pathway = geneGroup) |> mutate(list = if_else(Pathway %in% c("Undiff SSC", "Diff SSC", "Spermatocyte", "Spermatid 1", "Spermatid 2"),  "Spermatogenesis Stage Expr Cluster (Xia et al, 2020)", "Spermatogenesis Expr log2(UMI) (Xia et al, 2020)")) |> 
  mutate(Pathway = fct_relevel(Pathway, c("Unexp","< -6","-6 to -4","-4 to -2","-2 to 0", "0 to 2", ">2", "Undiff SSC", "Diff SSC", "Spermatocyte", "Spermatid 1", "Spermatid 2"))) |> 
  arrange(Pathway)

write_tsv(germExpressionFiltered, paste0(paperPath, "data/germExpressionFiltered.tsv"))


```

###### Cancer Pathways
```{r pathways}

cancerPathways <- c("Ras signaling pathway", "TGF-beta signaling pathway", "mTOR signaling pathway", "PI3K-Akt signaling pathway", "JAK-STAT signaling pathway", "Wnt signaling pathway", "Notch signaling pathway", "p53 signaling pathway", "Hippo signaling pathway", "Cell cycle")
nonCancerPathways <-c("Olfactory transduction")

KEGG_Pathways <- read_tsv(paste0(paperPath, "data/kegg/keggPathways.txt"), col_types = 'cc',col_names = c("keggPathway", "Pathway")) |> 
  mutate(Pathway = str_remove(Pathway, " - Homo sapiens \\(human\\)"))
KEGG_Names <- read_tsv(paste0(paperPath, "data/kegg/keggGenes.txt"), col_types = 'cc-c',col_names = c("keggGene", "transcriptType", "names")) |> 
  filter(transcriptType == "CDS") |> select(-transcriptType) |> 
  separate(names, into = c("gene"), sep = ",", extra = "drop") |> 
  separate(gene, into = c("gene"), sep = ";", extra = "drop")
pathway_gene_list0 <-  read_tsv(paste0(paperPath, "data/kegg/keggPathwayMap.txt"), col_types = 'cc', col_names = c("keggPathway", "keggGene")) |> 
  mutate(keggPathway = str_remove(keggPathway, "path:")) |> 
  left_join(KEGG_Names,by = join_by(keggGene)) |> 
  left_join(KEGG_Pathways,by = join_by(keggPathway)) |> 
  select(Pathway, gene) 
write_tsv(pathway_gene_list0, paste0(paperPath, "data/pathway_gene_list0.tsv"))
pathway_gene_listCancer <- pathway_gene_list0 |> filter(Pathway %in% cancerPathways)
pathway_gene_listNonCancer <- pathway_gene_list0 |> filter(Pathway %in% nonCancerPathways) |> 
  filter(!gene %in% pathway_gene_listCancer$gene) 

pathway_gene_list <- pathway_gene_listCancer |> 
  filter(gene %in% known_cancer_and_germline) |>
  bind_rows(pathway_gene_listNonCancer) |>
  filter(gene %in% names(vCovEx)) |> 
  mutate(Pathway = str_remove(Pathway, " signaling pathway")) |> 
  mutate(Pathway = str_replace(Pathway, " ", "_")) 
  
for (i in 1:length(unique(pathway_gene_list$Pathway))){
  germExBin <- unique(pathway_gene_list$Pathway)[i]
  gene_list_x <- pathway_gene_list |> filter(Pathway == germExBin) |> select(gene)
  write_tsv(gene_list_x, paste0(dndsPath, "geneSetEnrich/geneLists/pathway_", germExBin, ".tsv"))
}

```

##### Function script
```{r dndsScript}
#!/usr/bin/env Rscript

suppressPackageStartupMessages(library(dndscv))
suppressPackageStartupMessages(library(tidyverse))

# Get gene list file from the command line argument
args <- commandArgs(trailingOnly = TRUE)
geneListFile <- args[1]

dndsPath <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/"
geneListPath <- paste0(dndsPath, "geneSetEnrich/geneLists/")

# Load the dndscv results
load(paste0(dndsPath, "inputFor_dNdS/results/dndsout_PentaMethExomeAll.Rdata"))

# Source the custom function
source(paste0(dndsPath, "geneSetEnrich/genesetdndsMutCount.R"))

# Create the methylation matrix
nt = c("A","C","G","T")
pentanuc_list = paste(rep(nt,each=4^4,times=1),rep(nt,each=4^3,times=4),rep(nt,each=4^2,times=4^2),rep(nt,each=4,times=4^3),rep(nt,each=1,times=4^4), sep="")
pentanuc_subs = c(sapply(pentanuc_list, function(x) paste(x, paste(substr(x,1,2),nt[nt!=substr(x,3,3)],substr(x,4,5),sep=""), sep=">")))

# PentaMethSubModel 
methPentaSubs = pentanuc_subs
for (j in 1:length(pentanuc_subs)) {
  if (substr(pentanuc_subs[j], 9, 9) == "T" && substr(pentanuc_subs[j], 3, 3) == "C" && substr(pentanuc_subs[j], 4, 4) == "G") {
    methPentaSubs = c(methPentaSubs, paste0("z_High", pentanuc_subs[j]), paste0("z_Low", pentanuc_subs[j]))
  }
  if (substr(pentanuc_subs[j], 9, 9) == "A" && substr(pentanuc_subs[j], 3, 3) == "G" && substr(pentanuc_subs[j], 2, 2) == "C") {
    methPentaSubs = c(methPentaSubs, paste0("z_High", pentanuc_subs[j]), paste0("z_Low", pentanuc_subs[j]))
  }
}
M_matrix = array("",dim=c(length(methPentaSubs), 4))
M_matrix[,1] = methPentaSubs
M_matrix[,2] = paste(methPentaSubs,"*wmis",sep="")
M_matrix[,3] = paste(methPentaSubs,"*wnon",sep="")
M_matrix[,4] = paste(methPentaSubs,"*wspl",sep="")

# Initialize the geneSetEnrich dataframe with globaldnds data
geneSetEnrich <- output$globaldnds|>
  mutate(name = c("missense", "nonsense", "splice", "truncating", "all"))|>
  mutate(muts = c(sum(output$genemuts$n_mis),
                  sum(output$genemuts$n_non),
                  sum(output$genemuts$n_spl),
                  sum(output$genemuts$n_non + output$genemuts$n_spl),
                  sum(output$genemuts$n_non + output$genemuts$n_spl + output$genemuts$n_mis)))|>
  mutate(geneGroup = "Exome")|>
  mutate(n_genes = dim(output$sel_cv)[1])

# Extract name of the gene list and read the file
geneListName <- tools::file_path_sans_ext(basename(geneListFile))
geneList <- read_tsv(geneListFile, col_types = cols())|> pull(gene)

message(paste0("Running ", geneListName, "..."))

# Append results to geneSetEnrich
geneSetEnrich <- geneSetEnrich|>
  bind_rows(
    genesetdndsMutCount(output, gene_list = geneList, sm = M_matrix)|>
    mutate(geneGroup = geneListName))

# Write the results to a .tsv file
write_tsv(geneSetEnrich, paste0(dndsPath, "geneSetEnrich/results/geneSetEnrich_", geneListName,".tsv"))

```

##### Summarize geneset enrich
```{r sumGeneSetEnrich}
cancerPathways <- tibble(Pathway = c("Ras signaling pathway", "TGF-beta signaling pathway", "mTOR signaling pathway", "PI3K-Akt signaling pathway", "JAK-STAT signaling pathway", "Wnt signaling pathway", "Notch signaling pathway", "p53 signaling pathway", "Hippo signaling pathway", "Cell cycle")) |> 
  mutate(Pathway = str_remove(Pathway, " signaling pathway")) |> 
  mutate(Pathway = str_replace(Pathway, " ", "_")) 

globalPathwaydnds0 <- tibble()
for (i in 1:length(cancerPathways$Pathway)){
  path <- cancerPathways$Pathway[i]
  pathway <- read_tsv(paste0(dndsPath, "geneSetEnrich/results/geneSetEnrich_pathway_", path, ".tsv"), col_types = cols()) |> 
    filter(geneGroup != "Exome")
  globalPathwaydnds0 <- globalPathwaydnds0 |> bind_rows(pathway)
}

expr_file_list <- list.files(path = paste0(dndsPath, "geneSetEnrich/results/"), 
                        pattern = "geneSetEnrich_expr_.*\\.tsv", 
                        full.names = T)

globalExprdnds0 <- tibble()
for (i in 1:length(expr_file_list)){
  file  = expr_file_list[i]
  expr <- read_tsv(file, col_types = cols()) |> 
    filter(geneGroup != "Exome")
  globalExprdnds0  <- globalExprdnds0  |> bind_rows(expr)
}

geneSetEnrich <- globalExprdnds0 |> bind_rows(globalPathwaydnds0)
write_tsv(geneSetEnrich, paste0(paperPath, "data/geneSetEnrich.tsv"))

```

##### Submit jobs
```{bash dndsComp}

# Submit driver lists
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich

for genelistFile in /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich/geneLists/driver_*.tsv; do
  geneListName=$(basename "${genelistFile}" .tsv)
  
  # Submit the job with the gene list file as an argument to the R script
  bsub -o "jobLogs/enrich_${geneListName}.%J.out" \
       -e "jobLogs/enrich_${geneListName}.%J.err" \
       -q long \
       -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' \
       -M 80000 \
       Rscript runGeneSetEnrich.R "${genelistFile}"
done

# Submit expr lists
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich

for genelistFile in /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich/geneLists/expr_*.tsv; do
  geneListName=$(basename "${genelistFile}" .tsv)
  
  # Submit the job with the gene list file as an argument to the R script
  bsub -o "jobLogs/enrich_${geneListName}.%J.out" \
       -e "jobLogs/enrich_${geneListName}.%J.err" \
       -q long \
       -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' \
       -M 80000 \
       Rscript runGeneSetEnrich.R "${genelistFile}"
done

# Submit pathway lists
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich

for genelistFile in /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich/geneLists/pathway_*.tsv; do
  geneListName=$(basename "${genelistFile}" .tsv)
  
  # Submit the job with the gene list file as an argument to the R script
  bsub -o "jobLogs/enrich_${geneListName}.%J.out" \
       -e "jobLogs/enrich_${geneListName}.%J.err" \
       -q long \
       -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' \
       -M 80000 \
       Rscript runGeneSetEnrich.R "${genelistFile}"
done

# Submit neg selection lists
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich

for genelistFile in /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/geneSetEnrich/geneLists/neg_*.tsv; do
  geneListName=$(basename "${genelistFile}" .tsv)
  
  # Submit the job with the gene list file as an argument to the R script
  bsub -o "jobLogs/enrich_${geneListName}.%J.out" \
       -e "jobLogs/enrich_${geneListName}.%J.err" \
       -q long \
       -R 'select[mem>=80000] rusage[mem=80000] span[hosts=1]' \
       -M 80000 \
       Rscript runGeneSetEnrich.R "${genelistFile}"
done

```

##### Mut set enrichment
```{r reccurVars, fig.height=5,fig.width=9}
allSNVs <- collapsedTargVars |> 
  filter(class == "snv")

totalCov <- read_tsv(paste0(path, "postNextflow/cov/totalCovMerged_Coding.bed"), col_types ='c-dd', col_names = c("chr", "pos", "cov")) |>
  left_join(read_tsv(paste0(path, "postNextflow/triNuc/triNucUniqMerged_Coding.bed"), col_types ='c-dc', col_names = c("chr", "pos", "tri")), by = join_by(chr, pos))

mutModel_dndsTri0 <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/mle_submodel_TriExomeAll.tsv"), col_types = cols()) |> filter(!name %in% c("wmis", "wspl", "wnon"))
mutModel_dndsTri <- mutModel_dndsTri0 |> 
  mutate(triRate = if_else(name != "t", mle*mutModel_dndsTri0$mle[1], mle)) |> 
  mutate(name = if_else(name == "t", "TTT>TGT", name)) |> 
  mutate(tri = str_sub(name,1,3), alt = str_sub(name,6,6)) |> 
  select(tri, alt, triRate)

dddmutsCount <- read_tsv(paste0(localPath, "data/DDDmuts2020.txt"), col_types = cols()) |> 
  select(chr = chrom, pos, ref, alt) |> 
  filter(ref %in% c("A","C","G","T") & alt %in% c("A","C","G","T")) |> 
  group_by(chr, pos, ref, alt) |> summarize(count = n(), .groups = "drop") |> 
  mutate(source = "DDD") |> 
  left_join(totalCov, by = c("chr", "pos")) |> 
  left_join(allSNVs |> rename(pos = start) |>
    group_by(chr, pos, ref, alt) |> 
    summarize(spermCount = n(), .groups = "drop"), by = c("chr", "pos", "ref", "alt")) |> 
  mutate(spermCount = replace_na(spermCount,0)) |> 
  drop_na() |>
  mutate(reccurGroup = if_else(count > 1, "2-4", "1")) |>
  mutate(reccurGroup = if_else(count > 5, "5+", reccurGroup)) |> 
  left_join(mutModel_dndsTri, by = join_by(alt, tri))

cosmicMutsCount <- read_tsv(paste0(paperPath, "data/cosmic/COSMIC_v99_WholeGenomeExome_dNdSAnnotatedMuts.tsv"), col_types = cols()) |> 
  rename(alt = mut) |> 
  group_by(chr, pos, ref, alt) |> summarize(count = n(), .groups = "drop") |> 
  filter(ref %in% c("A","C","G","T") & alt %in% c("A","C","G","T")) |> 
  mutate(source = "COSMIC") |> 
  left_join(totalCov, by = c("chr", "pos")) |> 
  left_join(allSNVs |> rename(pos = start) |>
    group_by(chr, pos, ref, alt) |> 
    summarize(spermCount = n(), .groups = "drop"), by = c("chr", "pos", "ref", "alt")) |> 
  mutate(spermCount = replace_na(spermCount,0)) |> 
  drop_na() |> 
  mutate(reccurGroup = if_else(count >= 10, "10-49", "1-9")) |>
  mutate(reccurGroup = if_else(count >= 50, "50+", reccurGroup)) |>
  left_join(mutModel_dndsTri, by = join_by(alt, tri))

mutRateEnrich <- dddmutsCount |> bind_rows(cosmicMutsCount) |>
  mutate(spermExp = cov * triRate) |> 
  group_by(reccurGroup, source) |> summarize(cov = sum(cov), spermCount = sum(spermCount), spermExp = sum(spermExp), .groups = "drop") |> 
  mutate(mutRate = spermCount/cov) |> 
  mutate(obsExp = spermCount/spermExp) |> 
  # Add poisson CIs
  mutate(poisson = map(spermCount, poisson.test)) |> 
  mutate(out = map(poisson, ~  tibble(ci_lower = .x$conf.int[1],
                      ci_upper = .x$conf.int[2]))) |> 
  unnest_wider(c(out)) |> 
  select(-poisson) |> 
  mutate(rateLower = ci_lower/spermExp, rateUpper = ci_upper/spermExp)
write_tsv(mutRateEnrich, paste0(paperPath, "data/mutRateEnrich.tsv"))
```

### Annotate Significant Genes
#### Databases for annot
```{r databases}
sigGenes <- read_tsv(paste0(dndsPath, "sigGenes.tsv"), col_types = cols()) 

# DDD list
dddList <- read_csv(paste0(paperPath, "data/DDG2P_29_2_2024.csv"), col_types = cols()) |> 
  dplyr::rename(gene = `gene symbol`) |> 
  filter(`allelic requirement` != "biallelic_autosomal") |> 
  # filter(gene %in% sigGenes$gene_name) |> 
  mutate(mutType = if_else(is.na(`variant consequence`), `mutation consequence flag`, `variant consequence`)) |> 
  # Remove diseases that dont match mechanism observed in sperm
  filter(!`disease name` %in% c("SPINAL AND BULBAR MUSCULAR ATROPHY", "Juvenile polyposis/hereditary hemorrhagic telangiectasia syndrome", "PROTEUS SYNDROME")) |> 
  filter(!(mutType == "missense_variant;inframe_deletion;inframe_insertion" & gene %in% c("FGFR2", "FGFR3", "DDX3X", "PTPN11"))) |> 
  group_by(gene) |> summarize(DD_disease = paste(`disease name`, collapse = ", "), DD_allelic_requirement = paste(unique(`allelic requirement`), collapse = ", "), DD_mut_csq = paste(unique(`mutation consequence`), collapse = ", "), DD_mut_type = paste(unique(mutType), collapse = ", "), DD_conf = paste(unique(`confidence category`), collapse = ", ")) 

# cosmic list
cosmicList <- read_tsv(paste0(paperPath, "data/cosmic/COSMIC_CGC_v99_hg19.tsv"), col_types = cols()) |> 
  select(gene = `Gene Symbol`, Tier:`Other Syndrome`) |> 
  filter(gene %in% sigGenes$gene_name)

knownPosSelection <- c("PTPN11", "FGFR3", "FGFR2", "HRAS", "RET", "BRAF", "KRAS", "MAP2K1", "MAP2K2", "SOS1", "CBL", "RAF1", "SMAD4")

# Other disorders
otherDis <- tibble(gene = c("BMPR2", "DHX9", "SMAD6", "ROBO1"),
                   other_disorder = c("Pulmonary hypertension", "Developmental disorders, Charcot-Marie-Tooth disease", "Congenital heart defects, Craniosynostosis, Radioulnar synostosis", "Congenital heart defects, Pituitary stalk interruption syndrome"))

rasList <- read_xlsx("~/Google Drive/My Drive/Sperm/targetedData/ras-pathway-gene-names.xlsx") |> 
  pull(`Gene name`)

keggPathways <- read_tsv(paste0(paperPath, "data/pathway_gene_list0.tsv"), col_types = cols()) |> group_by(gene) |> mutate(pathways = paste0(str_remove(Pathway, " signaling pathway"), collapse = ", ")) |> 
  select(gene, pathways) |> distinct()

gnomadGeneConstraint <- read_tsv(paste0(paperPath, "data/gnomad.v4.0.constraint_metrics.tsv"), col_types = cols()) |> 
  filter(mane_select & str_detect(transcript, "ENST") & gene %in% sigGenes$gene_name) |> 
  mutate(across(c(lof.oe, lof.oe_ci.lower, lof.oe_ci.upper, mis.oe, mis.oe_ci.lower, mis.oe_ci.upper), ~ round(., digits = 3))) |> 
  mutate(gnomad_lof_oe = paste0(lof.oe, " (CI: ", lof.oe_ci.lower, "-", lof.oe_ci.upper, ")")) |> 
  mutate(gnomad_mis_oe = paste0(mis.oe, " (CI: ", mis.oe_ci.lower, "-", mis.oe_ci.upper, ")")) |> 
  select(gene, gnomad_mis_oe, gnomad_lof_oe) 

omimAnnot <- read_tsv(paste0(paperPath, "data/morbidmap_2024-06-21.txt"), comment = "#", col_names = c("OMIM_Phenotypes", "gene", "MIM Number",	"Cyto Location"), col_types = cols()) |> 
  select(gene, OMIM_Phenotypes) |> 
  separate_rows(gene, sep = ", ") |> 
  filter(gene %in% sigGenes$gene_name) |> 
  # Remove somatic, complex disease, and tentative associations
  filter(!str_detect(OMIM_Phenotypes, "somatic") & !str_detect(OMIM_Phenotypes, "\\{")& !str_detect(OMIM_Phenotypes, "\\?") & !str_detect(OMIM_Phenotypes, "\\(1\\)")) |> 
  mutate(OMIM_Phenotypes = str_remove(OMIM_Phenotypes, " \\(3\\)")) |> 
  group_by(gene) |> summarize(OMIM_Phenotypes = paste0(OMIM_Phenotypes, collapse = "; "))

```


#### Table annotated
```{r effectTable}
fullAnnotGenesDisease <- sigGenes |>  
  rename(gene = gene_name) |> 
  mutate(LOF = if_else((ptrunc_cv < 0.1 | pind_cv < 0.1) & ((n_non + n_spl + n_ind) > 1), "Yes", "-")) |> 
  mutate(missense = if_else(pmis_cv < 0.1, "Yes", "-")) |> 
  mutate(germlineMechanism = if_else(LOF == "Yes", "LOF", "Missense Only")) |> 
  mutate(germline_driver = if_else(gene %in% knownPosSelection, "known", "novel")) |> 
  left_join(dddList, by = "gene") |> 
  left_join(otherDis, by = "gene") |> 
  left_join(cosmicList, by = "gene") |> 
  left_join(keggPathways, by = "gene") |> 
  mutate(ras = if_else(gene %in% rasList, "Ras", "-")) |> 
  mutate(pathwayCurated = if_else(ras == "Ras" | gene %in% c("LZTR1", "CUL3", "RIT1") & gene != "ARHGAP35", "RAS-MAPK signalling", "Other") ) |> 
  mutate(pathwayCurated = if_else(gene %in% c("SMAD4", "SMAD6", "BMPR2", "TCF12"), "BMP signalling", pathwayCurated)) |> 
  mutate(pathwayCurated = if_else(gene %in% c("CSNK2B", "CTNNB1", "MIB1", "CCAR2", "FAT1"), "Wnt signalling", pathwayCurated)) |> 
  mutate(pathwayCurated = if_else(gene %in% c("ARID1A", "KDM5B","KDM5C", "NSD1", "EP300", "ANKRD11", "KMT2D", "MECP2", "KMT2E"), "Epigenetic modifier", pathwayCurated)) |> 
  mutate(pathwayCurated = if_else(gene %in% c("DDX3X", "DHX9", "SCAF4"), "RNA metabolism", pathwayCurated)) |> 
  arrange(germline_driver, DD_disease) |> 
  # Cancer mech
  mutate(cancerMechanism = if_else(`Role in Cancer` %in% c("oncogene", "oncogene, fusion") | gene == "CBL", "Activating", "Fusion Only")) |> 
  mutate(cancerMechanism = if_else(`Role in Cancer` %in% c("TSG", "TSG, fusion") | gene == "KMT2D", "LOF", cancerMechanism)) |> 
  mutate(cancerMechanism = if_else(is.na(Tier), "Not in list", cancerMechanism)) |> 
  # Add disease info
  mutate(DD_disease = str_to_title(DD_disease)) |> 
  arrange(DD_disease, other_disorder) |> 
  mutate(DD_disease = str_replace_all(DD_disease, setNames(toupper(c("Cul3", "Pten", "Mib", "Leopard", "Ppm1d", "Kbg")), c("Cul3", "Pten", "Mib", "Leopard", "Ppm1d", "Kbg")))) |>
  mutate(DD_disease = str_remove(DD_disease, " \\(Monoallelic\\)")) |>
  mutate(source = if_else(is.na(DD_disease), "-", "DDG2P (Thormann et al. 2019)")) |> 
  mutate(inherited_disease = if_else(is.na(DD_disease), other_disorder, DD_disease)) |> 
  mutate(DD_allelic_requirement = str_remove(DD_allelic_requirement, "_autosomal")) |> 
  mutate(DD_mut_type = str_remove(DD_mut_type, "_variant")) |> 
  mutate(DD_mut_type = str_remove(DD_mut_type, "restricted repertoire of mutations;")) |> 
  mutate(DD_Mechanism = if_else(DD_mut_type == "activating", "Activating", "LOF")) |> 
  mutate(DD_Mechanism = if_else(is.na(DD_conf), "Not in list", DD_Mechanism )) |> 
  # Non DDG2P genes
  mutate(DD_allelic_requirement = if_else(gene %in% c("BMPR2", "DHX9", "SMAD6", "ROBO1"), "monoallelic", DD_allelic_requirement)) |>
  mutate(source = if_else(gene == "BMPR2", "Deng et al. 2000; Momose et al. 2015; Evans et al. 2016", source)) |>
  mutate(source = if_else(gene == "DHX9", "Calame et al. 2023", source)) |>
  mutate(source = if_else(gene == "SMAD6", "Luyckx et al. 2022", source)) |>
  mutate(source = if_else(gene == "ROBO1", "Bashamboo et al. 2017; Kruszka et al. 2017; Liu and Chen 2020; Huang et al. 2022", source)) |>
  # Add x-linked info to disease
  mutate(inherited_disease = if_else(gene == "AR", paste0(inherited_disease, " (X-linked hemizygous)"), inherited_disease)) |> 
  mutate(inherited_disease = if_else(gene == "DDX3X", paste0(inherited_disease, " (X-linked heterozygous)"), inherited_disease)) |> 
  left_join(gnomadGeneConstraint, by = join_by(gene)) |> 
  left_join(omimAnnot, by = join_by(gene))

write_csv(fullAnnotGenesDisease, paste0(paperPath, "data/fullAnnotGenesDisease.csv"))

simpleAnnotGenes <- fullAnnotGenesDisease |> 
  select(gene, testSig, typeSig, pathwayCurated, pathways, germlineMechanism, DD_disease, DD_conf, OMIM_Phenotypes, DD_Mechanism, cancerMechanism,  Tier) 

write_csv(simpleAnnotGenes, paste0(paperPath, "data/simpleAnnotGenes.csv"))

diseaseAnnotGenes <- fullAnnotGenesDisease |> 
  select(gene, DD_disease, DD_conf, OMIM_Phenotypes, DD_Mechanism) 

write_tsv(diseaseAnnotGenes, paste0(paperPath, "extended/SupTable8_DiseaseSummary.tsv"))
```

#### gnomad processing v2.1
##### Download
```{bash gnomadDownload}

cd /lustre/scratch126/casm/team294rr/External_Databases/Variants/gnomAD_v2
bsub -o jobLogs/download.%J.out -e jobLogs/download.%J.err -q long -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "wget https://storage.googleapis.com/gcp-public-data--gnomad/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz; wget https://storage.googleapis.com/gcp-public-data--gnomad/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz.tbi"
```

##### Process
```{bash gnomadProcessing}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/gnomad
nano filterToAFv2.1.sh

#!/bin/bash
module load bcftools
bcftools view -Ov -o - /lustre/scratch126/casm/team294rr/External_Databases/Variants/gnomAD_v2/gnomad.exomes.r2.1.1.sites.vcf.bgz | \
bcftools view -i 'FILTER=="PASS"' -Ov | \
bcftools query -f '%CHROM\t%POS\t%REF\t%ALT\t%INFO/AC\t%INFO/AN\t%INFO/AF\n' > gnomad.exomes.v2.1.1.AF.txt

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/gnomad
bsub -e jobLogs/%J.err -o jobLogs/%J.out -q basement -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 ./filterToAFv2.1.sh

```

##### Bin by AF
```{bash gnomadAFProcessing}
nano splitAFv2.sh

#!/bin/bash

input_file="gnomad.exomes.v2.1.1.AF.txt"

# Filter column 5 == 1
awk '$5 == 1 && ($6 > 100000)' "$input_file" > v2_AFs/AF_1.txt

# Filter column 5 == 2
awk '$5 == 2 && ($6 > 100000)' "$input_file" > v2_AFs/AF_2.txt

# Filter based on column 5 and column 6 ranges
# awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1e-5 && $7 > 1e-6)' "$input_file" > v2_AFs/AF_1e-6_to_1e-5.txt
awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1e-4 && $7 > 1e-5)' "$input_file" > v2_AFs/AF_1e-5_to_1e-4.txt
awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1e-3 && $7 > 1e-4)' "$input_file" > v2_AFs/AF_1e-4_to_1e-3.txt
awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1e-2 && $7 > 1e-3)' "$input_file" > v2_AFs/AF_1e-3_to_1e-2.txt
awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1e-1 && $7 > 1e-2)' "$input_file" > v2_AFs/AF_1e-2_to_1e-1.txt
awk '($5 != 1 && $5 != 2) && ($6 > 100000) && ($7 <= 1 && $7 > 1e-1)' "$input_file" > v2_AFs/AF_1e-1_to_1.txt


bsub -e jobLogs/%J.err -o jobLogs/%J.out -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 ./splitAFv2.sh


```

#### Germline datasets
```{r dndsGlobInput2}
# DNMs
dnmGrouped <- read_tsv(paste0(dndsPath, "trios/denovo-db.non-ssc-samples.variants.tsv"), col_types = cols(), comment = "##") |> 
  bind_rows(read_tsv(paste0(dndsPath, "trios/denovo-db.ssc-samples.variants.tsv"), col_types = cols(), comment = "##"))
table(dnmGrouped$PrimaryPhenotype)

controlDNMs <- dnmGrouped |> filter(PrimaryPhenotype == "control") |> 
  filter(str_length(Variant) == 3) |> 
  mutate(ref = str_sub(Variant,1,1), mut = str_sub(Variant,3,3)) |> 
  select(sampleID = `#SampleID`, chr = Chr, pos = Position, ref, mut)
write_tsv(controlDNMs, paste0(dndsPath, "globalAnalysis/germComp/controlDNMs.txt"))

# DDD
dddmuts <- read_tsv(paste0(localPath, "data/DDDmuts2020.txt"), col_types = cols()) |> 
  select(sampleID = id, chr = chrom, pos, ref, mut = alt) |> 
  filter(ref %in% c("A", "T", "C", "G") & mut %in% c("A", "T", "C", "G"))
write_tsv(dddmuts, paste0(dndsPath, "globalAnalysis/germComp/dddmuts.txt"))

# gnomad
for(group in c("AF_1", "AF_2", "AF_1e-5_to_1e-4", "AF_1e-4_to_1e-3", "AF_1e-3_to_1e-2", "AF_1e-2_to_1e-1", "AF_1e-1_to_1")){
inputVars <- read_tsv(paste0(dndsPath,"gnomad/v2_AFs/" , group, ".txt"), col_names = c("chr", "pos", "ref", "mut"), col_types = 'cccc--') |> 
  mutate(chr = str_remove(chr, "chr")) |> 
  mutate(sampleID = "i") |> 
  select(sampleID, chr, pos, ref, mut)
write_tsv(inputVars, paste0(dndsPath, "globalAnalysis/germComp/", group, ".txt"))
}
```



#### Script dN/dS
```{r dndsGnomad}

#!/usr/bin/env Rscript

# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide input file.")
}

# Get the argument provided
input_file <- commandArgs(trailingOnly = TRUE)[1]

library(dndscv)
library(tidyverse)

# refCDS object
refcds_37 <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/RefCDS_GRCh37_vF.Rdat"
load(refcds_37)
# Covariates
load("/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/covariates_20pc_GRCh37-38.epi_strict_outliers.Rdat")
# Gene Lists
load("/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/globalAnalysis/geneLists.Rdata")

# Calc dnds
geneGroupGlobal_dnds <- function(muts, geneList, label){
  dndsObj <- dndscv(muts, gene_list = geneList, cv=scores, refdb=refcds_37, max_coding_muts_per_sample = Inf, max_muts_per_gene_per_sample = Inf)
  outDF <- dndsObj$globaldnds |> 
    filter(name %in% c("wall","wmis", "wtru")) |> 
    mutate(name = c("missense", "truncating", "all")) |> 
    mutate(muts = c(sum(dndsObj$genemuts$n_mis), sum(dndsObj$genemuts$n_non+dndsObj$genemuts$n_spl), sum(dndsObj$genemuts$n_mis+dndsObj$genemuts$n_non+dndsObj$genemuts$n_spl))) |> 
    mutate(n_genes = dim(dndsObj$sel_cv)[1]) |> 
    mutate(geneGroup = label)
  return(outDF)
}

# dnds format variant file
inputVars <- read_tsv(paste0(input_file, ".txt"), col_types = cols())

outDF <- geneGroupGlobal_dnds(inputVars, exomeGenes, "Exome") |> 
  bind_rows(geneGroupGlobal_dnds(inputVars, cancergenes, "Known Cancer")) |> 
  bind_rows(geneGroupGlobal_dnds(inputVars, known_cancer_and_germline, "Known Cancer + Germline Driver")) |> 
  bind_rows(geneGroupGlobal_dnds(inputVars, knownGermline, "Germline Driver")) |> 
  mutate(group = input_file) |> 
  #Convert w to driver count by multiplying muts by (w-1/w)
  mutate(n_drivers = (mle-1)/mle * muts) |> mutate(cilowDrivers = (cilow-1)/cilow * muts) |> mutate(cihighDrivers = (cihigh-1)/cihigh * muts)

write_tsv(outDF, paste0("/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/globalAnalysis/output/", input_file, ".global_dnds.tsv"), col_names = F)

```

##### Submit
```{bash dndsGnomadsubmit}

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/globalAnalysis/germComp/
for file in AF_1 AF_2 AF_1e-5_to_1e-4 AF_1e-4_to_1e-3 AF_1e-3_to_1e-2 AF_1e-2_to_1e-1 AF_1e-1_to_1 autismDNMs controlDNMs dddmuts
do
    echo "$file"
    bsub -e ../jobLogs/%J.err -o ../jobLogs/%J.out -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "Rscript ../global_dNdS.R ${file}"
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/globalAnalysis/somaticComp
for file in cosmicFormatted lungFormatted prostateFormatted liverFormatted
do
    echo "$file"
    bsub -e ../jobLogs/%J.err -o ../jobLogs/%J.out -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M 100000 "Rscript ../global_dNdS.R ${file}"
done

#Group 
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/dnds/globalAnalysis/
cat output/* > all_global_dNdS.tsv

```

#### Contraint data gnomad
```{r gnomadConstraint}

simpleAnnotGenes <- read_csv(paste0(paperPath, "data/simpleAnnotGenes.csv"), col_types = cols()) 
spermLofGene <- simpleAnnotGenes |> filter(germlineMechanism == "LOF") |> pull(gene)

above10kCov <- names(vCovEx)[vCovEx > 10000]
gnomadConstraintAllGenes <- read_tsv(paste0(paperPath, "data/gnomad.v2.1.1.lof_metrics.by_gene.txt"), col_types = cols()) |> 
  filter(exp_lof > 3) |>
  mutate(geneCat = if_else(gene %in% spermLofGene, "Sperm LOF selection gene (n=31)","Other gene (n = 17,031)")) |> 
  mutate(source = "gnomadV2") |> 
  left_join(sig_dndsAll |> filter(gene_name %in% above10kCov) |> mutate(wlof = (wnon_cv+wind_cv)/2) |> select(gene = gene_name, wlof, wmis = wmis_cv)) |> 
  drop_na(wlof) |> arrange(-wlof) |> 
  mutate(labelGene = if_else(geneCat == "Sperm LOF selection gene (n=31)" & (lof_z < -5 | wlof > 30), gene, "")) |> 
  select(gene, geneCat, labelGene, lof_z, wlof)
write_tsv(gnomadConstraintAllGenes, paste0(paperPath, "data/gnomadConstraintAllGenes.tsv"))
```

## d) Collapse analysis files
Get per sample variant and sample info which collapses coverage and variant calls when a sample has been sequenced more than once
### Variant coverage
#### Calc coverage
```{bash collapseIndivs}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/collapse
mkdir -p varList
mkdir -p varCov
mkdir -p collapseCut
mkdir -p jobLogs
#Individuals have sometimes more than one targeted seq and or targeted + exome. Collapse coverage to one file per individual
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow
rm cov/jobLogs/collapse*
for sample in `cut -f1 ../targetedSamplesFiltered.txt | cut -c1-8 | sort | uniq`;
  do echo $sample
  bsub -o cov/jobLogs/collapse.$sample.out -e cov/jobLogs/collapse.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; sed 's/;/\t/g' cov/masked/$sample*.cov.bed | cut -f 1-3,6 | sort -T tmp -k1,1 -k2,2n | bedtools merge -d -1 -c 4 -o sum > cov/collapse/collapseCut/$sample.cov.bed"
done


```

#### Cov bed
```{r collapse}
# Read in variants
 
collapsedVars <- read_tsv(paste0(paperPath, "data/analysisTargVars.tsv"), col_types = cols())  |> 
  group_by_at(vars(chr:alt, PD_ID, age_at_sampling:twinStatus, class:ClinVar)) |> 
  summarise(TIMES_CALLED = sum(TIMES_CALLED), .groups = "drop") 

PD_IDlist <- collapsedVars |> distinct(PD_ID) |> pull(PD_ID)

# Write out list of sites to get coverage for in each sample
for(sample in PD_IDlist) {
  covBedVariants <- collapsedVars |> filter(PD_ID == sample) |> 
    mutate(startBed = start - 1) |> 
    select(chr, startBed, start) |> 
    arrange(chr, startBed)
  write_tsv(covBedVariants, paste0(path, "postNextflow/cov/collapse/varList/", sample, ".vars.bed"), col_names = F)
}

```

#### Cov bed intersect
```{bash collapse}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/collapse
rm jobLogs/intersect*
for sample in `cut -f2 ../../../targetedSamplesFiltered.txt | sort | uniq`;
  do echo $sample
  bsub -o jobLogs/intersect.$sample.out -e jobLogs/intersect.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 "module load bedtools; sort -T tmp -k1,1 -k2,2n varList/$sample.vars.bed > varList/$sample.vars.sorted.bed; bedtools intersect -a collapseCut/$sample.cov.bed -b varList/$sample.vars.sorted.bed -wa > varCov/$sample.vars.bed"
done

# Group results
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/collapse
rm collapsedCov.bed
for sample in `cut -f2 ../../../targetedSamplesFiltered.txt | sort | uniq`;
  do echo $sample
  sed "s/$/\t$sample/" varCov/$sample.vars.bed >> collapsedCov.bed
done
```

#### Variants
```{r collapse}
# Process cov
collapsedTargVars <- read_tsv(paste0(paperPath, "data/analysisTargVars.tsv"), col_types = cols())  |>
  group_by_at(vars(chr:alt, methBin, PD_ID, age_at_sampling:twinStatus, class:ClinVar)) |> 
  summarise(TIMES_CALLED = sum(TIMES_CALLED), .groups = "drop") |> 
  mutate(indiv = str_sub(PD_ID, 1,7)) |>
  left_join(read_tsv(paste0(path, "postNextflow/cov/collapse/collapsedCov.bed"), col_types = 'c-ddc', col_names = c("chr", "start", "DUPLEX_COV", "PD_ID")) |> distinct(), by = c("chr", "start",  "PD_ID")) |> drop_na(DUPLEX_COV)

write_tsv(collapsedTargVars, paste0(paperPath, "data/collapsedTargVars.tsv"))

simpleOut <- collapsedTargVars |> select(chr:PD_ID,  age = age_at_sampling, TIMES_CALLED, DUPLEX_COV, csq, gene, gnomAD_AF, ClinVar, CLNSIG, PHEN) |> arrange(gene)
write_csv(simpleOut, paste0(paperPath, "data/spermAllVars.csv"))

```


### Shared Vars
```{r sharedness}

# Variants overlapping on timepoints
sharedTimepointVars <- collapsedTargVars |> 
  group_by(indiv, chr, start, ref, alt) |> 
  summarize(count = n(), .groups = "drop") |> 
  filter(count > 1) |> 
  left_join(collapsedTargVars |> select(c(chr:alt, class:ClinVar)) |> distinct(), by = join_by(chr, start, ref, alt))
dim(sharedTimepointVars)[1]

# Get number of variants that had coverage in second timepoint
twoTimepointIndivs <- targetedSamplesFiltered |> 
  mutate(indiv = str_sub(PD_ID, 1,7)) |> 
  distinct(indiv,tissue_timepoint) |> 
  group_by(indiv) |> summarize(timepoints = n()) |> filter(timepoints > 1)
print(paste0("Number of 2 timepoint samples in targeted: ", dim(twoTimepointIndivs)[1]))

firstTimepointVars <- collapsedTargVars |> 
  filter(indiv %in% twoTimepointIndivs$indiv) |> filter(tissue_timepoint == 1) |> 
  select(chr, start, indiv) |> 
  # Append second timepoint ID to look for coverage
  left_join(targetedSamplesFiltered |> 
    mutate(indiv = str_sub(PD_ID, 1,7)) |> filter(indiv %in% twoTimepointIndivs$indiv) |> filter(tissue_timepoint == 2) |> 
    distinct(PD_ID, indiv), by = join_by(indiv)) |> 
  select(chr, start, PD_ID)

write_tsv(firstTimepointVars, paste0(path, "postNextflow/cov/timepointShared/firstTimepointVars.tsv"), col_names = F)

```

#### Extract cov at shared sites
```{bash sharedVars}
#!/bin/bash

input_file="$1"

# Output file
output_file="firstTimepointCov.tsv"

# Initialize the output file with a header
echo -e "PD_ID\tchr\tstart\tResult" > "$output_file"

# Loop through each line in the TSV file
while IFS=$'\t' read -r chr start PD_ID; do
    # Construct the filename for the .cov.bed file
    cov_file="../collapse/collapseCut/${PD_ID}.cov.bed"

    # Check if the .cov.bed file exists
    if [ -e "$cov_file" ]; then
        # Use awk to search for a matching entry in the .cov.bed file
        # and print the fourth column or 0 if no match is found
        result=$(awk -v chr="$chr" -v start="$start" '$1 == chr && $3 == start {print $4; exit}' "$cov_file")
        echo -e "$PD_ID\t$chr\t$start\t${result:-0}" >> "$output_file"
    else
        echo -e "$PD_ID\t$chr\t$start\t0 (File not found)" >> "$output_file"
    fi
done < "$input_file"

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/cov/timepointShared/
bsub -o %J.out -e %J.err -q long -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M 1000 "./extractCovTimepoint.sh firstTimepointVars.tsv"

```

## e) Expected VAF sums
Generating background expectations for specific sets of variants in vafSum analyses

### i) Annots of Interest

#### Basic catgerories
Getting variant lists for simpler annotations through bash filtering
```{bash basicAnnots}
#!/bin/bash

# Read the match string and column number from command line arguments
match_string="$1"
column_number="$2"

# Check if both arguments are provided
if [[ -z "$match_string" || -z "$column_number" ]]; then
    echo "Please provide the match string and column number as arguments."
    echo "Example: bash filter_tsv.sh synonymous 5"
    exit 1
fi

# Path to the output TSV file
output_file="backgrounds/${match_string}_vepCovered_sorted.tsv"

# Filter the TSV file based on the provided match string and column number
awk -F'\t' -v pattern="$match_string" -v column="$column_number" -v OFS='_' \
    '$column == pattern {print $1, $2, $3, $4}' vepCoveredProcessed.tsv | sort > "$output_file"

echo "Filtered and sorted TSV file created: $output_file"

```

##### Submit different categories
```{bash subCats}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
bsub -e jobLogs/basic.vep.err -o jobLogs/basic.vep.out -J basic_vep.%J -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 ./basicFilter.sh synonymous 5
bsub -e jobLogs/basic.vep.err -o jobLogs/basic.vep.out -J basic_vep.%J -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 ./basicFilter.sh missense 5

bsub -e jobLogs/basic.vep.err -o jobLogs/basic.vep.out -J basic_vep.%J -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M10000 ./basicFilter.sh HIGH 6
bsub -e jobLogs/basic.vep.err -o jobLogs/basic.vep.out -J basic_vep.%J -q long -R 'select[mem>=20000] rusage[mem=20000] span[hosts=1]' -M20000 ./basicFilter.sh MODIFIER 6

```


#### Clinical Categories
Getting variant lists for more complex annotations by pulling into R
##### Get R readable file
```{bash processVEP}
# Reduce size of VEP files to possible variants to pull

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep

#!/bin/bash

# Filtering conditions
cadd_threshold=30
impact_string="HIGH"
clin_string="athogenic"

awk -F"\t" -v cadd_threshold="$cadd_threshold" -v impact_string="$impact_string" -v clin_string="$clin_string" '$13 > cadd_threshold || $6 == impact_string || $10 ~ clin_string' vepCoveredProcessed.tsv > clinFilterVEP.vcf


cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep
bsub -e jobLogs/clin.vep.err -o jobLogs/clin.vep.out -J preFilter_vep -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000 ./clinFilterVep.sh

```

#### Process Clinical 
```{r processVEP}
vepCovered <- read_tsv(paste0(path, "postNextflow/vep/clinFilterVEP.vcf"), col_types = 'ccccccccccccd', col_names = c("chr", "start", "ref", "alt", "csq", "IMPACT", "gene", "gnomAD_AF", "PHEN", "CLNSIG", "CLNSIGCONF", "trinuc", "cadd")) |> 
  mutate(CLNSIG = str_remove(CLNSIG, "[\\|,\\/].*")) |> 
  # Criteria for labeling variants as ClinVar path or not:
  mutate(ClinVar = if_else(CLNSIG %in% c("Pathogenic", "Likely_pathogenic") | 
                             CLNSIG == "Conflicting_classifications_of_pathogenicity" & 
                              (str_detect(CLNSIGCONF, "Pathogenic") | str_detect(CLNSIGCONF, "Likely_pathogenic") & !str_detect(CLNSIGCONF, "enign")) & !str_detect(PHEN, "recessive"), T, F)) |> 
  mutate(gnomAD_AF = as.numeric(if_else(gnomAD_AF == "-", "0", gnomAD_AF)))

# Write for analysis file
write_tsv(vepCovered |> filter(PHEN != "-"), paste0(paperPath, "data/clinVarFiltered.tsv"))

# A) Just Clinvar pathogenic
write_delim(vepCovered |> 
  filter(ClinVar) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredClin.tsv"), col_names = F, delim = "_")

# B) Clinvar pathogenic | DDD lof
dddLOF <- read_csv(paste0(paperPath, "data/DDG2P_29_2_2024.csv"), col_types = cols()) |> 
  dplyr::rename(gene = `gene symbol`) |> 
  filter(`allelic requirement` %in% c("monoallelic_autosomal","monoallelic_X_hem","monoallelic_X_het","mitochondrial") & `confidence category` %in% c("strong","definitive","moderate")) |> 
  filter(str_detect(`mutation consequence`,"absent gene product")) |> distinct(gene) |> pull(gene)
write_tsv(tibble(gene = dddLOF), paste0(path, "postNextflow/vep/dddList.tsv"), col_names = T)

write_delim(vepCovered |> 
  filter(ClinVar | (gene %in% dddLOF & IMPACT == "HIGH")) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredClinDDlof.tsv"), col_names = F, delim = "_")

# C) Clinvar pathogenic | DDD lof | DDD CADD >= 30 & gnomad occurs max once in exome dataset: Note gnomad filter removed 2.5k of 125k
write_delim(vepCovered |> 
  filter(ClinVar | (gene %in% dddLOF & IMPACT == "HIGH") | (gene %in% dddLOF & cadd >= 30 & gnomAD_AF < 5e-6)) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredClinDDlofCADD.tsv"), col_names = F, delim = "_")

# D) ClinVar terms
write_delim(vepCovered |> filter(ClinVar & str_detect(PHEN, "RASopathy")) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredRasopathy.tsv"), col_names = F, delim = "_")
write_delim(vepCovered |> filter(ClinVar & str_detect(PHEN, "Hereditary_cancer-predisposing_syndrome")) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredCancerPredisposing.tsv"), col_names = F, delim = "_")

# E) Disorder Specific. 
## i) Achondroplasia
write_delim(vepCovered |> filter(start == 1806119 & str_detect(PHEN, "Achondroplasia")) |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredAchondroplasia.tsv"), col_names = F, delim = "_")
## ii) Noonan's
write_delim(vepCovered |> filter(ClinVar & str_detect(PHEN, "oonan")) |> filter(!str_detect(PHEN, "eurofibromatosis"))  |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredNoonan.tsv"), col_names = F, delim = "_")
## iii) NF1
write_delim(vepCovered |> filter(gene == "NF1") |> filter((ClinVar & str_detect(PHEN, "eurofibromatosis")) | IMPACT == "HIGH" | cadd >= 30)  |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredNF1.tsv"), col_names = F, delim = "_")
## iv) CrouzonPfeiffer
write_delim(vepCovered |> filter((str_detect(PHEN, "rouzon") | str_detect(PHEN, "feiffe")) & gene %in% c("FGFR2", "FGFR1") & ClinVar)  |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredCrouzonPfeiffer.tsv"), col_names = F, delim = "_")
## v) Apert
write_delim(vepCovered |> filter((chr == "10" & start == 123279677 & alt %in% c("C")) | (chr == "10" & start == 123279674 & alt %in% c("C")))  |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredApert.tsv"), col_names = F, delim = "_")
## vi) Thanatophoric_dysplasia
write_delim(vepCovered |>  filter((str_detect(PHEN, "Thanatophoric_dysplasia")) & start!= 1806119 & ClinVar)  |> 
  select(chr:alt), paste0(path, "postNextflow/vep/backgrounds/vepCoveredThanatophoric_dysplasia.tsv"), col_names = F, delim = "_")

rm(vepCovered)
gc()
```

##### Sort in bash order 
```{bash sort}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep/backgrounds

for file in `ls vepCovered*.tsv | grep -v "sorted"` ; do
    # Check if the file exists
    if [ -f "$file" ]; then
        # Extract the base file name without the extension
        base_name="${file%.*}"
        echo "$base_name"
        # Sort the file and redirect the output to a new sorted file
        sort "$file" > "${base_name}_sorted.tsv"
    fi
done

```


### ii) SNV expected
#### Tri + meth dnds model adjusted for age
```{r expMutRates}
targetedSamplesFiltered <- read_tsv(paste0(metaPath,"targetedSamplesFiltered.tsv"), col_types = cols())
#Read in variants
analysisTargVars <- read_tsv(paste0(paperPath, "data/analysisTargVars.tsv"), col_types = cols()) 

# Base pair trinucleotide methylation model from dnds of exome samples
triRate <- read_tsv(paste0(dndsPath, "inputFor_dNdS/results/mle_submodel_TriMethExomeAll.tsv"), col_types = cols()) |> 
  filter(!name %in% c("wmis", "wspl", "wnon")) |> 
  # Handle meth
  mutate(Meth = if_else(str_detect(name, "z_High"), "High", "Mid")) |> mutate(Meth = if_else(str_detect(name, "z_Low"), "Low", Meth)) |> 
  mutate(name = if_else(str_detect(name, "z_High"), str_sub(name, 7,14), name)) |> mutate(name = if_else(str_detect(name, "z_Low"), str_sub(name, 6,13), name)) |> 
  rename(tri = name, triRate = mle, tricilow = cilow, tricihigh = cihigh) |> 
  mutate(alt = str_sub(tri, 6,6)) |> 
  mutate(ref = str_sub(tri, 2,2)) |> 
  mutate(tri = str_sub(tri, 1,3)) |> 
  select(tri, ref, alt, triRate, methBin = Meth)

burdenNoPos <- read_tsv(paste0(paperPath, "data/burdensCoding.tsv"), col_types = cols()) |> 
  select(Sample_PD_ID, burdenAll_NoPos) |> 
  left_join(targetedSamplesFiltered, by = join_by(Sample_PD_ID)) |> 
  filter(nanoseq %in% c("Targeted", "Exome")) 

cohortRate <- burdenNoPos |> 
  filter(nanoseq == "Exome") |> 
  summarize(rate = mean(burdenAll_NoPos))

m <- lm(burdenAll_NoPos ~ age_at_sampling, burdenNoPos |> filter(nanoseq == "Exome"))

ggplot(burdenNoPos, aes(x = age_at_sampling, y = burdenAll_NoPos, fill = nanoseq, colour = nanoseq)) + 
  geom_point(size=3.5, pch=21, col='white', stroke=0.25) + 
  theme(text = element_text(size=16)) + 
  geom_smooth(method='lm', alpha = 0.2) +
  scale_fill_manual(values = target_colours,  name = "NanoSeq type") +
  scale_colour_manual(values = target_colours,  name = "NanoSeq type") +
  xlab('Age (years)') + 
  ylab('Substitutions per bp') + 
  theme_pubr() + 
  ylim(0,NA) +
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))

indivRate <- burdenNoPos |> 
  mutate(burdenPred = m$coefficients[1] + m$coefficients[2]*age_at_sampling) |> 
  mutate(cohortRate = (cohortRate |> pull(rate))) |> 
  mutate(ratio = burdenPred/cohortRate) |> 
  select(Sample_PD_ID, ratio)

# Sample correction factor based on ratio of burden in that sample to the full cohort burden used to get tri rates
write_tsv(indivRate, paste0(paperPath, "data/indivRatioMutRates.tsv"))
# Full cohort tri rates
write_tsv(triRate, paste0(paperPath, "data/triExpectedMutRates.tsv"))

# Write out per sample rate files
for (id in indivRate$Sample_PD_ID) {
  rate <- indivRate |> filter(Sample_PD_ID == id) |> pull(ratio)
  outRate <- triRate |> mutate(triRate = format((triRate*rate), digits = 4)) 
  write_tsv(outRate, paste0(path, "postNextflow/expected/triRateTarg/", id, ".tsv"), col_names = F)
}


```

#### Generate Exp Counts
##### Targ with methylation
```{r generateExp}
#!/usr/bin/env Rscript

# Check if the argument is provided
if (length(commandArgs(trailingOnly = TRUE)) == 0) {
  print("Please provide id.")
}

# Get the argument provided
id <- commandArgs(trailingOnly = TRUE)[1]
model <- commandArgs(trailingOnly = TRUE)[2]

path <- "/lustre/scratch126/casm/team294rr/mn7/sperm/targeted/"

library(tidyverse)

# Write out per sample rate files

triRate <- read_tsv(paste0(path, "postNextflow/expected/triRate", model ,"/", id, ".tsv"), col_names = c("tri", "ref", "alt", "rate", "methBin"), col_types = 'cccdc')
indivCov <- read_tsv(paste0(path, "postNextflow/cov/methAnnot/bin10/", id, ".methCov.masked.bed"), col_types = 'c-ccc', col_names = c("chr", "start", "trirefcov", "meth")) |> separate(trirefcov, into = c("tri", "ref", "cov"), convert = T) |> 
  filter(cov > 10) |> 
  mutate(alt = list(c("A", "T", "C", "G"))) |> 
  unnest(c(alt)) |> 
  filter(ref != alt)  |> 
  mutate(meth = as.numeric(str_replace(meth, "\\.", "0"))) |> 
  mutate(meth = if_else((substr(tri,2,3) == "CG" & alt == "T") | (substr(tri,1,2) == "CG" & alt == "A"), meth, 0)) |> 
  mutate(methBin = if_else(meth > 4, "High", "Mid")) |> mutate(methBin = if_else(meth == 1, "Low", methBin)) |> 
  left_join(triRate, by = c("tri", "ref", "alt", "methBin")) |> 
  mutate(rate = format(rate, digits = 4)) |> 
  select(chr,start,ref,alt,rate)

  
write_tsv(indivCov, paste0(path, "postNextflow/expected/exp", model ,"/", id, ".tsv"))

```


##### Run Rscript
```{bash runScript}
# Targ Model
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/
rm jobLogs/expCount.*
for sample in `grep "exome" ../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o jobLogs/expCount.$sample.out -e jobLogs/expCount.$sample.err -q normal -R 'select[mem>=200000] rusage[mem=200000] span[hosts=1]' -M 200000 Rscript genExp.R $sample Targ
done

for sample in `grep "targeted" ../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o jobLogs/expCount.$sample.out -e jobLogs/expCount.$sample.err -q normal -R 'select[mem>=16000] rusage[mem=16000] span[hosts=1]' -M 16000 Rscript genExp.R $sample Targ
done



```

#### Sort in bash
```{bash runScript}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/
nano sortBash.sh

#!/bin/bash

# Check if an input file is provided
if [ $# -eq 0 ]; then
  echo "Please provide an input file."
  exit 1
fi

# Input file name
input_file="$1.tsv"

out_file="sorted/$1.tsv"

# Remove first header line, concatenate first four columns, and retain the fifth column
awk 'NR>1 {print $1"_"$2"_"$3"_"$4"\t"$5}' "$input_file" | sort -k1,1 > "$out_file"

```

##### Run sort
```{bash runScript}

#Targ Model
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/expTarg
mkdir -p sorted
mkdir -p summed

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/expTarg
rm ../jobLogs/sortTarg*
for sample in `grep "exome" ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o ../jobLogs/sortTarg.$sample.out -e ../jobLogs/sortTarg.$sample.err -q normal -R 'select[mem>=140000] rusage[mem=140000] span[hosts=1]' -M 140000 ../sortBash.sh $sample
done
for sample in `grep "targeted" ../../../targetedSamplesFiltered.txt | cut -f1`;
  do echo $sample
  bsub -o ../jobLogs/sortTarg.$sample.out -e ../jobLogs/sortTarg.$sample.err -q normal -R 'select[mem>=10000] rusage[mem=10000] span[hosts=1]' -M 10000 ../sortBash.sh $sample
done

```

#### Intersect
##### Sum intersecting regions
```{bash intersect}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected
nano intersect.sh
#!/bin/bash

indiv="sorted/$1.tsv"
variantSet="../../vep/backgrounds/${2}_sorted.tsv"

awk -F'\t' -v id="$1" -v variantID="$2" -v variantSet="$variantSet" '
    NR==FNR { variant_ids[$1]; next }
    $1 in variant_ids { print $2 }
' "$variantSet" "$indiv" | python -c '
import sys

total = 0.0
for line in sys.stdin:
    total += float(line.strip())

print(total, sys.argv[1], sys.argv[2], sep="\t")
' "$1" "$2" > "summed/$1.$2.tsv"
```

##### Submit loop
```{bash intersect}
# Targ Model
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/expTarg
rm ../jobLogs/intTarg*

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/expTarg
for sample in $(grep "exome" ../../../targetedSamplesFiltered.txt | cut -f1); do
  echo $sample
  for file in ../../vep/backgrounds/*_sorted.tsv; do
    filename=$(basename "$file")
    base="${filename%_sorted.tsv}"
    echo "Processing file: $base"
    bsub -o ../jobLogs/intTarg.$sample.out -e ../jobLogs/intTarg.$sample.err -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M 100000 ../intersect.sh $sample $base
  done
done

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/expTarg
for sample in $(grep "targeted" ../../../targetedSamplesFiltered.txt | cut -f1); do
  echo $sample
  for file in ../../vep/backgrounds/*_sorted.tsv; do
    filename=$(basename "$file")
    base="${filename%_sorted.tsv}"
    echo "Processing file: $base"
    bsub -o ../jobLogs/intTarg.$sample.out -e ../jobLogs/intTarg.$sample.err -q normal -R 'select[mem>=100000] rusage[mem=100000] span[hosts=1]' -M 100000 ../intersect.sh $sample $base
  done
done

# Summarize
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected
cat expTarg/summed/* > valsExpectedTarg.tsv

```

### iii) Indel Expected
Indel model just number of base pairs * mutation rate in sample
#### Get Regions
```{bash indelBackground}
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/indels/
mkdir -p jobLogs
nano convertBed.sh
#!/bin/bash
awk -F'\t' 'BEGIN {OFS="\t"} {print $1, $2-1, $2}'

# Convert non-coding coverage regions to bed file
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/indels/

echo "awk -F'\t' 'BEGIN {OFS=\"\t\"} {print \$1, \$2-1, \$2}' /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/vep/backgrounds/MODIFIER_vepCovered.tsv | uniq > nonCoding.tsv; module load bedtools; sort -k1,1 -k2,2n nonCoding.tsv | bedtools merge > nonCoding.bed" | bsub -e jobLogs/nonCoding.err -o jobLogs/nonCoding.out -q normal -R 'select[mem>=1000] rusage[mem=1000] span[hosts=1]' -M1000


# Clinvar patho indels
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/indels/
zgrep -v "single_nucleotide_variant" /lustre/scratch126/casm/team294rr/External_Databases/Annotations/clinvar_20230527.vcf.gz > clinvar37_indel.vcf
```

##### Get Regions R (Clin and DDD)
```{r indelCoding}
# Get ClinVar indel pathogenic bed file
clinVarPathIndelSites <- read_tsv(paste0(path, "postNextflow/expected/indels/clinvar37_indel.vcf"), col_names = c("chr", "start", "ref", "alt", "info"), col_types = 'cd-cc--c', comment = '#') |> 
  mutate(CLNSIG = str_extract(info, "(?<=CLNSIG=)[^;]+"), 
         CLNSIGCONF = str_extract(info, "(?<=CLNSIGCONF=)[^;]+")) |> 
  filter(str_length(ref) < 22 & str_length(alt) < 22) |> 
    # Criteria for labeling variants as ClinVar path or not:
  filter(CLNSIG %in% c("Pathogenic/Likely_pathogenic", "Pathogenic", "Likely_pathogenic") | 
                             CLNSIG == "Conflicting_classifications_of_pathogenicity" & 
                              (str_detect(CLNSIGCONF, "Pathogenic") | str_detect(CLNSIGCONF, "Likely_pathogenic") & !str_detect(CLNSIGCONF, "enign")
                                 )) |>
  mutate(bedStart = start - 1)
write_tsv(clinVarPathIndelSites |> select(chr, bedStart, start), paste0(path, "postNextflow/expected/indels/clinVarPath37_indel.bed"), col_names = F)

# Get ddd monogenic LOF gene base pairs or just NF1
load("/Users/mn7/volumes/mn7_lustre/sperm/targeted/genomicRegions/refcds_GRCh37-GencodeV18+Appris.rda")

process_gene <- function(gene) {
  if (gene %in% genes$gene_name) {
    gene_CDS <- RefCDS[[which(genes$gene_name == gene)]]
    
    intervals_cds <- tibble(
      chr = gene_CDS$chr,
      start = gene_CDS$intervals_cds[, 1],
      end = gene_CDS$intervals_cds[, 2]
    )
    
    return(intervals_cds)
  } else {
    warning(paste("Gene", gene, "not found in RefCDS. Skipping..."))
    return(NULL)
  }
}

dddLOF <- read_tsv(paste0(path, "postNextflow/vep/dddList.tsv"), col_types = 'c') |> pull(gene)

dddSites <- map_dfr(genes_of_interest, process_gene, .id = "gene_name") |> 
  mutate(bedStart = start - 1)
write_tsv(dddSites |> select(chr, bedStart, start), paste0(path, "postNextflow/expected/indels/dddGeneSites.bed"), col_names = F)

nf1Sites <- map_dfr(c("NF1"), process_gene, .id = "gene_name") |> 
  mutate(bedStart = start - 1)
write_tsv(nf1Sites |> select(chr, bedStart, start), paste0(path, "postNextflow/expected/indels/nf1Sites.bed"), col_names = F)
```

#### Count regions
```{bash indelClin}

# Sort beds
module load bedtools; sort -k1,1 -k2,2n clinVarPath37_indel.bed | bedtools merge > clinVarPath37_indel_sorted.bed
module load bedtools; sort -k1,1 -k2,2n dddGeneSites.bed | bedtools merge > dddGeneSites_sorted.bed
module load bedtools; sort -k1,1 -k2,2n nf1Sites.bed | bedtools merge > nf1Sites_sorted.bed

clinVarPath37_indel_sorted.bed nf1Sites_sorted.bed dddGeneSites_sorted.bed nonCoding.bed


# Count number of base pairs that are in each region and sample
MN7="/lustre/scratch126/casm/team294rr/mn7"
target_files=("clinVarPath37_indel_sorted.bed" "nf1Sites_sorted.bed" "dddGeneSites_sorted.bed" "nonCoding.bed")

cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/indels/
mkdir -p nonCodingBP
rm jobLogs/countBP*

# Loop through each target file
for target_file in "${target_files[@]}"; do
    # Loop through samples
    for sample in $(cat ../../../targetedSamplesFiltered.txt | cut -f1); do
        echo $sample
        echo "module load bedtools; bedtools intersect -a $MN7/sperm/targeted/postNextflow/cov/masked/$sample.cov.bed -b $target_file -wa | wc -l > nonCodingBP/$sample.${target_file%.bed}.txt" | bsub -o jobLogs/countBP.$sample.out -e jobLogs/countBP.$sample.err -q normal -R 'select[mem>=4000] rusage[mem=4000] span[hosts=1]' -M 4000
    done
done

# Group results for all
cd /lustre/scratch126/casm/team294rr/mn7/sperm/targeted/postNextflow/expected/indels/
rm countsIndelRegions.tsv

# Loop through samples
for sample in $(cut -f1 ../../../targetedSamplesFiltered.txt); do
    echo $sample
    # Concatenate indicating the region file used
    for target_file in "${target_files[@]}"; do
        sed "s/$/\t$sample\t${target_file%.bed}/" nonCodingBP/$sample.${target_file%.bed}.txt >> countsIndelRegions.tsv
    done
done
```

#### Generate Exp
```{r indelCoding}
 # Join indel mut rate and infer expected coding and non-coding counts
indelMutRate <- read_tsv(paste0(paperPath, "data/burdenCodingIndel.tsv"), col_types = cols()) |>  
                       # Add 3 samples with no indels
    bind_rows(tibble(Sample_PD_ID = c(""))) |> #remove sampleIDs for public code
    mutate_all(~replace_na(., 0)) |> 
    select(Sample_PD_ID, indelBurden = indelBurdenAll_NoPos) |> 
  left_join(targetedSamplesFiltered, by = join_by(Sample_PD_ID)) |> 
  filter(nanoseq != "Genome")

 m <- lm(indelBurden ~ age_at_sampling, indelMutRate |> filter(nanoseq == "Exome"))

ggplot(indelMutRate, aes(x = age_at_sampling, y = indelBurden, fill = nanoseq, colour = nanoseq)) + 
  geom_point(size=3.5, pch=21, col='white', stroke=0.25) + 
  theme(text = element_text(size=16)) + 
  geom_smooth(method='lm', alpha = 0.2) +
  scale_fill_manual(values = target_colours,  name = "NanoSeq type") +
  scale_colour_manual(values = target_colours,  name = "NanoSeq type") +
  xlab('Age (years)') + 
  ylab('Substitutions per bp') + 
  theme_pubr() + 
  ylim(0,NA) +
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12))

indivRate <- indelMutRate |> 
  mutate(burdenPred = m$coefficients[1] + m$coefficients[2]*age_at_sampling) |> 
  select(Sample_PD_ID, burdenPred, age_at_sampling, nanoseq)

bpCounts <- read_tsv(paste0(path, "postNextflow/expected/indels/countsIndelRegions.tsv"), col_types = cols(), col_names = c("bp", "Sample_PD_ID", "region"))

indelExpected <-
  # Non coding
  bpCounts |> filter(region == "nonCoding") |> mutate(vafGroup = "non-coding_indel") |> 
  # Coding counts by subtracting non-coding counts from total bp covered
  bind_rows(read_delim(paste0(path, "postNextflow/statsCoverage.tsv"), delim = " ", col_types = 'cd-----', col_names = c("Sample_PD_ID", "bpUnique")) |> 
    left_join(bpCounts |> filter(region == "nonCoding"), by = join_by(Sample_PD_ID)) |> 
    mutate(coding = bpUnique - bp) |> 
    mutate(vafGroup = "coding_indel") |> 
    select(bp = coding, vafGroup, Sample_PD_ID)) |> 
  # ClinVar path once for each annot
  bind_rows(bpCounts |> filter(region %in% c("clinVarPath37_indel_sorted")) |> mutate(vafGroup = "Clin")) |> 
  bind_rows(bpCounts |> filter(region %in% c("clinVarPath37_indel_sorted", "dddGeneSites_sorted")) |> mutate(vafGroup = "ClinDDlof")) |> 
  bind_rows(bpCounts |> filter(region %in% c("clinVarPath37_indel_sorted", "dddGeneSites_sorted")) |> mutate(vafGroup = "ClinDDlofCADD")) |> 
  # NF1
  bind_rows(bpCounts |> filter(region == "nf1Sites_sorted") |> mutate(vafGroup = "NF1")) |> 
  left_join(indivRate, by = join_by(Sample_PD_ID)) |> 
  mutate(vafSum = bp * burdenPred) |> 
  select(Sample_PD_ID, vafSum, vafGroup , age_at_sampling, nanoseq)

ggplot(indelExpected, aes(x = age_at_sampling, y = vafSum, fill = vafGroup, colour = vafGroup)) + 
  geom_point(size=3.5, pch=21, col='white', stroke=0.25) + 
  theme(text = element_text(size=16)) + 
  xlab('Age (years)') + 
  facet_wrap(~nanoseq, scales = "free_y") + 
  theme_pubr() + 
  ylim(0,NA) +
  theme(legend.position = "right", strip.background = element_blank(), strip.text = element_text(size = 12)) 

write_tsv(indelExpected |> select(Sample_PD_ID, vafGroup, vafSum) |> drop_na(), paste0(path, "postNextflow/expected/valsExpectedIndelTarg.tsv"))

```
